# Comparing `tmp/tripmaster-1.0.2-py3-none-any.whl.zip` & `tmp/tripmaster-1.0.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,107 +1,107 @@
-Zip file size: 138639 bytes, number of entries: 105
+Zip file size: 139008 bytes, number of entries: 105
 -rw-r--r--  2.0 unx      249 b- defN 22-Dec-23 09:48 tripmaster/__init__.py
 -rw-r--r--  2.0 unx        3 b- defN 22-Dec-23 09:48 tripmaster/core/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/app/__init__.py
--rw-r--r--  2.0 unx     6108 b- defN 22-Dec-23 09:48 tripmaster/core/app/config.py
+-rw-r--r--  2.0 unx     6114 b- defN 23-Apr-10 13:28 tripmaster/core/app/config.py
 -rw-r--r--  2.0 unx     2334 b- defN 22-Dec-23 09:48 tripmaster/core/app/io.py
 -rw-r--r--  2.0 unx     2678 b- defN 22-Dec-23 09:48 tripmaster/core/app/pipeline.py
 -rw-r--r--  2.0 unx     3347 b- defN 22-Dec-23 09:48 tripmaster/core/app/reinforce.py
--rw-r--r--  2.0 unx     5813 b- defN 22-Dec-23 09:48 tripmaster/core/app/standalone.py
+-rw-r--r--  2.0 unx     5965 b- defN 23-Apr-11 02:18 tripmaster/core/app/standalone.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/app/supervise.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/components/__init__.py
 -rw-r--r--  2.0 unx     4572 b- defN 22-Dec-23 09:48 tripmaster/core/components/backend.py
 -rw-r--r--  2.0 unx    11741 b- defN 22-Dec-23 09:48 tripmaster/core/components/contract.py
 -rw-r--r--  2.0 unx    27131 b- defN 22-Dec-23 09:48 tripmaster/core/components/evaluator.py
 -rw-r--r--  2.0 unx    11251 b- defN 22-Dec-23 09:48 tripmaster/core/components/loss.py
 -rw-r--r--  2.0 unx     2901 b- defN 22-Dec-23 09:48 tripmaster/core/components/problem.py
 -rw-r--r--  2.0 unx     6415 b- defN 22-Dec-23 09:48 tripmaster/core/components/repo.py
 -rw-r--r--  2.0 unx     2962 b- defN 22-Dec-23 09:48 tripmaster/core/components/task.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/components/environment/__init__.py
 -rw-r--r--  2.0 unx     6891 b- defN 22-Dec-23 09:48 tripmaster/core/components/environment/base.py
 -rw-r--r--  2.0 unx     8408 b- defN 22-Dec-23 09:48 tripmaster/core/components/environment/supervised.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/components/machine/__init__.py
 -rw-r--r--  2.0 unx    14038 b- defN 22-Dec-23 09:48 tripmaster/core/components/machine/data_traits.py
--rw-r--r--  2.0 unx    12501 b- defN 22-Dec-23 09:48 tripmaster/core/components/machine/machine.py
+-rw-r--r--  2.0 unx    12650 b- defN 23-Apr-10 07:50 tripmaster/core/components/machine/machine.py
 -rw-r--r--  2.0 unx      996 b- defN 22-Dec-23 09:48 tripmaster/core/components/machine/reinforce.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/components/modeler/__init__.py
 -rw-r--r--  2.0 unx     2583 b- defN 22-Dec-23 09:48 tripmaster/core/components/modeler/machine_memory.py
 -rw-r--r--  2.0 unx     6639 b- defN 22-Dec-23 09:48 tripmaster/core/components/modeler/memory_batch.py
--rw-r--r--  2.0 unx    18909 b- defN 22-Dec-23 09:48 tripmaster/core/components/modeler/modeler.py
+-rw-r--r--  2.0 unx    19207 b- defN 23-Apr-13 08:34 tripmaster/core/components/modeler/modeler.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/__init__.py
 -rw-r--r--  2.0 unx     5294 b- defN 23-Mar-03 09:09 tripmaster/core/components/operator/multi_task.py
--rw-r--r--  2.0 unx    13480 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/operator.py
--rw-r--r--  2.0 unx    16179 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/reinforce.py
--rw-r--r--  2.0 unx    18259 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/supervise.py
+-rw-r--r--  2.0 unx    12786 b- defN 23-Apr-10 13:47 tripmaster/core/components/operator/operator.py
+-rw-r--r--  2.0 unx    16067 b- defN 23-Apr-13 08:34 tripmaster/core/components/operator/reinforce.py
+-rw-r--r--  2.0 unx    18796 b- defN 23-Apr-13 08:34 tripmaster/core/components/operator/supervise.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/__init__.py
 -rw-r--r--  2.0 unx      896 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/batching.py
 -rw-r--r--  2.0 unx     1272 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/distributed.py
 -rw-r--r--  2.0 unx     1635 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/event_trigger.py
 -rw-r--r--  2.0 unx     4521 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/exploration_strategy.py
 -rw-r--r--  2.0 unx     1082 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/metric_logging.py
--rw-r--r--  2.0 unx    14307 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/model_selection.py
+-rw-r--r--  2.0 unx    16929 b- defN 23-Apr-07 02:55 tripmaster/core/components/operator/strategies/model_selection.py
 -rw-r--r--  2.0 unx     7487 b- defN 22-Dec-23 09:48 tripmaster/core/components/operator/strategies/optimization.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/__init__.py
 -rw-r--r--  2.0 unx    16055 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/component.py
 -rw-r--r--  2.0 unx     5996 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/contract.py
--rw-r--r--  2.0 unx    10576 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/data.py
+-rw-r--r--  2.0 unx    10655 b- defN 23-Apr-12 03:26 tripmaster/core/concepts/data.py
 -rw-r--r--  2.0 unx     3670 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/evaluator.py
 -rw-r--r--  2.0 unx      470 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/hyper_params.py
 -rw-r--r--  2.0 unx      479 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/loss.py
 -rw-r--r--  2.0 unx      375 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/machine.py
 -rw-r--r--  2.0 unx     3782 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/modeler.py
 -rw-r--r--  2.0 unx      894 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/operator.py
 -rw-r--r--  2.0 unx      990 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/scenario.py
 -rw-r--r--  2.0 unx     3197 b- defN 22-Dec-23 09:48 tripmaster/core/concepts/schema.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/launcher/__init__.py
 -rw-r--r--  2.0 unx     6326 b- defN 22-Dec-23 09:48 tripmaster/core/launcher/job.py
 -rw-r--r--  2.0 unx     3085 b- defN 23-Feb-11 04:05 tripmaster/core/launcher/launcher.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/system/__init__.py
 -rw-r--r--  2.0 unx     3133 b- defN 22-Dec-23 09:48 tripmaster/core/system/reinforce.py
--rw-r--r--  2.0 unx     2655 b- defN 22-Dec-23 09:48 tripmaster/core/system/supervise.py
--rw-r--r--  2.0 unx    34448 b- defN 22-Dec-23 09:48 tripmaster/core/system/system.py
+-rw-r--r--  2.0 unx     2658 b- defN 23-Apr-10 13:37 tripmaster/core/system/supervise.py
+-rw-r--r--  2.0 unx    34453 b- defN 23-Apr-12 03:23 tripmaster/core/system/system.py
 -rw-r--r--  2.0 unx     6326 b- defN 22-Dec-23 09:48 tripmaster/core/system/validation.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/system/test/__init__.py
 -rw-r--r--  2.0 unx      268 b- defN 22-Dec-23 09:48 tripmaster/core/system/test/test_multi.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/core/test/__init__.py
 -rw-r--r--  2.0 unx     2273 b- defN 22-Dec-23 09:48 tripmaster/core/test/test_generic.py
 -rw-r--r--  2.0 unx      142 b- defN 22-Dec-23 09:48 tripmaster/plugins/__init__.py
 -rw-r--r--  2.0 unx      985 b- defN 23-Feb-10 09:13 tripmaster/plugins/load.py
 -rw-r--r--  2.0 unx     1262 b- defN 22-Dec-23 09:48 tripmaster/plugins/backend/__init__.py
--rw-r--r--  2.0 unx    17985 b- defN 23-Feb-10 09:31 tripmaster/plugins/backend/paddle_.py
+-rw-r--r--  2.0 unx    18010 b- defN 23-Apr-10 14:25 tripmaster/plugins/backend/paddle_.py
 -rw-r--r--  2.0 unx    15364 b- defN 22-Dec-23 09:48 tripmaster/plugins/backend/torch_.py
 -rw-r--r--  2.0 unx      298 b- defN 22-Dec-23 09:48 tripmaster/plugins/batching/__init__.py
 -rw-r--r--  2.0 unx      831 b- defN 22-Dec-23 09:48 tripmaster/plugins/batching/fixed_size.py
 -rw-r--r--  2.0 unx    11702 b- defN 22-Dec-23 09:48 tripmaster/plugins/batching/resource_limit.py
 -rw-r--r--  2.0 unx      900 b- defN 22-Dec-23 09:48 tripmaster/plugins/distributed/__init__.py
 -rw-r--r--  2.0 unx      249 b- defN 22-Dec-23 09:48 tripmaster/plugins/launch/__init__.py
 -rw-r--r--  2.0 unx    17557 b- defN 23-Feb-11 07:05 tripmaster/plugins/launch/gpucluster.py
 -rw-r--r--  2.0 unx      301 b- defN 22-Dec-23 09:48 tripmaster/plugins/launch/local.py
 -rw-r--r--  2.0 unx    16371 b- defN 22-Dec-23 09:48 tripmaster/plugins/launch/paddlecloud.py
 -rw-r--r--  2.0 unx      353 b- defN 22-Dec-23 09:48 tripmaster/plugins/metric_logging/__init__.py
 -rw-r--r--  2.0 unx     2519 b- defN 22-Dec-23 09:48 tripmaster/plugins/metric_logging/tableprint.py
 -rw-r--r--  2.0 unx     2734 b- defN 22-Dec-23 09:48 tripmaster/plugins/metric_logging/tensorboard.py
 -rw-r--r--  2.0 unx      417 b- defN 22-Dec-23 09:48 tripmaster/plugins/traits/__init__.py
--rw-r--r--  2.0 unx     6519 b- defN 22-Dec-23 09:48 tripmaster/plugins/traits/basic.py
+-rw-r--r--  2.0 unx     6869 b- defN 23-Apr-12 13:28 tripmaster/plugins/traits/basic.py
 -rw-r--r--  2.0 unx     3076 b- defN 22-Dec-23 09:48 tripmaster/plugins/traits/dataclass.py
 -rw-r--r--  2.0 unx     1018 b- defN 22-Dec-23 09:48 tripmaster/plugins/traits/dgl.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-23 09:48 tripmaster/utils/__init__.py
 -rw-r--r--  2.0 unx      496 b- defN 22-Dec-23 09:48 tripmaster/utils/data.py
 -rw-r--r--  2.0 unx      153 b- defN 22-Dec-23 09:48 tripmaster/utils/enum.py
 -rw-r--r--  2.0 unx       90 b- defN 22-Dec-23 09:48 tripmaster/utils/function.py
 -rw-r--r--  2.0 unx      166 b- defN 22-Dec-23 09:48 tripmaster/utils/profile_support.py
 -rw-r--r--  2.0 unx      684 b- defN 22-Dec-23 09:48 tripmaster/utils/sample.py
 -rw-r--r--  2.0 unx     1123 b- defN 22-Dec-23 09:48 tripmaster/utils/stream.py
 -rw-r--r--  2.0 unx     3485 b- defN 22-Dec-23 09:48 tripmaster/utils/visualization.py
 -rw-r--r--  2.0 unx       49 b- defN 22-Dec-23 09:48 tripmaster/utils/logging/__init__.py
 -rw-r--r--  2.0 unx     1982 b- defN 22-Dec-23 09:48 tripmaster/utils/logging/capture.py
 -rw-r--r--  2.0 unx     1369 b- defN 22-Dec-23 09:48 tripmaster/utils/logging/config.yaml
--rw-r--r--  2.0 unx    11217 b- defN 22-Dec-23 09:48 tripmaster/utils/logging/core.py
+-rw-r--r--  2.0 unx    11217 b- defN 23-Apr-12 12:44 tripmaster/utils/logging/core.py
 -rw-r--r--  2.0 unx     7389 b- defN 22-Dec-23 09:48 tripmaster/utils/logging/inspector.py
 -rw-r--r--  2.0 unx     8502 b- defN 22-Dec-23 09:48 tripmaster/utils/logging/logger.py
 -rw-r--r--  2.0 unx     3483 b- defN 22-Dec-23 09:48 tripmaster/utils/logging/logging.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Mar-03 09:38 tripmaster-1.0.2.dist-info/LICENSE
--rw-r--r--  2.0 unx      879 b- defN 23-Mar-03 09:38 tripmaster-1.0.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-03 09:38 tripmaster-1.0.2.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 23-Mar-03 09:38 tripmaster-1.0.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     9953 b- defN 23-Mar-03 09:38 tripmaster-1.0.2.dist-info/RECORD
-105 files, 510943 bytes uncompressed, 122481 bytes compressed:  76.0%
+-rw-r--r--  2.0 unx    11357 b- defN 23-Apr-13 08:41 tripmaster-1.0.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx      879 b- defN 23-Apr-13 08:41 tripmaster-1.0.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-13 08:41 tripmaster-1.0.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 23-Apr-13 08:41 tripmaster-1.0.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     9953 b- defN 23-Apr-13 08:41 tripmaster-1.0.3.dist-info/RECORD
+105 files, 514363 bytes uncompressed, 122850 bytes compressed:  76.1%
```

## zipnote {}

```diff
@@ -294,23 +294,23 @@
 
 Filename: tripmaster/utils/logging/logger.py
 Comment: 
 
 Filename: tripmaster/utils/logging/logging.py
 Comment: 
 
-Filename: tripmaster-1.0.2.dist-info/LICENSE
+Filename: tripmaster-1.0.3.dist-info/LICENSE
 Comment: 
 
-Filename: tripmaster-1.0.2.dist-info/METADATA
+Filename: tripmaster-1.0.3.dist-info/METADATA
 Comment: 
 
-Filename: tripmaster-1.0.2.dist-info/WHEEL
+Filename: tripmaster-1.0.3.dist-info/WHEEL
 Comment: 
 
-Filename: tripmaster-1.0.2.dist-info/top_level.txt
+Filename: tripmaster-1.0.3.dist-info/top_level.txt
 Comment: 
 
-Filename: tripmaster-1.0.2.dist-info/RECORD
+Filename: tripmaster-1.0.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tripmaster/core/app/config.py

```diff
@@ -127,15 +127,15 @@
 
     optimizer: Optimizer = field(default_factory=lambda: Optimizer())
     modelselector: Dict[str, Any] = field(default_factory=lambda: dict())
     evaluator_trigger: Dict[str, Any] = field(default_factory=lambda: dict())
 
 
 @dataclass
-class Inferencer(Operator):
+class Inferencer(Operator, dict):
     pass
 
 
 @dataclass
 class Repo(dict):
 
     server: str = ""
```

## tripmaster/core/app/standalone.py

```diff
@@ -58,14 +58,18 @@
             system.problem.serialize(system.hyper_params.problem.serialize.path)
             logger.info("problem serialized")
 
         if to_save(system.hyper_params.pm_modeler):
             system.pm_modeler.serialize(system.hyper_params.pm_modeler.serialize.path)
             logger.info("pm_modeler serialized")
 
+        if to_save(system.hyper_params):
+            system.serialize(system.hyper_params.serialize.path)
+            logger.info("system serialized")
+
 
 
 class TMStandaloneApp(TMConfigurable):
 
     InputStreamType = None
     OutputStreamType = None
     SystemType = None
```

## tripmaster/core/components/machine/machine.py

```diff
@@ -85,41 +85,51 @@
         for evaluator_component_name in cls.provide_evaluator(contract_graph, controller=cls,
                                                                  controller_role=role):
             components.append(evaluator_component_name)
 
 
         contract_graph.add_subsystem("MachineSubSystem", components)
 
-    def forward_with_validation(self, data, scenario):
+    def validate_forward_input(self, data, scenario):
 
-        if self.validate:
-            for key in (TMContractChannel.Source, TMContractChannel.Target):
-                assert self.requires(forward=True, channel=key).is_valid(data)
-
-        output = self.forward(data, scenario=scenario)
-
-        if self.validate:
-            if scenario == TMScenario.Learning:
-                assert self.provides(forward=False, channel=TMContractChannel.Learn).is_valid(output)
-                assert self.loss.requires(forward=True,
-                                                  channel=TMContractChannel.Truth).is_valid(data)
-                assert self.loss.requires(forward=True,
-                                                  channel=TMContractChannel.Learn).is_valid(output)
-            elif scenario == TMScenario.Evaluation:
-                assert self.provides(forward=False, channel=TMContractChannel.Inference).is_valid(output)
-                assert self.evaluator.requires(forward=True,
-                                                       channel=TMContractChannel.Truth).is_valid(data)
-                assert self.evaluator.requires(forward=True,
-                                                       channel=TMContractChannel.Inference).is_valid(output)
-            elif scenario == TMScenario.Inference:
-                assert self.provides(forward=False, channel=TMContractChannel.Inference).is_valid(output)
-            else:
-                raise NotImplementedError()
+        if not self.validate:
+            return
 
-        return output 
+        for key in (TMContractChannel.Source, TMContractChannel.Target):
+            assert self.requires(forward=True, channel=key).is_valid(data)
+
+        if scenario == TMScenario.Learning:
+            assert self.loss.requires(forward=True,
+                                              channel=TMContractChannel.Truth).is_valid(data)
+        elif scenario == TMScenario.Evaluation:
+            assert self.evaluator.requires(forward=True,
+                                                   channel=TMContractChannel.Truth).is_valid(data)
+        elif scenario == TMScenario.Inference:
+            pass
+        else:
+            raise NotImplementedError()
+
+
+    def validate_forward_output(self, output, scenario):
+
+        if not self.validate:
+            return
+
+        if scenario == TMScenario.Learning:
+            assert self.provides(forward=False, channel=TMContractChannel.Learn).is_valid(output)
+            assert self.loss.requires(forward=True,
+                                      channel=TMContractChannel.Learn).is_valid(output)
+        elif scenario == TMScenario.Evaluation:
+            assert self.provides(forward=False, channel=TMContractChannel.Inference).is_valid(output)
+            assert self.evaluator.requires(forward=True,
+                                           channel=TMContractChannel.Inference).is_valid(output)
+        elif scenario == TMScenario.Inference:
+            assert self.provides(forward=False, channel=TMContractChannel.Inference).is_valid(output)
+        else:
+            raise NotImplementedError()
 
     @abc.abstractmethod
     def forward(self, input, scenario=None):
         """
 
         Args:
             input ():
```

## tripmaster/core/components/modeler/modeler.py

```diff
@@ -246,16 +246,22 @@
         Returns:
         """
 
         processed = []
 
         for idx, sample in enumerate(data_channel):
 
-            for result in self.model_sample(sample, scenario=scenario, level=data_channel.level):
+            try:
+                results = list(self.model_sample(sample, scenario=scenario, level=data_channel.level))
+            except Exception as e:
+                logger.error(f"Error in model_sample: Uri: {sample['uri']}, Error: {e}")
+                logger.exception(e)
+                continue
 
+            for result in results:
                 uri_key = TMDataLevel.uri_key(data_channel.level)
                 result[uri_key] = idx
                 processed.append(result)
 
         # make sure the problem samples for a raw sample are ordered together
         # processed.sort(key=lambda x: x[TMTaskDataStream.SAMPLE_URI_KEY])
         # processed = add_sample_uri(processed, TMProblemDataStream.SAMPLE_URI_KEY)
@@ -271,26 +277,28 @@
 
         Returns:
 
         """
 
         data_iter = iter(data_channel)
         first_element = next(data_iter)
-        uri_key = None
+        robust_uri_key = None
         for x in TMDataLevel.upper_level(data_channel.level):
             key = TMDataLevel.uri_key(x)
             if key in first_element:
-                uri_key = key
+                robust_uri_key = key
                 break
 
         data_iter = itertools.chain([first_element], data_iter)
 
         target_level = TMDataLevel.reconstruct(data_channel.level)
         uri_key = TMDataLevel.uri_key(target_level)
 
+        assert robust_uri_key == uri_key
+
         def key_func(x):
             return x[uri_key]
 
         for key, group in itertools.groupby(data_iter,
                                             key=key_func):
 
             yield self.reconstruct_sample(group, level=data_channel.level,
```

## tripmaster/core/components/operator/operator.py

```diff
@@ -1,38 +1,22 @@
-import weakref
-from typing import Union
-from tqdm import tqdm
 import abc
-from tripmaster.core.components.evaluator import MachineEvaluationStreamInfo
-from tripmaster.core.components.machine.machine import TMMultiMachine
-from tripmaster.core.components.modeler.machine_memory import TMMachine2MemoryModeler, \
-    TMProtoMultiMachine2MemoryModeler
+
+from tripmaster import P, D
+from tripmaster import logging
+from tripmaster.core.components.modeler.machine_memory import TMMachine2MemoryModeler
 from tripmaster.core.components.modeler.memory_batch import TMMemory2BatchModeler
+from tripmaster.core.components.operator.strategies.distributed import TMDistributedStrategyFactory
 from tripmaster.core.components.operator.strategies.event_trigger import TMEpochwiseTrigger
 from tripmaster.core.components.operator.strategies.metric_logging import TMMetricLoggingStrategyFactory
 from tripmaster.core.components.operator.strategies.model_selection import BestOneModelSelectionStrategy
-from tripmaster.core.concepts.component import TMConfigurable, TMSerializableComponent
-from tripmaster.core.concepts.contract import TMContractChannel
-from tripmaster.core.concepts.data import TMDataStream, TMDataLevel, TMMultiDataStream
-
-from tripmaster.core.concepts.operator import TMOperatorInterface
-from tripmaster.core.components.operator.strategies.distributed import TMDistributedStrategyFactory
-
-from tripmaster.core.components.operator.strategies.metric_logging import TMMetricLoggingStrategyFactory
-from tripmaster.core.concepts.contract import TMContractChannel
 from tripmaster.core.components.operator.strategies.optimization import EpochwiseLRUpdateStrategy
-
-from tripmaster.core.concepts.data import TMDataStream, TMDataLevel
-
-from tripmaster import logging
+from tripmaster.core.concepts.component import TMConfigurable
+from tripmaster.core.concepts.data import TMDataStream
+from tripmaster.core.concepts.operator import TMOperatorInterface
 from tripmaster.core.concepts.scenario import TMScenario
-from tripmaster.utils.stream import isolate_iterators
-from tqdm import tqdm
-from tripmaster import P, T, M, D
-
 
 logger = logging.getLogger(__name__)
 
 
 def deep_merge_dict(dict1, dict2):
     """
     merge fields in dict2 into dict1
@@ -73,14 +57,15 @@
 
 
     def runtime(self, runtime_options):
 
         self.select_distributed_strategy(runtime_options)
         self.build_operator_modeler(runtime_options)
         self.select_metric_logging_strategy(runtime_options)
+
     def build_operator_modeler(self, runtime_options):
 
         if self.machine.DataTraits and self.machine.DataTraits.SAMPLE_OOM_POSSIBLE:
             resource_limit = runtime_options.resource.memory.learning_memory_limit
         else:
             resource_limit = None
 
@@ -322,15 +307,14 @@
                 parameters,
                 self.Optimizer[name], self.algorithm_params[name],
                 self.LRScheduler[name], self.lr_scheduler_params[name],
                 self.gradient_clip_val
             )
 
     def test(self, test_config):
-
         self.optimization_strategy.test(test_config)
 
     def eval_and_select_model(self, train_batchstreams: TMDataStream, local_rank, epoch, step):
 
         # if local_rank != 0:
         #     return
```

## tripmaster/core/components/operator/reinforce.py

```diff
@@ -176,20 +176,19 @@
             for batch_env in batch_env_pool.envs():
                 truth = batch_env.truth()
                 if truth is not None:
                     truth = self.host.reallocate_data(truth, local_rank)
 
                 try:
                     observations, accumulated_rewards, batch_mask = self.host.play_once(batch_env, self.host.device(local_rank))
-                    ic(accumulated_rewards)
+
                     avg_reward = sum(accumulated_rewards) / batch_env.batch_size()
                     eval_env_nums += batch_env.batch_size()
 
                     observations.update(truth)
-                    ic(avg_reward)
                     yield {"objective": avg_reward, "sample_num": batch_env.batch_size()}, truth, observations
 
                     if self.hyper_params.eval_env_nums and eval_env_nums >= self.hyper_params.eval_env_nums:
                         break
 
                 except RuntimeError as e:
                     if 'out of memory' in str(e):
@@ -197,16 +196,14 @@
                         logger.error(f"Out of Memory: Data Shapes = {shapes}")
                     logger.exception(e)
                     raise e
                 except Exception as e:
                     logger.exception(e)
                     raise e
 
-        ic("eval_envs finished")
-
     def evaluate(self, batch_env_pool: TMEnvironmentPool, local_rank, epoch, step):
 
         # if local_rank != 0:
         #     return
 
         batch_env_pool.scenario = TMScenario.Evaluation
```

## tripmaster/core/components/operator/supervise.py

```diff
@@ -71,14 +71,15 @@
         machine_samplestream = self.batch_modeler.reconstruct_datastream(machine_batchstream,
                                                                          scenario=self.scenario)
 
         return machine_samplestream
 
 
 
+
 class TMSupervisedEvaluatorMixin(TMEvaluatorMixin):
     """
     TMSupervisedEvaluatorMixin
     """
     def __init__(self, hyper_params,  **kwargs):
         super().__init__(hyper_params, **kwargs)
 
@@ -100,15 +101,18 @@
 
         with P.OptimizerBehaviors.no_grad():
             for i, truth in tqdm(enumerate(data_loader)):
                 # measure data loading time
 
                 try:
                     truth = self.reallocate_data(truth, local_rank)
-                    inferenced = self.machine.forward_with_validation(truth, scenario=TMScenario.Evaluation)
+
+                    self.machine.validate_forward_input(truth, scenario=TMScenario.Evaluation)
+                    inferenced = self.machine.forward(truth, scenario=TMScenario.Evaluation)
+                    self.machine.validate_forward_output(inferenced, scenario=TMScenario.Evaluation)
 
                     # truth.update(inferenced)  # sometimes the truth is constructed by machine
                     # for key in truth:
                     #     if key.endswith("_id") or key.endswith("_uri") or key == "uri":
                     #         inferenced[key] = truth[key]
                     #     if key not in inferenced:
                     #         inferenced[key] = truth[key]
@@ -239,17 +243,17 @@
                     #               logger.warning(f"batch size = {batch_size}") #, hyper_param == {self.hyper_params}, world_size = {self.world_size}")
 
                     # if training_setting.parallel == "dp" and world_size * 2 > batch_size:
                     #     duplicate_num = (world_size * 2 + (batch_size - 1)) // batch_size
                     #     logger.warning(
                     #         f"we are repeating {duplicate_num} times of small batch with size {batch_size} for dp ")
                     #     batch_traits.duplicate(batch, duplicate_num)
-
-                    output = self.machine.forward_with_validation(batch, scenario=TMScenario.Learning)
-                    
+                    self.machine.validate_forward_input(batch, scenario=TMScenario.Learning)
+                    output = self.machine.forward(batch, scenario=TMScenario.Learning)
+                    self.machine.validate_forward_input(output, scenario=TMScenario.Learning)
                     # batch.update(output)  # sometimes the truth is generated by machine
                     # deep_merge_dict(batch, output)
                     loss = self.machine.loss(output, batch)
 
                     reduced_loss = self.distributed_strategy.sync_loss(loss)
 
                     self.optimization_strategy.on_batch_end(self.machine, output, reduced_loss, i)
@@ -369,30 +373,35 @@
         assert batch_stream.level == TMDataLevel.Batch, f"wrong data level, {batch_stream.level}"
 
         # memory_stream = self.fit_memory(machine_stream)
         # batch_stream = self.batchify(memory_stream)
 
         self.distributed_strategy.run(train_worker, batch_stream, runtime_options)
 
+    def test(self, config):
+        TMSupervisedLearnerMixin.test(self, config)
+
+
 
 def predict_worker(local_rank, predictor, data_streams, runtime_options):
     """
 
     Args:
         local_rank ():
         learner ():
         data_streams ():
         evaluator ():
 
     Returns:
 
     """
     logger.warning(f"start inference {local_rank}")
-    D.set_device(local_rank)
-    return predictor.inference(local_rank, data_streams, runtime_options)
+
+    result = predictor.inference(local_rank, data_streams, runtime_options)
+    return result
 
 
 def remove_tensor(data):
     if isinstance(data, dict):
 
         for key in list(data.keys()):
 
@@ -420,40 +429,46 @@
     """
     TMLearner
     """
 
     def __init__(self, hyper_params, machine, states=None):
         super().__init__(hyper_params, machine, scenario=TMScenario.Inference, states=states)
 
+    def inference_batch(self, batch, local_rank):
+
+        batch_traits = self.machine.BatchTraits
+
+        batch = self.reallocate_data(batch, local_rank)
+        batch_size = batch_traits.batch_size(batch)
+
+        inferenced = self.machine.forward(batch, scenario=TMScenario.Inference)
+        deep_merge_dict(inferenced, batch)
+        yield inferenced
+
     def inference_channel(self, local_rank, data_loader):
         """
 
         Args:
             local_rank:
             data_loader:
 
         Returns:
 
         """
-
-        batch_traits = self.machine.BatchTraits
-
         P.OptimizerBehaviors.set_inference_mode(self.machine)
 
         with P.OptimizerBehaviors.no_grad():
             for i, batch in tqdm(enumerate(data_loader)):
                 try:
-                    batch = self.reallocate_data(batch, local_rank)
-                    batch_size = batch_traits.batch_size(batch)
 
-                    inferenced = self.machine.forward(batch, scenario="inference")
-                    deep_merge_dict(inferenced, batch)
-                    yield inferenced
+                    yield from self.inference_batch(batch, local_rank)
 
                 except Exception as e:
+
+                    batch_traits = self.machine.BatchTraits
                     shapes = batch_traits.shape(batch)
                     logger.error(f"Learn for {i}-th Batch, Data Shapes = {shapes}")
                     raise e
 
     def inference(self, local_rank, predict_batchstreams: TMDataStream, runtime_options):
         """
 
@@ -468,55 +483,58 @@
             task_evaluator ():
             learn_conf ():
 
         Returns:
 
         """
 
-        inference_setting = self.hyper_params.inference
 
         self.local_rank = local_rank
 
         self.distributed_strategy.init(local_rank)
 
         inference_machine_datastream = TMDataStream()
         inference_machine_datastream.level = TMDataLevel.Batch
         inference_machine_datastream.inference_channels = predict_batchstreams.inference_channels
 
         for channel in predict_batchstreams.inference_channels:
+
             inference_machine_datastream[channel] = self.inference_channel(local_rank, predict_batchstreams[
                 channel])  # why cannot it step into the predict_channel function.
 
+
         return inference_machine_datastream
 
     def operate(self, machine_stream: TMDataStream, runtime_options):
         """
 
         Args:
             problem ():
             raw ():
             problem_modeler ():
 
         Returns:
 
         """
 
+        self.runtime_options = runtime_options
+
         assert runtime_options.distributed.lower() != "ddp", "Inference does not support DDP"
 
         # logger.info(f"operate with parameter {runtime_options}")
-        assert machine_stream.level == TMDataLevel.Machine, f"wrong data level, {machine_stream.level}"
+        assert machine_stream.level == TMDataLevel.Batch, f"wrong data level, {machine_stream.level}"
 
-        memory_stream = self.fit_memory(machine_stream)
-        batch_stream = self.batchify(memory_stream)
-        infered_batchstream = self.distributed_strategy.run(predict_worker, batch_stream, runtime_options)
+        # memory_stream = self.fit_memory(machine_stream)
+        # batch_stream = self.batchify(memory_stream)
+        infered_batchstream = self.distributed_strategy.run(predict_worker, machine_stream, runtime_options)
 
-        infered_memory_stream = self.unbatchify(infered_batchstream)
-        infered_machine_stream = self.unfit_memory(infered_memory_stream)
+        # infered_memory_stream = self.unbatchify(infered_batchstream)
+        # infered_machine_stream = self.unfit_memory(infered_memory_stream)
 
-        return infered_machine_stream
+        return infered_batchstream
```

## tripmaster/core/components/operator/strategies/model_selection.py

```diff
@@ -47,14 +47,82 @@
 
 @dataclass
 class HotpotSelectedModelInfo(SelectedModelInfo):
     hotpot: bool = True
     cur_best: bool = False
 
 
+class LatestModelSelectionStrategy(TMModelSelectionStrategy):
+    """
+    LatestModelSelectionStrategy
+    """
+
+    Name = "latest"
+
+    def __init__(self, hyper_params):
+
+        super().__init__(hyper_params)
+
+        self.latest_model_path = None
+
+        self.prev_model_name = None
+
+#        signal(TMEvaluationSignals.ON_PROBLEM_STREAM_EVALUATED).connect(self)
+#        signal(TMEvaluationSignals.ON_TASK_STREAM_EVALUATED).connect(self)
+
+    def select_model(self, results, machine, learner):
+
+
+        if result.local_rank == 0:
+            import os
+            if self.prev_model_name:
+                os.remove(self.prev_model_name + ".model.pt")
+                #    os.remove(self.prev_model_name + ".trainer.pt")
+
+
+            logger.warning(f"latest model found, saving... ")
+
+            model_info = SelectedModelInfo(
+                prefix=self.hyper_params.prefix,
+                stage=self.hyper_params.stage,
+                metric=self.hyper_params.metric,
+                channel=self.hyper_params.channel,
+                perf=self.cur_best_perf,
+                epoch=result.epoch,
+                step=result.step,
+            )
+            if self.hyper_params.id_pattern:
+                model_info.id_patten = self.hyper_params.id_pattern
+
+            file_name = model_info.id_patten.format(prefix=model_info.prefix, stage=model_info.stage,
+                                                    channel=model_info.channel,
+                                         metric=model_info.metric, perf=model_info.perf,
+                                         epoch=model_info.epoch, step=model_info.step)
+
+            self.latest_model_path = file_name + ".model.pt"
+            machine.serialize(path=self.latest_model_path)
+            yield model_info
+#                file_name = f"{self.hyper_params.save_prefix}-epoch={result.epoch}-{metric}={self.cur_best_perf}"
+
+
+                #torch.save({
+                #    'state_dict': self.learner.machine.state_dict(),
+                #    TMMachine.HYPER_PARAMS_KEY: self.learner.machine.hyper_params
+                #}, file_name + ".model.pt")
+
+#                torch.save({
+
+#                    'optimization': trainer.optimization.state_dict(),
+#                    'lr_sheduler': self.lr_scheduler.state_dict(),
+#                    'best_perf': {metric: self.cur_best_perf}
+#                }, file_name + ".trainer.pt")
+
+                # self.prev_model_name = file_name
+
+
 class BestOneModelSelectionStrategy(TMModelSelectionStrategy):
     """
     TMModelSelectionStrategy
     """
 
     Name = "best_one"
 
@@ -79,17 +147,20 @@
         self.prev_model_name = None
 
 #        signal(TMEvaluationSignals.ON_PROBLEM_STREAM_EVALUATED).connect(self)
 #        signal(TMEvaluationSignals.ON_TASK_STREAM_EVALUATED).connect(self)
 
     def select_model(self, results, machine, learner):
 
-        result = results[self.hyper_params.stage]
+        if self.hyper_params.stage not in results:
+            raise Exception(f"the stage {self.hyper_params.stage} not in evaluation results {results.keys()}")
 
 
+        result = results[self.hyper_params.stage]
+
         perf = result.performance
 
         channel = self.hyper_params.channel
         if channel not in perf:
             raise Exception(f"the channel {channel} not in evaluation metrics {perf.keys()}")
 
         perf = perf[self.hyper_params.channel]
```

## tripmaster/core/concepts/data.py

```diff
@@ -154,14 +154,17 @@
     def level(self):
         return self.__level
 
     @level.setter
     def level(self, level):
         self.__level = level
 
+        for channel in self.channels:
+            self[channel].level = level
+
     @property
     def channels(self):
         return self.__channels.keys()
 
     @property
     def learn_channels(self):
         return self.hyper_params.channels.learn if self.hyper_params.channels.learn else []
```

## tripmaster/core/system/supervise.py

```diff
@@ -59,17 +59,16 @@
             input_datastream = self.operator.fit_memory(input_datastream)
             input_datastream = self.operator.batchify(input_datastream)
 
             # CAUTION !!! do not delete this line !!!
             # We need the dummy_ref to make the system copied to child process in ddp
             self.operator.dummy_ref = self.evaluate_callback
 
-            self.operator.evaluate_signal.connect(self.evaluate_callback)
-
             if self.is_learning():
+                self.operator.evaluate_signal.connect(self.evaluate_callback)
                 self.operator.good_model_discovered_signal.connect(
                     self.better_model_discovered)
 
             result = self.operator.operate(input_datastream, runtime_options)
 
             if not self.is_learning():  # result is the inferenced machine stream
```

## tripmaster/core/system/system.py

```diff
@@ -25,15 +25,15 @@
 from tripmaster.core.system.validation import TMSystemValidator
 from tripmaster.utils.function import return_none
 
 from tripmaster.utils.profile_support import profile
 
 from collections import OrderedDict
 from tripmaster.core.app.config import TMConfig
-import addict
+
 import os
 logger = logging.getLogger(__name__)
 
 
 #
 # class TMSystemSignal(object):
 #
@@ -543,20 +543,21 @@
 
             self.task_evaluating_strategy.on_evaluation_begin()
             self.task_evaluating_strategy.on_stream_inferenced(task_inference_info)
 
             last_inference_info = task_inference_info
             last_strategy = self.task_evaluating_strategy
 
-        for channel in last_inference_info.truth_stream.eval_channels:
-            truth_channel = last_inference_info.truth_stream[channel]
-            inference_channel = last_inference_info.inferenced_stream[channel]
-            for truth, inference in zip(truth_channel, inference_channel):
-                # consume the stream, and actually run the pipeline
-                pass
+        if last_inference_info:
+            for channel in last_inference_info.truth_stream.eval_channels:
+                truth_channel = last_inference_info.truth_stream[channel]
+                inference_channel = last_inference_info.inferenced_stream[channel]
+                for truth, inference in zip(truth_channel, inference_channel):
+                    # consume the stream, and actually run the pipeline
+                    pass
 
         if self.machine_evaluating_strategy:
             eval_results["machine"] = self.machine_evaluating_strategy.on_evaluation_end(evalation_termination_info)
 
         if self.problem_evaluating_strategy:
             eval_results["problem"] = self.problem_evaluating_strategy.on_evaluation_end(evalation_termination_info)
 
@@ -621,22 +622,21 @@
         inference = not self.is_learning()
         assert input_data_stream.level == TMDataLevel.Machine
         scenario = TMScenario.Learning if not inference else TMScenario.Inference
 
         if self.pm_modeler is not None:
             input_data_stream = self.pm_modeler.reconstruct_datastream(
                 input_data_stream, scenario=scenario, with_truth=not inference)
-        elif self.tp_modeler is not None:
+
+        if self.tp_modeler is not None:
             input_data_stream.level = TMDataLevel.Problem
 
             logger.info(f"problem data recovered: ")
-            for channel in input_data_stream.channels:
-                logger.info(f"\t{channel}: {len(input_data_stream[channel])}")
-
-        if self.tp_modeler is not None:
+            # for channel in input_data_stream.channels:
+            #     logger.info(f"\t{channel}: {len(input_data_stream[channel])}")
 
             input_data_stream = self.tp_modeler.reconstruct_datastream(
                 input_data_stream, scenario=scenario, with_truth=not inference)
 
         return input_data_stream
 
     def better_model_discovered(self, info_iter: Union[tuple, SelectedModelInfo]):
```

## tripmaster/plugins/backend/paddle_.py

```diff
@@ -49,15 +49,16 @@
             logger.warning(
                 f"You have request to use multiple gpus, but with Single trainer. Only one of the gpus will be used")
 
     def run(self, func, train_data_streams, runtime_options):
         """
         train_impl
         """
-        return func(0, self.operator, train_data_streams, runtime_options)
+        result = func(0, self.operator, train_data_streams, runtime_options)
+        return result
 
     def init(self, local_rank):
         """
         init_train_loop
         """
 
         if self.use_gpu:
@@ -555,14 +556,15 @@
 
     @classmethod
     def is_device(self, x):
         raise NotImplementedError()
 
     @classmethod
     def set_device(cls, device):
+
         paddle.set_device(device)
 
     @classmethod
     def cuda_available(cls):
         raise NotImplementedError()
         
     @classmethod
```

## tripmaster/plugins/traits/basic.py

```diff
@@ -34,41 +34,45 @@
 class TMTensorElementTraits(TMElementTraits):
 
     ElementType = (np.ndarray, T.is_tensor)
 
     @classmethod
     def collate(self, list_of_samples):
 
+        ndim = max([x.ndim for x in list_of_samples])
         first_elem = list_of_samples[0]
         # if isinstance(first_elem, np.ndarray):
         #     list_of_samples = [T.to_tensor(b) for b in list_of_samples]
         
         shapes = [list(x.shape if isinstance(x, np.ndarray) else T.shape(x)) for x in list_of_samples]
-
-        max_shape = tuple([max(x[i] for x in shapes) for i in range(first_elem.ndim)])
-    
+        shapes = [x + [0] * (ndim - len(x)) for x in shapes]
+        max_shape = tuple([max(x[i] for x in shapes) for i in range(ndim)])
 
         for idx, b in enumerate(list_of_samples):
             this_shape = b.shape if isinstance(b, np.ndarray) else T.shape(b)
             if tuple(this_shape) == max_shape:
-                continue 
-                
-            if isinstance(first_elem, np.ndarray):
-                pad = [(0, max_shape[i] - this_shape[i]) for i in range(b.ndim)]
+                continue
+
+            if len(this_shape) < ndim:
+                this_shape = list(this_shape) + [0] * (ndim - len(this_shape))
+                b = b.reshape(this_shape)
+
+            if isinstance(b, np.ndarray):
+                pad = [(0, max_shape[i] - this_shape[i]) for i in range(ndim)]
                 b = np.pad(b, pad)
             else:  # is tensor 
 
-                dim_order = range(first_elem.ndim - 1, -1, -1)
+                dim_order = range(ndim - 1, -1, -1)
 
                 pad = [[0, max_shape[i] - this_shape[i]] for i in dim_order]
                 pad = sum(pad, [])
                 b = T.pad(b, pad, 0)
 
             list_of_samples[idx] = b
-        
+
         if isinstance(first_elem, np.ndarray):
             result = T.to_tensor(np.stack(list_of_samples, 0))
         else:
             result = T.stack(list_of_samples, 0)
         return result
 
 
@@ -142,19 +146,22 @@
         assert isinstance(batched_data, dict)
 
         batch_size = cls.batch_size(batched_data)
 
         unbatched_data = collections.defaultdict(list)
 
         for key in batched_data.keys():
-            try:
-                traits = TMElementTraitsFactory.get().get_element_batch_traits(batched_data[key])
-                unbatched_data[key] = traits.decollate(batched_data[key])
-            except UnsupportedTraitsError as e:
-                unbatched_data[key] = batched_data[key]
+            if batched_data[key] is None:
+                unbatched_data[key] = [None] * batch_size
+            else:
+                try:
+                    traits = TMElementTraitsFactory.get().get_element_batch_traits(batched_data[key])
+                    unbatched_data[key] = traits.decollate(batched_data[key])
+                except UnsupportedTraitsError as e:
+                    unbatched_data[key] = batched_data[key]
 
         result_list = list()
         key_list = list(batched_data.keys())
 
         for sample in zip(*(unbatched_data[key] for key in key_list)):
             result_list.append(dict(zip(key_list, sample)))
```

## Comparing `tripmaster-1.0.2.dist-info/LICENSE` & `tripmaster-1.0.3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `tripmaster-1.0.2.dist-info/METADATA` & `tripmaster-1.0.3.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tripmaster
-Version: 1.0.2
+Version: 1.0.3
 Summary: A High Level Framework for Deep Learning App and Pipelines for Paddle.
 Home-page: https://github.com/baidu-research/tripmaster
 Author: Mingming Sun
 Author-email: sunmingming01@baidu.com
 License: Apache
 Keywords: Deep Learning,Framework,Pipelines
 Description-Content-Type: text/markdown
```

## Comparing `tripmaster-1.0.2.dist-info/RECORD` & `tripmaster-1.0.3.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,90 +1,90 @@
 tripmaster/__init__.py,sha256=iYCOpjCOFdPW4KItbmM06dw-GdBqOWOJtMhxek3aMD4,249
 tripmaster/core/__init__.py,sha256=ajz1GSNU9xYVrFEDSz6Xwg7amWQ_yvW75tQa1ZvRIWc,3
 tripmaster/core/app/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-tripmaster/core/app/config.py,sha256=6V78nmwsAOvWG8Ap4IigVPYyZj5cl8-WvUIKS0ps2R8,6108
+tripmaster/core/app/config.py,sha256=RxOoe6ajTVMuTMC4Hn_vejZdLmJlEMP1BtmmNz4et-Q,6114
 tripmaster/core/app/io.py,sha256=FPLAH5wUydwZWu9VetI6iAXc5461PBYFRLcPUJU9tyU,2334
 tripmaster/core/app/pipeline.py,sha256=8B6r5HJYuVUS5kmurpK6VjWO22Hw0i2RYD8AeoTXkS8,2678
 tripmaster/core/app/reinforce.py,sha256=W0Cn31iqmmwyQF4WPCB0zdkBTZaHvdXcB9nCoeHCK_U,3347
-tripmaster/core/app/standalone.py,sha256=DKvvZkUUX-LMI7WgLVR2h_awwZvbHUyHVUphJalGsEI,5813
+tripmaster/core/app/standalone.py,sha256=WwIVgMCXbejNR2kXsF313aXkRx8cCLwFxAPgWIDYvUQ,5965
 tripmaster/core/app/supervise.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/components/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/components/backend.py,sha256=LmLo8cb1o0hu1Ri9gAWhdlKtoQUjob2facpG07IDWd0,4572
 tripmaster/core/components/contract.py,sha256=6vRxYGdBLyKNJw89OzdJO9mJ-1CHp2ERvFwoBzx89j4,11741
 tripmaster/core/components/evaluator.py,sha256=msPO6M2-1mXgN6Mvhh33AGM2ElxqeQ7a2r4oaFTd9aM,27131
 tripmaster/core/components/loss.py,sha256=Gx_SrdW43xdMT5ntjy2RFHYYny6NU1V7yGclMjB4S3E,11251
 tripmaster/core/components/problem.py,sha256=dBU4Jr3kyBCMG8h06IWSyKaWhrfw82OApZb8w0ZkK6c,2901
 tripmaster/core/components/repo.py,sha256=UeDHg_ix9RT0Z6B_sIEHeqtskTcM0I2cPPLI7GEMyIw,6415
 tripmaster/core/components/task.py,sha256=BNVcTFeXdzH1mZn9CdUI-gqkoLnYGgkrkNE9gl6JMe8,2962
 tripmaster/core/components/environment/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/components/environment/base.py,sha256=Je5wjPx5Ku_xcy5UO0LTfQB08XoAp2Ee0zn4IrEQnRU,6891
 tripmaster/core/components/environment/supervised.py,sha256=GW2PWYvQdqYVBqzpOddHBfeJUofakzcrHBdiBUnU0ek,8408
 tripmaster/core/components/machine/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/components/machine/data_traits.py,sha256=iDqXKyUErdGv8L-t-r_4g48mdLKodjBvedYG5x5q8o8,14038
-tripmaster/core/components/machine/machine.py,sha256=MV2HSdvuJtbqOM24KgCvemwbSKaR7pBrlGccvUP4g3o,12501
+tripmaster/core/components/machine/machine.py,sha256=7_9Q9ZzFDGwBhVLf1RL34n7nD-AMEX0DfvtC-TjAopA,12650
 tripmaster/core/components/machine/reinforce.py,sha256=MdNoprSWPtahAhVk4Ogdwy14E_7aYAktzkrAj6fT1N8,996
 tripmaster/core/components/modeler/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/components/modeler/machine_memory.py,sha256=_AABiwekJh1iZSZrEgMZBpnFggp2NzN9u-NUNCJxNtc,2583
 tripmaster/core/components/modeler/memory_batch.py,sha256=sEYCLhANrFco2xh0wyUg6bju2bwgXBHmeAEW1r4W3Zg,6639
-tripmaster/core/components/modeler/modeler.py,sha256=sCrxTnYDYdj5sXJK6Y8sZEYTlExZktW0XGRsm5IGCkI,18909
+tripmaster/core/components/modeler/modeler.py,sha256=fAMHxyi2LVADOtPR6uAs9PBvEH6kztp6HcqV2_glp70,19207
 tripmaster/core/components/operator/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/components/operator/multi_task.py,sha256=LJBHCJ3VJxiPpC1XUAKCTBXFKtDbXPLlLVpc27bUAik,5294
-tripmaster/core/components/operator/operator.py,sha256=Ok_OMK9KwACxMDnDoips8PiJYZkDh4HDBxsmvSn7PI0,13480
-tripmaster/core/components/operator/reinforce.py,sha256=J8I-NFFLhUb2fhGFOsxLCGU2_lR3oBpn0JiGk894c-k,16179
-tripmaster/core/components/operator/supervise.py,sha256=Y66yIghqlMCiesBJqgWpUqZToASXbVHeF9XqZATOr_I,18259
+tripmaster/core/components/operator/operator.py,sha256=6uJExBRCFIjK_m290_28WvYGHc7hX9jNxXEJ14qSQKU,12786
+tripmaster/core/components/operator/reinforce.py,sha256=y4xKNLZ59tiB4ZuDfmAl7mZTZO8KlC6gFsujlMY4x6c,16067
+tripmaster/core/components/operator/supervise.py,sha256=DGHRS01lkBUIUTgJ-cuI1TLw5_F_lwJSLGyy7F73ajw,18796
 tripmaster/core/components/operator/strategies/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/components/operator/strategies/batching.py,sha256=5u9BfUzeqadfdUNtgAypjlnVOTwXEErKYD3New1cwXc,896
 tripmaster/core/components/operator/strategies/distributed.py,sha256=XuJ9PsRLNa5sm3erklsuAcX_Disulf0XhnhYX-rXEyk,1272
 tripmaster/core/components/operator/strategies/event_trigger.py,sha256=XJ_RbSqF3AzkeA-rfB5Idh3xffPPBDy5HH01Uzx44j8,1635
 tripmaster/core/components/operator/strategies/exploration_strategy.py,sha256=Ay-_m7KDW8QXR2pKiV66qR_jGyNhB7lPT7DgXEnXgwU,4521
 tripmaster/core/components/operator/strategies/metric_logging.py,sha256=P6GDPJKlf8nIg5PrMNTDawWSqST6aFwceYvFSKjfFMU,1082
-tripmaster/core/components/operator/strategies/model_selection.py,sha256=htx6bxERxDvUyoFuSd6_0U7rAS31nkmhVHIDtAs61fE,14307
+tripmaster/core/components/operator/strategies/model_selection.py,sha256=CvXKhxBNWX9xmkTKFxzCdeBnwFR_qWI5IMCN64bf_nI,16929
 tripmaster/core/components/operator/strategies/optimization.py,sha256=HetJg2XPZhifxmHLXrRKTH7f80JXcYZq5oWcEwX_j3c,7487
 tripmaster/core/concepts/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/concepts/component.py,sha256=i5eTKRCzCu-zyK-zPzM4QsQtocIdYY83dfN-nMaxpTI,16055
 tripmaster/core/concepts/contract.py,sha256=l9csDtejpUSdd_6DvQ7voWe8KiVptYtfzSxat2YvJGE,5996
-tripmaster/core/concepts/data.py,sha256=Agyt5MKKpov49aEVEmRpZSo0j3QItskIZK_eWKudV8Y,10576
+tripmaster/core/concepts/data.py,sha256=dW2iDB19XVLJEhZimYRDkcI8S6KNqeRbRoNPHVGlWAU,10655
 tripmaster/core/concepts/evaluator.py,sha256=uPfykwCHquBsSxEh6ee5tjtEQU7YXCElitcpJfRfFVI,3670
 tripmaster/core/concepts/hyper_params.py,sha256=SqEwvNiWAt2FMD1e4_XmkZBifzzAAvXcaztY8_bU0Hc,470
 tripmaster/core/concepts/loss.py,sha256=O_F68_Y6SluazjRRp5dB0tIn6EA3sxPQLG0utfW967Y,479
 tripmaster/core/concepts/machine.py,sha256=SEH-rmVRO7xJOSHn3PWr5h5Br_qGG-bfKiIaWqGaw7s,375
 tripmaster/core/concepts/modeler.py,sha256=BmEQ6yL9fULLtDP3bFSE0lMDtTE_9lQGLddWAcaQjYk,3782
 tripmaster/core/concepts/operator.py,sha256=Gr40avVoA4gThJJ_v97OActOfCbOtfcuDWjNSBgYVzQ,894
 tripmaster/core/concepts/scenario.py,sha256=0Qhk6aeh_9ZmbZcd7bd1nXWUDkZfig-OnVSxMQf3A7k,990
 tripmaster/core/concepts/schema.py,sha256=Gvsf3lAB0ET50omCN13mNhQ9rEB1vJha2QXXthpsTOs,3197
 tripmaster/core/launcher/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/launcher/job.py,sha256=I4SYoFBPHXLRRiQ4vgGF8o6GGeyXhi0WHxZyve0Wbvw,6326
 tripmaster/core/launcher/launcher.py,sha256=H_zDvyRcyFtzjQYKQ6M8h8Qf-Y_Yw40EpIsUPBDqc5M,3085
 tripmaster/core/system/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/system/reinforce.py,sha256=SFRQuTLv1ZtL9JVPulhkX_VcozUVPqcRkRSzxZOUxqU,3133
-tripmaster/core/system/supervise.py,sha256=1FJS8FLmr9g1b8IJR68BWZx9gTPrAucZXT9vs6vo86U,2655
-tripmaster/core/system/system.py,sha256=h2Av-hM2u7v1ZRNWWHX_mw37d6HA1R5L1E3NPadF_h4,34448
+tripmaster/core/system/supervise.py,sha256=CidS6RoQnsE5NfdwIa__Xqu3-bxwSc7Lvt2F5wu3f6M,2658
+tripmaster/core/system/system.py,sha256=Oz6o37vMrHVvxn_bpRw8qH1yZ8aoUzGtKuyhbyor178,34453
 tripmaster/core/system/validation.py,sha256=zzAtTHno-Wxf583Fleb5Wk-lhBETYKjgJqbYU_OE2dI,6326
 tripmaster/core/system/test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/system/test/test_multi.py,sha256=t2E9935sUhQFZ3mlDVphvFgIr9rLBZyEZChaSLx_wlE,268
 tripmaster/core/test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/core/test/test_generic.py,sha256=_QFbahiMgY5KV_lnuGDinSI3foR_LFFIbpkQBaPyaDo,2273
 tripmaster/plugins/__init__.py,sha256=jqFHp4HGB8CZKoF19vIagodw0rfHIdmxUzqyj_1N46g,142
 tripmaster/plugins/load.py,sha256=ETI9RFghmBWfqBLd2_mrwftzEFw5wm-HqOCD3AF5k3M,985
 tripmaster/plugins/backend/__init__.py,sha256=0pfqGVPttLmODn0aU8b-RDpkMo4ilkVxDStRm4tbanY,1262
-tripmaster/plugins/backend/paddle_.py,sha256=XYcNhUazKGbYduycVTRoE1GeWZPRkvBqFP7aE67DE-Y,17985
+tripmaster/plugins/backend/paddle_.py,sha256=FHxHZBu7_1eTViMHseYmGiQndkmZeSDxfFqGhSHD_k4,18010
 tripmaster/plugins/backend/torch_.py,sha256=-8Xz2eXZywSQtSm_Y6xh8U3IgL0tibn0icIg5C-g0sU,15364
 tripmaster/plugins/batching/__init__.py,sha256=fIDuWNF_0H0FWwU1xDDpBYoYSrwG2dTGMtSD8VRCiM0,298
 tripmaster/plugins/batching/fixed_size.py,sha256=ECPTrf3iLMNcFc-_tzBlGADrDhFYNfDxT4aqbCyjIQs,831
 tripmaster/plugins/batching/resource_limit.py,sha256=i07aZ4s3YJw9P1F2dtFIUp-NPMrA4VUgnyERqp7u_Zs,11702
 tripmaster/plugins/distributed/__init__.py,sha256=8MJqtVN5O6xVxKO_gUx2dum6fZ1Bg8QitnXjxpcJMxo,900
 tripmaster/plugins/launch/__init__.py,sha256=8AmPUoFBh_8CY32XJ4uPGLceSq1Hbqo71HZaZWeLjtU,249
 tripmaster/plugins/launch/gpucluster.py,sha256=MTOrYKGvaGMJP5chEJ8Oxwl1RQVAmcXgJWbrBC98zm4,17557
 tripmaster/plugins/launch/local.py,sha256=NHXPZt21MGHd-FXHOACAxOsH3Dt6GH_aWgGzmnqFmoE,301
 tripmaster/plugins/launch/paddlecloud.py,sha256=2zCp4TIjRZDnL0gqE_36wlsSBIXy-a6XSr1cWSIITUA,16371
 tripmaster/plugins/metric_logging/__init__.py,sha256=g0s1sFMZ6jHDkwOl1wm6NBpU2L3Szg36u_fMZBxxODA,353
 tripmaster/plugins/metric_logging/tableprint.py,sha256=DlXCCnchaEocfFP8uebo0TqNo0nat_b526NhhASo864,2519
 tripmaster/plugins/metric_logging/tensorboard.py,sha256=ewbcuWv6fT0nY7sWQDJEBrpXPSnc2__JuLij3n6J3Jg,2734
 tripmaster/plugins/traits/__init__.py,sha256=5BiK12gAVFJw0OT2Nu0QWrsqhXvgDCqCWLJaTpPd1K4,417
-tripmaster/plugins/traits/basic.py,sha256=iN8f9v8_HYCVnrPEy4EdrzKJag6KgmpPqJdtFzKEhFI,6519
+tripmaster/plugins/traits/basic.py,sha256=Z49XElzjZyP_VPoeCxg9ZKS_7HBAfXzEF9I51OGRrpY,6869
 tripmaster/plugins/traits/dataclass.py,sha256=SJ7GTZHGdUDU0mVWEJzT6Heo6ODXGokh8M2sQLCPdZw,3076
 tripmaster/plugins/traits/dgl.py,sha256=H5Ufsm1QPHoN42OWHS4KyG-CGCDDjM72DVsO-7tRWDg,1018
 tripmaster/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tripmaster/utils/data.py,sha256=0CKkWtIemw5FFaX6eEsMdxvgHTQL9VWfFZraSllk3XM,496
 tripmaster/utils/enum.py,sha256=eGzQ9pjgKuVY2lVUBdCDWjI-TRSV3p0wzC6DLa5PyiM,153
 tripmaster/utils/function.py,sha256=bwPLQ1HA2WJrML8CHI2ThSMHeCER2PfS2R-UA9toAe4,90
 tripmaster/utils/profile_support.py,sha256=kyfRu0ykYtslDpwfxOsgdWwzvZO20VLooyu1o_KixAE,166
@@ -94,12 +94,12 @@
 tripmaster/utils/logging/__init__.py,sha256=wcvOBO8BH8xNs0KiMp1foAsu5wEh5PJKaS2z4fLJgjY,49
 tripmaster/utils/logging/capture.py,sha256=PpB759dRHLOUDNCJQxw1_aBPYrOTl78frnDDJVltR-k,1982
 tripmaster/utils/logging/config.yaml,sha256=IApV4PVZYOmxP_tpqM5DAL-IAngkc7RslwsvDbJ2i0w,1369
 tripmaster/utils/logging/core.py,sha256=wPOX9boLYlhh3NOxtgP9MpOgtuRK4mwOBigQBDTEx9c,11217
 tripmaster/utils/logging/inspector.py,sha256=cl7_P1mMJdpnugebK5tyNjv8DBaGpb3xsK3ynB3Zuog,7389
 tripmaster/utils/logging/logger.py,sha256=paz1R6JYp7cz6IoOMcbm7JRYXIj0-aRIvoOQaVpINiw,8502
 tripmaster/utils/logging/logging.py,sha256=NNFjOQpOlQzczetyj8MIxqayaWZyEW731vDimKBUNc4,3483
-tripmaster-1.0.2.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-tripmaster-1.0.2.dist-info/METADATA,sha256=tsFpVdqKiX-DwI_TB-7Am-F8B2g7Z4OIByfTxlfqBbU,879
-tripmaster-1.0.2.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-tripmaster-1.0.2.dist-info/top_level.txt,sha256=maHIEfa7B54A9-_P0yed19EnIuL2hK_QI3vWPHPlDoI,11
-tripmaster-1.0.2.dist-info/RECORD,,
+tripmaster-1.0.3.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+tripmaster-1.0.3.dist-info/METADATA,sha256=GTFDhZlg5lEIkKn0flfFMOacjxIq2tOyRv-qo9k3Pio,879
+tripmaster-1.0.3.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+tripmaster-1.0.3.dist-info/top_level.txt,sha256=maHIEfa7B54A9-_P0yed19EnIuL2hK_QI3vWPHPlDoI,11
+tripmaster-1.0.3.dist-info/RECORD,,
```

