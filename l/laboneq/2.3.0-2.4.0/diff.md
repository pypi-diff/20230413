# Comparing `tmp/laboneq-2.3.0-py3-none-any.whl.zip` & `tmp/laboneq-2.4.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,241 +1,241 @@
-Zip file size: 940455 bytes, number of entries: 239
--rw-rw-rw-  2.0 unx        5 b- defN 23-Mar-30 07:15 laboneq/VERSION.txt
--rw-r--r--  2.0 unx      306 b- defN 23-Feb-02 07:13 laboneq/__init__.py
+Zip file size: 946465 bytes, number of entries: 239
+-rw-rw-rw-  2.0 unx        5 b- defN 23-Apr-13 09:53 laboneq/VERSION.txt
+-rw-r--r--  2.0 unx      306 b- defN 23-Feb-13 10:47 laboneq/__init__.py
 -rw-r--r--  2.0 unx     2829 b- defN 23-Feb-02 07:13 laboneq/_token.py
 -rw-r--r--  2.0 unx      238 b- defN 23-Feb-02 07:13 laboneq/_version.py
 -rw-r--r--  2.0 unx     1392 b- defN 23-Feb-02 07:13 laboneq/simple.py
 -rw-r--r--  2.0 unx      184 b- defN 23-Feb-02 07:13 laboneq/_observability/__init__.py
 -rw-r--r--  2.0 unx      538 b- defN 23-Feb-02 07:13 laboneq/_observability/tracing/__init__.py
 -rw-r--r--  2.0 unx      893 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_noop_tracer.py
 -rw-r--r--  2.0 unx     2309 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_tracer.py
 -rw-r--r--  2.0 unx      444 b- defN 23-Feb-02 07:13 laboneq/compiler/__init__.py
 -rw-r--r--  2.0 unx      204 b- defN 23-Feb-02 07:13 laboneq/compiler/fastlogging.py
--rw-rw-rw-  2.0 unx    22466 b- defN 23-Mar-24 15:37 laboneq/compiler/qccs-schema_2_5_0.json
+-rw-rw-rw-  2.0 unx    22524 b- defN 23-Apr-06 14:15 laboneq/compiler/qccs-schema_2_5_0.json
 -rw-r--r--  2.0 unx      666 b- defN 23-Feb-02 07:13 laboneq/compiler/remote.py
--rw-r--r--  2.0 unx      654 b- defN 23-Mar-13 16:53 laboneq/compiler/code_generator/__init__.py
--rw-r--r--  2.0 unx    18645 b- defN 23-Mar-13 16:53 laboneq/compiler/code_generator/analyze_events.py
--rw-r--r--  2.0 unx    28581 b- defN 23-Mar-23 16:28 laboneq/compiler/code_generator/analyze_playback.py
--rw-r--r--  2.0 unx    64344 b- defN 23-Mar-30 07:15 laboneq/compiler/code_generator/code_generator.py
--rw-r--r--  2.0 unx     4026 b- defN 23-Mar-23 16:28 laboneq/compiler/code_generator/command_table_tracker.py
--rw-r--r--  2.0 unx     6917 b- defN 23-Mar-30 07:15 laboneq/compiler/code_generator/compressor.py
--rw-r--r--  2.0 unx     1414 b- defN 23-Mar-13 16:53 laboneq/compiler/code_generator/feedback_register_allocator.py
--rw-r--r--  2.0 unx    10355 b- defN 23-Mar-13 16:53 laboneq/compiler/code_generator/interval_calculator.py
--rw-r--r--  2.0 unx    18617 b- defN 23-Mar-13 16:53 laboneq/compiler/code_generator/measurement_calculator.py
--rw-r--r--  2.0 unx    30091 b- defN 23-Mar-30 07:15 laboneq/compiler/code_generator/sampled_event_handler.py
--rw-r--r--  2.0 unx    15940 b- defN 23-Mar-30 07:15 laboneq/compiler/code_generator/seq_c_generator.py
--rw-r--r--  2.0 unx     6160 b- defN 23-Mar-30 07:15 laboneq/compiler/code_generator/seqc_tracker.py
--rw-r--r--  2.0 unx     7741 b- defN 23-Mar-24 08:01 laboneq/compiler/code_generator/signatures.py
--rw-r--r--  2.0 unx     3500 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/utils.py
+-rw-r--r--  2.0 unx      654 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/__init__.py
+-rw-r--r--  2.0 unx    18645 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/analyze_events.py
+-rw-r--r--  2.0 unx    28581 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/analyze_playback.py
+-rw-r--r--  2.0 unx    64112 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/code_generator.py
+-rw-r--r--  2.0 unx     4026 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/command_table_tracker.py
+-rw-r--r--  2.0 unx     2727 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/compressor.py
+-rw-r--r--  2.0 unx     1414 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/feedback_register_allocator.py
+-rw-r--r--  2.0 unx    10355 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/interval_calculator.py
+-rw-r--r--  2.0 unx    18617 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/measurement_calculator.py
+-rw-r--r--  2.0 unx    29598 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/sampled_event_handler.py
+-rw-r--r--  2.0 unx    18104 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/seq_c_generator.py
+-rw-r--r--  2.0 unx     6129 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/seqc_tracker.py
+-rw-r--r--  2.0 unx     7741 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/signatures.py
+-rw-r--r--  2.0 unx     3500 b- defN 23-Mar-02 10:50 laboneq/compiler/code_generator/utils.py
 -rw-r--r--  2.0 unx     1476 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/wave_index_tracker.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/common/__init__.py
--rw-r--r--  2.0 unx     1093 b- defN 23-Mar-13 16:53 laboneq/compiler/common/awg_info.py
--rw-r--r--  2.0 unx     1903 b- defN 23-Mar-13 16:53 laboneq/compiler/common/awg_sampled_event.py
+-rw-r--r--  2.0 unx     1093 b- defN 23-Apr-06 14:15 laboneq/compiler/common/awg_info.py
+-rw-r--r--  2.0 unx     1903 b- defN 23-Apr-06 14:15 laboneq/compiler/common/awg_sampled_event.py
 -rw-r--r--  2.0 unx      480 b- defN 23-Feb-02 07:13 laboneq/compiler/common/awg_signal_type.py
--rw-r--r--  2.0 unx     3983 b- defN 23-Mar-29 07:02 laboneq/compiler/common/compiler_settings.py
+-rw-r--r--  2.0 unx     3983 b- defN 23-Apr-06 14:15 laboneq/compiler/common/compiler_settings.py
 -rw-r--r--  2.0 unx     4547 b- defN 23-Feb-16 12:45 laboneq/compiler/common/device_type.py
 -rw-r--r--  2.0 unx     1532 b- defN 23-Feb-15 13:56 laboneq/compiler/common/event_type.py
 -rw-r--r--  2.0 unx      229 b- defN 23-Mar-07 13:19 laboneq/compiler/common/play_wave_type.py
--rw-r--r--  2.0 unx      580 b- defN 23-Mar-24 08:01 laboneq/compiler/common/pulse_parameters.py
--rw-r--r--  2.0 unx      953 b- defN 23-Mar-29 00:03 laboneq/compiler/common/signal_obj.py
+-rw-r--r--  2.0 unx      580 b- defN 23-Apr-06 14:15 laboneq/compiler/common/pulse_parameters.py
+-rw-r--r--  2.0 unx     2052 b- defN 23-Apr-06 14:15 laboneq/compiler/common/signal_obj.py
 -rw-r--r--  2.0 unx      400 b- defN 23-Feb-02 07:13 laboneq/compiler/common/trigger_mode.py
 -rw-r--r--  2.0 unx      154 b- defN 23-Feb-02 07:13 laboneq/compiler/experiment_access/__init__.py
--rw-r--r--  2.0 unx      222 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/acquire_info.py
--rw-r--r--  2.0 unx      602 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/cache.py
--rw-r--r--  2.0 unx      295 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/device_info.py
--rw-r--r--  2.0 unx    41960 b- defN 23-Mar-24 08:01 laboneq/compiler/experiment_access/dsl_loader.py
--rw-r--r--  2.0 unx    16225 b- defN 23-Mar-30 07:15 laboneq/compiler/experiment_access/experiment_dao.py
--rw-r--r--  2.0 unx    13914 b- defN 23-Mar-24 15:37 laboneq/compiler/experiment_access/json_dumper.py
--rw-r--r--  2.0 unx    20890 b- defN 23-Mar-24 15:37 laboneq/compiler/experiment_access/json_loader.py
--rw-r--r--  2.0 unx     6134 b- defN 23-Mar-24 15:37 laboneq/compiler/experiment_access/loader_base.py
--rw-r--r--  2.0 unx      270 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/marker.py
--rw-r--r--  2.0 unx      260 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/oscillator_info.py
--rw-r--r--  2.0 unx      197 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/param_ref.py
--rw-r--r--  2.0 unx     1263 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/pulse_def.py
--rw-r--r--  2.0 unx    21550 b- defN 23-Mar-14 16:36 laboneq/compiler/experiment_access/section_graph.py
--rw-r--r--  2.0 unx      851 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/section_info.py
--rw-r--r--  2.0 unx     1069 b- defN 23-Mar-23 16:28 laboneq/compiler/experiment_access/section_signal_pulse.py
--rw-r--r--  2.0 unx      387 b- defN 23-Mar-13 16:53 laboneq/compiler/experiment_access/signal_info.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 14:57 laboneq/compiler/new_scheduler/__init__.py
--rw-r--r--  2.0 unx     3133 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/case_schedule.py
--rw-r--r--  2.0 unx     5890 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/interval_schedule.py
--rw-r--r--  2.0 unx     3317 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/loop_iteration_schedule.py
--rw-r--r--  2.0 unx     8531 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/loop_schedule.py
--rw-r--r--  2.0 unx     2016 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/match_schedule.py
--rw-r--r--  2.0 unx     2180 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/oscillator_schedule.py
--rw-r--r--  2.0 unx     1654 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/phase_reset_schedule.py
--rw-r--r--  2.0 unx     1820 b- defN 23-Mar-23 16:28 laboneq/compiler/new_scheduler/preorder_map.py
--rw-r--r--  2.0 unx     3821 b- defN 23-Mar-24 08:01 laboneq/compiler/new_scheduler/pulse_phase.py
--rw-r--r--  2.0 unx     6376 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/pulse_schedule.py
--rw-r--r--  2.0 unx      567 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/reserve_schedule.py
--rw-r--r--  2.0 unx     1404 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/root_schedule.py
--rw-r--r--  2.0 unx      630 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/schedule_data.py
--rw-r--r--  2.0 unx    39182 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/scheduler.py
--rw-r--r--  2.0 unx    12975 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/section_schedule.py
--rw-r--r--  2.0 unx      483 b- defN 23-Mar-29 00:03 laboneq/compiler/new_scheduler/utils.py
+-rw-r--r--  2.0 unx      222 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/acquire_info.py
+-rw-r--r--  2.0 unx      602 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/cache.py
+-rw-r--r--  2.0 unx      349 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/device_info.py
+-rw-r--r--  2.0 unx    42040 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/dsl_loader.py
+-rw-r--r--  2.0 unx    16297 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/experiment_dao.py
+-rw-r--r--  2.0 unx    13923 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/json_dumper.py
+-rw-r--r--  2.0 unx    20960 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/json_loader.py
+-rw-r--r--  2.0 unx     6182 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/loader_base.py
+-rw-r--r--  2.0 unx      270 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/marker.py
+-rw-r--r--  2.0 unx      260 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/oscillator_info.py
+-rw-r--r--  2.0 unx      197 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/param_ref.py
+-rw-r--r--  2.0 unx     1263 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/pulse_def.py
+-rw-r--r--  2.0 unx    21550 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_graph.py
+-rw-r--r--  2.0 unx      851 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_info.py
+-rw-r--r--  2.0 unx     1069 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_signal_pulse.py
+-rw-r--r--  2.0 unx      387 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/signal_info.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 14:48 laboneq/compiler/new_scheduler/__init__.py
+-rw-r--r--  2.0 unx     3269 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/case_schedule.py
+-rw-r--r--  2.0 unx     7443 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/interval_schedule.py
+-rw-r--r--  2.0 unx     3331 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/loop_iteration_schedule.py
+-rw-r--r--  2.0 unx     8588 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/loop_schedule.py
+-rw-r--r--  2.0 unx     7197 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/match_schedule.py
+-rw-r--r--  2.0 unx     2252 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/oscillator_schedule.py
+-rw-r--r--  2.0 unx     1765 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/phase_reset_schedule.py
+-rw-r--r--  2.0 unx     1820 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/preorder_map.py
+-rw-r--r--  2.0 unx     3821 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/pulse_phase.py
+-rw-r--r--  2.0 unx     6962 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/pulse_schedule.py
+-rw-r--r--  2.0 unx      625 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/reserve_schedule.py
+-rw-r--r--  2.0 unx     1375 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/root_schedule.py
+-rw-r--r--  2.0 unx     1016 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/schedule_data.py
+-rw-r--r--  2.0 unx    39737 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/scheduler.py
+-rw-r--r--  2.0 unx    13207 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/section_schedule.py
+-rw-r--r--  2.0 unx      757 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/utils.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/scheduler/__init__.py
--rw-r--r--  2.0 unx    12943 b- defN 23-Mar-23 16:28 laboneq/compiler/scheduler/event_graph.py
+-rw-r--r--  2.0 unx    12943 b- defN 23-Apr-06 14:15 laboneq/compiler/scheduler/event_graph.py
 -rw-r--r--  2.0 unx    24682 b- defN 23-Feb-02 07:13 laboneq/compiler/scheduler/event_graph_builder.py
--rw-r--r--  2.0 unx     1949 b- defN 23-Feb-09 09:31 laboneq/compiler/scheduler/sampling_rate_tracker.py
--rw-r--r--  2.0 unx   115469 b- defN 23-Mar-29 00:03 laboneq/compiler/scheduler/scheduler.py
+-rw-r--r--  2.0 unx     1949 b- defN 23-Feb-09 09:38 laboneq/compiler/scheduler/sampling_rate_tracker.py
+-rw-r--r--  2.0 unx   115572 b- defN 23-Apr-06 14:15 laboneq/compiler/scheduler/scheduler.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/workflow/__init__.py
--rw-r--r--  2.0 unx    48281 b- defN 23-Mar-30 07:15 laboneq/compiler/workflow/compiler.py
+-rw-r--r--  2.0 unx    48911 b- defN 23-Apr-06 14:15 laboneq/compiler/workflow/compiler.py
 -rw-r--r--  2.0 unx    12424 b- defN 23-Feb-28 13:10 laboneq/compiler/workflow/precompensation_helpers.py
--rw-r--r--  2.0 unx    11479 b- defN 23-Mar-30 07:15 laboneq/compiler/workflow/recipe_generator.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-13 15:54 laboneq/contrib/__init__.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-13 15:54 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-13 15:54 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py
--rw-r--r--  2.0 unx     4511 b- defN 23-Mar-13 16:42 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-13 15:54 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py
--rw-r--r--  2.0 unx     3379 b- defN 23-Mar-23 16:28 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-13 15:54 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py
--rw-r--r--  2.0 unx     2833 b- defN 23-Mar-13 16:32 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/bloch_simulator.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/__init__.py
--rw-r--r--  2.0 unx     6132 b- defN 23-Mar-30 06:56 laboneq/contrib/example_helpers/example_notebook_helper.py
--rw-r--r--  2.0 unx     4116 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/feedback_helper.py
--rw-r--r--  2.0 unx     3581 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/qubit_helper.py
--rw-r--r--  2.0 unx     8830 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/data_analysis/__init__.py
--rw-r--r--  2.0 unx     6670 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/data_analysis/data_analysis.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/__init__.py
--rw-r--r--  2.0 unx      502 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/hdawg.py
--rw-r--r--  2.0 unx      956 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py
--rw-r--r--  2.0 unx     1345 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/shfqc.py
--rw-r--r--  2.0 unx     1377 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/shfsg.py
--rw-r--r--  2.0 unx     1930 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
--rw-r--r--  2.0 unx     1618 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
--rw-r--r--  2.0 unx     2383 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
--rw-r--r--  2.0 unx       77 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/plotting/__init__.py
--rw-r--r--  2.0 unx     6098 b- defN 23-Mar-23 16:28 laboneq/contrib/example_helpers/plotting/plot_helpers.py
+-rw-r--r--  2.0 unx    11747 b- defN 23-Apr-06 14:15 laboneq/compiler/workflow/recipe_generator.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/__init__.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py
+-rw-r--r--  2.0 unx     4511 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py
+-rw-r--r--  2.0 unx     3379 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py
+-rw-r--r--  2.0 unx     2833 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/bloch_simulator.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/__init__.py
+-rw-r--r--  2.0 unx     6272 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/example_notebook_helper.py
+-rw-r--r--  2.0 unx     4116 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/feedback_helper.py
+-rw-r--r--  2.0 unx     3581 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/qubit_helper.py
+-rw-r--r--  2.0 unx     8830 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/data_analysis/__init__.py
+-rw-r--r--  2.0 unx     6670 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/data_analysis/data_analysis.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/__init__.py
+-rw-r--r--  2.0 unx      502 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/hdawg.py
+-rw-r--r--  2.0 unx      956 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py
+-rw-r--r--  2.0 unx     1345 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfqc.py
+-rw-r--r--  2.0 unx     1377 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg.py
+-rw-r--r--  2.0 unx     1930 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
+-rw-r--r--  2.0 unx     1618 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
+-rw-r--r--  2.0 unx     2383 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/plotting/__init__.py
+-rw-r--r--  2.0 unx     6620 b- defN 23-Apr-06 15:01 laboneq/contrib/example_helpers/plotting/plot_helpers.py
 -rw-r--r--  2.0 unx      308 b- defN 23-Feb-13 10:57 laboneq/controller/__init__.py
 -rw-r--r--  2.0 unx     1479 b- defN 23-Feb-02 07:13 laboneq/controller/cache.py
--rw-r--r--  2.0 unx    14834 b- defN 23-Mar-24 15:37 laboneq/controller/communication.py
--rw-r--r--  2.0 unx    33043 b- defN 23-Mar-28 08:16 laboneq/controller/controller.py
--rw-r--r--  2.0 unx     4504 b- defN 23-Mar-07 15:53 laboneq/controller/laboneq_logging.py
+-rw-r--r--  2.0 unx    14819 b- defN 23-Apr-13 09:53 laboneq/controller/communication.py
+-rw-r--r--  2.0 unx    33283 b- defN 23-Apr-13 09:53 laboneq/controller/controller.py
+-rw-r--r--  2.0 unx     4504 b- defN 23-Apr-06 14:15 laboneq/controller/laboneq_logging.py
 -rw-r--r--  2.0 unx      337 b- defN 23-Feb-02 07:13 laboneq/controller/protected_session.py
--rw-r--r--  2.0 unx    14870 b- defN 23-Mar-13 16:53 laboneq/controller/recipe_1_4_0.py
+-rw-r--r--  2.0 unx    14870 b- defN 23-Apr-06 14:15 laboneq/controller/recipe_1_4_0.py
 -rw-r--r--  2.0 unx      638 b- defN 23-Feb-02 07:13 laboneq/controller/recipe_enums.py
--rw-r--r--  2.0 unx    19575 b- defN 23-Mar-23 16:28 laboneq/controller/recipe_processor.py
+-rw-r--r--  2.0 unx    19575 b- defN 23-Apr-06 14:15 laboneq/controller/recipe_processor.py
 -rw-r--r--  2.0 unx     1917 b- defN 23-Feb-02 07:13 laboneq/controller/results.py
 -rw-r--r--  2.0 unx     1594 b- defN 23-Feb-13 10:57 laboneq/controller/toolkit_adapter.py
--rw-r--r--  2.0 unx      624 b- defN 23-Mar-07 15:53 laboneq/controller/util.py
+-rw-r--r--  2.0 unx      624 b- defN 23-Apr-06 14:15 laboneq/controller/util.py
 -rw-r--r--  2.0 unx      281 b- defN 23-Mar-07 07:28 laboneq/controller/versioning.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/controller/devices/__init__.py
--rw-r--r--  2.0 unx    12627 b- defN 23-Mar-29 07:02 laboneq/controller/devices/device_collection.py
+-rw-r--r--  2.0 unx    15231 b- defN 23-Apr-13 09:53 laboneq/controller/devices/device_collection.py
 -rw-r--r--  2.0 unx     1173 b- defN 23-Feb-13 10:57 laboneq/controller/devices/device_factory.py
--rw-r--r--  2.0 unx    22931 b- defN 23-Mar-29 07:02 laboneq/controller/devices/device_hdawg.py
+-rw-r--r--  2.0 unx    23560 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_hdawg.py
 -rw-r--r--  2.0 unx     1234 b- defN 23-Feb-13 10:57 laboneq/controller/devices/device_nonqc.py
--rw-r--r--  2.0 unx     8260 b- defN 23-Mar-23 16:28 laboneq/controller/devices/device_pqsc.py
--rw-r--r--  2.0 unx     1179 b- defN 23-Mar-28 08:16 laboneq/controller/devices/device_setup_dao.py
--rw-r--r--  2.0 unx    39516 b- defN 23-Mar-28 08:16 laboneq/controller/devices/device_shfqa.py
--rw-r--r--  2.0 unx    19911 b- defN 23-Mar-28 08:16 laboneq/controller/devices/device_shfsg.py
--rw-r--r--  2.0 unx    28085 b- defN 23-Mar-28 08:16 laboneq/controller/devices/device_uhfqa.py
--rw-r--r--  2.0 unx    41842 b- defN 23-Mar-29 07:02 laboneq/controller/devices/device_zi.py
--rw-r--r--  2.0 unx    29827 b- defN 23-Mar-28 08:16 laboneq/controller/devices/zi_emulator.py
--rw-r--r--  2.0 unx     9837 b- defN 23-Mar-24 15:37 laboneq/controller/devices/zi_node_monitor.py
+-rw-r--r--  2.0 unx     8260 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_pqsc.py
+-rw-r--r--  2.0 unx     2830 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_setup_dao.py
+-rw-r--r--  2.0 unx    40121 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_shfqa.py
+-rw-r--r--  2.0 unx    20516 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_shfsg.py
+-rw-r--r--  2.0 unx    28707 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_uhfqa.py
+-rw-r--r--  2.0 unx    42463 b- defN 23-Apr-13 09:53 laboneq/controller/devices/device_zi.py
+-rw-r--r--  2.0 unx    30874 b- defN 23-Apr-13 09:53 laboneq/controller/devices/zi_emulator.py
+-rw-r--r--  2.0 unx     9837 b- defN 23-Apr-06 14:15 laboneq/controller/devices/zi_node_monitor.py
 -rw-r--r--  2.0 unx       97 b- defN 23-Feb-02 07:13 laboneq/core/__init__.py
 -rw-r--r--  2.0 unx     1998 b- defN 23-Feb-02 07:13 laboneq/core/path.py
 -rw-r--r--  2.0 unx     1338 b- defN 23-Feb-02 07:13 laboneq/core/validators.py
 -rw-r--r--  2.0 unx      126 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/__init__.py
 -rw-r--r--  2.0 unx      123 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/laboneq_exception.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/serialization/__init__.py
--rw-r--r--  2.0 unx    19090 b- defN 23-Mar-07 15:53 laboneq/core/serialization/simple_serialization.py
+-rw-r--r--  2.0 unx    19090 b- defN 23-Apr-06 14:15 laboneq/core/serialization/simple_serialization.py
 -rw-r--r--  2.0 unx      161 b- defN 23-Feb-02 07:13 laboneq/core/types/__init__.py
 -rw-r--r--  2.0 unx     5138 b- defN 23-Feb-28 13:10 laboneq/core/types/compiled_experiment.py
 -rw-r--r--  2.0 unx     1473 b- defN 23-Feb-02 07:13 laboneq/core/types/uid.py
 -rw-r--r--  2.0 unx      660 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/__init__.py
--rw-r--r--  2.0 unx      934 b- defN 23-Feb-07 16:25 laboneq/core/types/enums/acquisition_type.py
+-rw-r--r--  2.0 unx      934 b- defN 23-Feb-07 17:52 laboneq/core/types/enums/acquisition_type.py
 -rw-r--r--  2.0 unx      213 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/averaging_mode.py
 -rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/carrier_type.py
 -rw-r--r--  2.0 unx      227 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/dsl_version.py
 -rw-r--r--  2.0 unx      185 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/execution_type.py
 -rw-r--r--  2.0 unx      223 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/high_pass_compensation_clearing.py
 -rw-r--r--  2.0 unx      157 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/io_direction.py
 -rw-r--r--  2.0 unx      252 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/io_signal_type.py
 -rw-r--r--  2.0 unx      316 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/mixer_type.py
 -rw-r--r--  2.0 unx      200 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/modulation_type.py
 -rw-r--r--  2.0 unx      152 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/port_mode.py
 -rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/reference_clock_source.py
 -rw-r--r--  2.0 unx      198 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/repetition_mode.py
 -rw-r--r--  2.0 unx      170 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/section_alignment.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/utilities/__init__.py
--rw-r--r--  2.0 unx     8039 b- defN 23-Mar-23 16:28 laboneq/core/utilities/pulse_sampler.py
--rw-r--r--  2.0 unx     9808 b- defN 23-Mar-24 08:01 laboneq/core/utilities/replace_pulse.py
+-rw-r--r--  2.0 unx     8039 b- defN 23-Apr-06 14:15 laboneq/core/utilities/pulse_sampler.py
+-rw-r--r--  2.0 unx     9808 b- defN 23-Apr-06 14:15 laboneq/core/utilities/replace_pulse.py
 -rw-r--r--  2.0 unx      178 b- defN 23-Feb-02 07:13 laboneq/dsl/__init__.py
--rw-r--r--  2.0 unx     2963 b- defN 23-Mar-23 16:28 laboneq/dsl/laboneq_facade.py
+-rw-r--r--  2.0 unx     2929 b- defN 23-Apr-06 14:15 laboneq/dsl/laboneq_facade.py
 -rw-r--r--  2.0 unx     2552 b- defN 23-Feb-15 13:56 laboneq/dsl/parameter.py
--rw-r--r--  2.0 unx    23470 b- defN 23-Mar-30 07:15 laboneq/dsl/session.py
+-rw-r--r--  2.0 unx    25670 b- defN 23-Apr-06 14:15 laboneq/dsl/session.py
 -rw-r--r--  2.0 unx     2296 b- defN 23-Feb-02 07:13 laboneq/dsl/utils.py
 -rw-r--r--  2.0 unx      487 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/__init__.py
 -rw-r--r--  2.0 unx      545 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibratable.py
 -rw-r--r--  2.0 unx     1886 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibration.py
 -rw-r--r--  2.0 unx      111 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibration_item.py
 -rw-r--r--  2.0 unx      992 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/mixer_calibration.py
 -rw-r--r--  2.0 unx     3403 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/observable.py
 -rw-r--r--  2.0 unx     1716 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/oscillator.py
 -rw-r--r--  2.0 unx     2650 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/precompensation.py
 -rw-r--r--  2.0 unx     5363 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/signal_calibration.py
 -rw-r--r--  2.0 unx      553 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/units.py
 -rw-r--r--  2.0 unx      363 b- defN 23-Feb-02 07:13 laboneq/dsl/device/__init__.py
--rw-r--r--  2.0 unx    42448 b- defN 23-Mar-24 14:51 laboneq/dsl/device/_device_setup_generator.py
+-rw-r--r--  2.0 unx    42448 b- defN 23-Apr-06 14:15 laboneq/dsl/device/_device_setup_generator.py
 -rw-r--r--  2.0 unx      601 b- defN 23-Feb-02 07:13 laboneq/dsl/device/connection.py
--rw-r--r--  2.0 unx    11946 b- defN 23-Mar-24 14:51 laboneq/dsl/device/device_setup.py
--rw-r--r--  2.0 unx     2551 b- defN 23-Mar-07 15:53 laboneq/dsl/device/device_setup_helper.py
+-rw-r--r--  2.0 unx    11946 b- defN 23-Apr-13 09:53 laboneq/dsl/device/device_setup.py
+-rw-r--r--  2.0 unx     2551 b- defN 23-Apr-06 14:15 laboneq/dsl/device/device_setup_helper.py
 -rw-r--r--  2.0 unx     1296 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instrument.py
 -rw-r--r--  2.0 unx     1893 b- defN 23-Feb-02 07:13 laboneq/dsl/device/logical_signal_group.py
 -rw-r--r--  2.0 unx     1729 b- defN 23-Feb-02 07:13 laboneq/dsl/device/physical_channel_group.py
 -rw-r--r--  2.0 unx      538 b- defN 23-Feb-02 07:13 laboneq/dsl/device/ports.py
--rw-r--r--  2.0 unx     4312 b- defN 23-Feb-27 13:40 laboneq/dsl/device/qubits.py
+-rw-r--r--  2.0 unx     4312 b- defN 23-Apr-13 09:47 laboneq/dsl/device/qubits.py
 -rw-r--r--  2.0 unx      215 b- defN 23-Feb-02 07:13 laboneq/dsl/device/server.py
 -rw-r--r--  2.0 unx      291 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/__init__.py
 -rw-r--r--  2.0 unx     1778 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instruments/hdawg.py
 -rw-r--r--  2.0 unx      466 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/nonqc.py
 -rw-r--r--  2.0 unx      948 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instruments/pqsc.py
--rw-r--r--  2.0 unx     2248 b- defN 23-Feb-06 17:42 laboneq/dsl/device/instruments/shfqa.py
--rw-r--r--  2.0 unx     1659 b- defN 23-Feb-06 17:42 laboneq/dsl/device/instruments/shfsg.py
+-rw-r--r--  2.0 unx     2248 b- defN 23-Feb-06 16:30 laboneq/dsl/device/instruments/shfqa.py
+-rw-r--r--  2.0 unx     1659 b- defN 23-Feb-06 16:30 laboneq/dsl/device/instruments/shfsg.py
 -rw-r--r--  2.0 unx     2312 b- defN 23-Feb-16 12:45 laboneq/dsl/device/instruments/uhfqa.py
 -rw-r--r--  2.0 unx      888 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/zi_standard_instrument.py
 -rw-r--r--  2.0 unx      187 b- defN 23-Feb-02 07:13 laboneq/dsl/device/io_units/__init__.py
--rw-r--r--  2.0 unx    11590 b- defN 23-Mar-28 08:16 laboneq/dsl/device/io_units/logical_signal.py
+-rw-r--r--  2.0 unx    12288 b- defN 23-Apr-06 14:15 laboneq/dsl/device/io_units/logical_signal.py
 -rw-r--r--  2.0 unx     3608 b- defN 23-Feb-02 07:13 laboneq/dsl/device/io_units/physical_channel.py
 -rw-r--r--  2.0 unx      114 b- defN 23-Feb-02 07:13 laboneq/dsl/device/servers/__init__.py
 -rw-r--r--  2.0 unx      704 b- defN 23-Feb-02 07:13 laboneq/dsl/device/servers/data_server.py
 -rw-r--r--  2.0 unx      718 b- defN 23-Feb-02 07:13 laboneq/dsl/enums/__init__.py
 -rw-r--r--  2.0 unx      508 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/__init__.py
 -rw-r--r--  2.0 unx      972 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/acquire.py
 -rw-r--r--  2.0 unx      814 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/call.py
 -rw-r--r--  2.0 unx      780 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/delay.py
--rw-r--r--  2.0 unx    41480 b- defN 23-Mar-28 08:16 laboneq/dsl/experiment/experiment.py
--rw-r--r--  2.0 unx     8058 b- defN 23-Mar-28 08:16 laboneq/dsl/experiment/experiment_signal.py
+-rw-r--r--  2.0 unx    41433 b- defN 23-Apr-06 15:01 laboneq/dsl/experiment/experiment.py
+-rw-r--r--  2.0 unx     7754 b- defN 23-Apr-06 14:15 laboneq/dsl/experiment/experiment_signal.py
 -rw-r--r--  2.0 unx      401 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/operation.py
 -rw-r--r--  2.0 unx     1647 b- defN 23-Feb-28 13:10 laboneq/dsl/experiment/play_pulse.py
--rw-r--r--  2.0 unx     3568 b- defN 23-Feb-16 12:45 laboneq/dsl/experiment/pulse.py
+-rw-r--r--  2.0 unx     3568 b- defN 23-Apr-03 11:23 laboneq/dsl/experiment/pulse.py
 -rw-r--r--  2.0 unx     7932 b- defN 23-Mar-13 15:23 laboneq/dsl/experiment/pulse_library.py
 -rw-r--r--  2.0 unx      890 b- defN 23-Feb-16 12:45 laboneq/dsl/experiment/reserve.py
 -rw-r--r--  2.0 unx    11366 b- defN 23-Feb-28 13:10 laboneq/dsl/experiment/section.py
 -rw-r--r--  2.0 unx      640 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/set.py
--rw-r--r--  2.0 unx      151 b- defN 23-Feb-14 15:16 laboneq/dsl/result/__init__.py
+-rw-r--r--  2.0 unx      151 b- defN 23-Feb-14 14:41 laboneq/dsl/result/__init__.py
 -rw-r--r--  2.0 unx     1766 b- defN 23-Feb-02 07:13 laboneq/dsl/result/acquired_result.py
 -rw-r--r--  2.0 unx     7240 b- defN 23-Feb-02 07:13 laboneq/dsl/result/results.py
 -rw-r--r--  2.0 unx      113 b- defN 23-Feb-02 07:13 laboneq/dsl/serialization/__init__.py
--rw-r--r--  2.0 unx     5243 b- defN 23-Feb-27 13:40 laboneq/dsl/serialization/serializer.py
+-rw-r--r--  2.0 unx     5243 b- defN 23-Feb-27 13:39 laboneq/dsl/serialization/serializer.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/executor/__init__.py
 -rw-r--r--  2.0 unx     3819 b- defN 23-Feb-16 12:45 laboneq/executor/execution_from_experiment.py
--rw-r--r--  2.0 unx     8152 b- defN 23-Mar-23 16:28 laboneq/executor/executor.py
--rw-r--r--  2.0 unx      145 b- defN 23-Feb-14 15:16 laboneq/openqasm3/__init__.py
+-rw-r--r--  2.0 unx     8152 b- defN 23-Apr-06 14:15 laboneq/executor/executor.py
+-rw-r--r--  2.0 unx      145 b- defN 23-Feb-14 14:41 laboneq/openqasm3/__init__.py
 -rw-r--r--  2.0 unx    10897 b- defN 23-Feb-16 12:45 laboneq/openqasm3/openqasm3_importer.py
 -rw-r--r--  2.0 unx      127 b- defN 23-Feb-02 07:13 laboneq/pulse_sheet_viewer/__init__.py
 -rw-r--r--  2.0 unx     2059 b- defN 23-Feb-16 12:45 laboneq/pulse_sheet_viewer/event_graph_viewer.py
 -rw-r--r--  2.0 unx     2692 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/interactive_psv.py
 -rw-r--r--  2.0 unx     3288 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py
--rw-rw-rw-  2.0 unx  1443040 b- defN 23-Mar-24 14:51 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
--rw-r--r--  2.0 unx      152 b- defN 23-Feb-14 15:16 laboneq/simulator/__init__.py
+-rw-rw-rw-  2.0 unx  1443040 b- defN 23-Apr-06 14:15 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
+-rw-r--r--  2.0 unx      152 b- defN 23-Feb-14 14:41 laboneq/simulator/__init__.py
 -rw-r--r--  2.0 unx     5904 b- defN 23-Feb-02 14:48 laboneq/simulator/output_simulator.py
--rw-r--r--  2.0 unx    37399 b- defN 23-Mar-30 06:56 laboneq/simulator/seqc_parser.py
--rw-r--r--  2.0 unx    12081 b- defN 23-Mar-29 07:02 laboneq/simulator/wave_scroller.py
--rw-rw-rw-  2.0 unx       22 b- defN 23-Mar-30 07:16 laboneq-2.3.0.dist-info/AUTHORS
--rw-rw-rw-  2.0 unx    11358 b- defN 23-Mar-30 07:16 laboneq-2.3.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3188 b- defN 23-Mar-30 07:16 laboneq-2.3.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-30 07:16 laboneq-2.3.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-Mar-30 07:16 laboneq-2.3.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    23448 b- defN 23-Mar-30 07:16 laboneq-2.3.0.dist-info/RECORD
-239 files, 2939742 bytes uncompressed, 902351 bytes compressed:  69.3%
+-rw-r--r--  2.0 unx    39230 b- defN 23-Apr-06 14:15 laboneq/simulator/seqc_parser.py
+-rw-r--r--  2.0 unx    12081 b- defN 23-Apr-06 14:15 laboneq/simulator/wave_scroller.py
+-rw-rw-rw-  2.0 unx       22 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/AUTHORS
+-rw-rw-rw-  2.0 unx    11358 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3188 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    23450 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/RECORD
+239 files, 2962254 bytes uncompressed, 908361 bytes compressed:  69.3%
```

## zipnote {}

```diff
@@ -693,26 +693,26 @@
 
 Filename: laboneq/simulator/seqc_parser.py
 Comment: 
 
 Filename: laboneq/simulator/wave_scroller.py
 Comment: 
 
-Filename: laboneq-2.3.0.dist-info/AUTHORS
+Filename: laboneq-2.4.0.dist-info/AUTHORS
 Comment: 
 
-Filename: laboneq-2.3.0.dist-info/LICENSE
+Filename: laboneq-2.4.0.dist-info/LICENSE
 Comment: 
 
-Filename: laboneq-2.3.0.dist-info/METADATA
+Filename: laboneq-2.4.0.dist-info/METADATA
 Comment: 
 
-Filename: laboneq-2.3.0.dist-info/WHEEL
+Filename: laboneq-2.4.0.dist-info/WHEEL
 Comment: 
 
-Filename: laboneq-2.3.0.dist-info/top_level.txt
+Filename: laboneq-2.4.0.dist-info/top_level.txt
 Comment: 
 
-Filename: laboneq-2.3.0.dist-info/RECORD
+Filename: laboneq-2.4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## laboneq/VERSION.txt

```diff
@@ -1 +1 @@
-2.3.0
+2.4.0
```

## laboneq/compiler/qccs-schema_2_5_0.json

### Pretty-printed

 * *Similarity: 0.999990295031056%*

 * *Differences: {"'definitions'": "{'device-def': {'properties': {'is_qc': OrderedDict([('type', 'boolean')])}}}"}*

```diff
@@ -118,14 +118,17 @@
                             "type": "string"
                         },
                         {
                             "type": "null"
                         }
                     ]
                 },
+                "is_qc": {
+                    "type": "boolean"
+                },
                 "oscillators_list": {
                     "$ref": "#/definitions/reference-list-def"
                 },
                 "parameters": {
                     "$ref": "#/definitions/reference-list-def"
                 },
                 "reference_clock_source": {
```

## laboneq/compiler/code_generator/code_generator.py

```diff
@@ -23,28 +23,30 @@
     analyze_phase_reset_times,
     analyze_precomp_reset_times,
     analyze_set_oscillator_times,
     analyze_trigger_events,
 )
 from laboneq.compiler.code_generator.analyze_playback import analyze_play_wave_times
 from laboneq.compiler.code_generator.command_table_tracker import CommandTableTracker
-from laboneq.compiler.code_generator.compressor import compress_generators_rle
 from laboneq.compiler.code_generator.feedback_register_allocator import (
     FeedbackRegisterAllocator,
 )
 from laboneq.compiler.code_generator.measurement_calculator import (
     IntegrationTimes,
     MeasurementCalculator,
     SignalDelays,
 )
 from laboneq.compiler.code_generator.sampled_event_handler import (
     FeedbackConnection,
     SampledEventHandler,
 )
-from laboneq.compiler.code_generator.seq_c_generator import SeqCGenerator
+from laboneq.compiler.code_generator.seq_c_generator import (
+    SeqCGenerator,
+    merge_generators,
+)
 from laboneq.compiler.code_generator.seqc_tracker import SeqCTracker
 from laboneq.compiler.code_generator.signatures import (
     PlaybackSignature,
     WaveformSignature,
 )
 from laboneq.compiler.code_generator.utils import normalize_phase
 from laboneq.compiler.code_generator.wave_index_tracker import WaveIndexTracker
@@ -79,42 +81,46 @@
     sample_pulse,
     verify_amplitude_no_clipping,
 )
 
 _logger = logging.getLogger(__name__)
 
 
-def add_wait_trigger_statements(awg: AWGInfo, init_generator, deferred_function_calls):
+def add_wait_trigger_statements(
+    awg: AWGInfo,
+    init_generator: SeqCGenerator,
+    deferred_function_calls: SeqCGenerator,
+):
     if awg.trigger_mode == TriggerMode.DIO_TRIGGER:
         if awg.awg_number == 0:
             init_generator.add_function_call_statement("setDIO", ["0"])
             init_generator.add_function_call_statement("wait", ["2000000"])
             init_generator.add_function_call_statement("playZero", ["512"])
             if awg.reference_clock_source != "internal":
                 init_generator.add_function_call_statement("waitDigTrigger", ["1"])
             init_generator.add_function_call_statement("setDIO", ["0xffffffff"])
             init_generator.add_function_call_statement("waitDIOTrigger")
             delay_first_awg_samples = str(
                 round(awg.sampling_rate * CodeGenerator.DELAY_FIRST_AWG / 16) * 16
             )
             if int(delay_first_awg_samples) > 0:
-                deferred_function_calls.append(
-                    {"name": "playZero", "args": [delay_first_awg_samples]}
+                deferred_function_calls.add_function_call_statement(
+                    "playZero", [delay_first_awg_samples]
                 )
-                deferred_function_calls.append({"name": "waitWave", "args": []})
+                deferred_function_calls.add_function_call_statement("waitWave")
         else:
             init_generator.add_function_call_statement("waitDIOTrigger")
             delay_other_awg_samples = str(
                 round(awg.sampling_rate * CodeGenerator.DELAY_OTHER_AWG / 16) * 16
             )
             if int(delay_other_awg_samples) > 0:
-                deferred_function_calls.append(
-                    {"name": "playZero", "args": [delay_other_awg_samples]}
+                deferred_function_calls.add_function_call_statement(
+                    "playZero", [delay_other_awg_samples]
                 )
-                deferred_function_calls.append({"name": "waitWave", "args": []})
+                deferred_function_calls.add_function_call_statement("waitWave")
 
     elif awg.trigger_mode == TriggerMode.DIO_WAIT:
         init_generator.add_variable_declaration("dio", "0xffffffff")
         body = SeqCGenerator()
         body.add_function_call_statement("getDIO", args=None, assign_to="dio")
         init_generator.add_do_while("dio & 0x0001", body)
         init_generator.add_function_call_statement("waitDIOTrigger")
@@ -994,15 +1000,15 @@
         _logger.debug(
             "** Start processing events for awg %d of %s",
             awg.awg_number,
             awg.device_id,
         )
         command_table_tracker = CommandTableTracker(awg.device_type)
 
-        deferred_function_calls = []
+        deferred_function_calls = SeqCGenerator()
         init_generator = SeqCGenerator()
 
         seqc_tracker = SeqCTracker(
             init_generator=init_generator,
             deferred_function_calls=deferred_function_calls,
             sampling_rate=global_sampling_rate,
             delay=global_delay,
@@ -1042,22 +1048,16 @@
         for part in seqc_tracker.loop_stack_generators:
             for generator in part:
                 seq_c_generators.append(generator)
         _logger.debug(
             "***  collected generators, seq_c_generators: %s", seq_c_generators
         )
 
-        main_generator = compress_generators_rle(
-            seq_c_generators, declarations_generator
-        )
+        main_generator = merge_generators(seq_c_generators)
 
-        if main_generator.needs_play_zero_counter():
-            declarations_generator.add_variable_declaration(
-                main_generator.play_zero_counter_variable_name()
-            )
         seq_c_generator = SeqCGenerator()
         if function_defs_generator.num_statements() > 0:
             seq_c_generator.append_statements_from(function_defs_generator)
             seq_c_generator.add_comment("=== END-OF-FUNCTION-DEFS ===")
         seq_c_generator.append_statements_from(declarations_generator)
         seq_c_generator.append_statements_from(main_generator)
```

## laboneq/compiler/code_generator/compressor.py

```diff
@@ -1,203 +1,91 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
-from typing import List
-
-from laboneq.compiler.code_generator.seq_c_generator import SeqCGenerator
+from collections import defaultdict
+from dataclasses import dataclass
+from typing import Callable, Hashable, List, Tuple
 
 _logger = logging.getLogger(__name__)
 
 
-def compress_generators(
-    generators: List[SeqCGenerator], declarations_generator: SeqCGenerator
+@dataclass
+class Run:
+    word: Tuple[Hashable] | str
+    count: int
+
+    @property
+    def span(self):
+        return self.count * len(self.word)
+
+
+def default_cost_function(r: Run):
+    """Some function to grade the fitness of this roll-up.
+
+    This implementation is quite simple: if `r.word` is a string, it will return
+    the number of characters saved (minus a fixed penalty for the overhead of the loop
+    itself).
+
+    This mostly serves for testing. For the real application (seqc compression) not all
+    statements are equally expensive. Some might be loops themselves.
+    Custom cost functions will be helpful.
+    """
+    return -((r.count - 1) * len(r.word) - 2)
+
+
+def compressor_core(
+    plaintext: List[Hashable] | str,
+    cost_function: Callable = default_cost_function,
+    recurse=False,
 ):
-    retval = SeqCGenerator()
-    last_hash = None
-    compressed_generators = []
-    _logger.debug("Compressing generators %s", generators)
-    for generator in generators:
-        if generator is None:
-            raise Exception("None of the generators to be compressed may be None")
-        _logger.debug(
-            "Generator with %d statements, hash %s",
-            generator.num_statements(),
-            hash(generator),
-        )
-        for statement in generator._statements:
-            _logger.debug("Statement: %s", statement)
-        current_hash = hash(generator)
-        if last_hash == current_hash:
-            compressed_generators[-1]["count"] += 1
-        else:
-            compressed_generators.append({"generator": generator, "count": 1})
-        last_hash = current_hash
-    variable_counter = 0
-    for generator_spec in compressed_generators:
-        count = generator_spec["count"]
-        if count > 1 and variable_counter < 14:
-            variable_name = "repeat_count_" + str(variable_counter)
-            declarations_generator.add_variable_declaration(variable_name, count)
-            retval.add_countdown_loop(variable_name, count, generator_spec["generator"])
-            variable_counter += 1
+    if len(plaintext) <= 1:
+        return plaintext
+    next_seen_map = {}
+    offsets = []
+    for i, c in list(enumerate(plaintext))[::-1]:
+        next_seen_index = next_seen_map.get(c)
+        if next_seen_index is None:
+            offsets.append(None)
         else:
-            retval.append_statements_from(generator_spec["generator"])
+            offsets.append(next_seen_index - i)
+        next_seen_map[c] = i
 
-    return retval
+    offsets = offsets[::-1]
 
-
-def compress_generators_rle(
-    seq_c_generators: List[SeqCGenerator], declarations_generator: SeqCGenerator
-):
-    for generator in seq_c_generators:
-        if generator is None:
-            raise Exception("None of the generators to be compressed may be None")
-    hash_pairs = [(hash(generator), generator) for generator in seq_c_generators]
-
-    hashes_back_converter = {hash_pair[0]: hash_pair[1] for hash_pair in hash_pairs}
-    hashes = [hash_pair[0] for hash_pair in hash_pairs]
-
-    _logger.debug("Trying to compress generator hashes %s", hashes)
-
-    hashes_dict = list(set(hashes))
-
-    last_hash = None
-    for item_hash in hashes:
-        if last_hash != item_hash:
-            generator = hashes_back_converter[item_hash]
-            _logger.debug(
-                "-- START %s hash %s", hashes_dict.index(item_hash), item_hash
-            )
-            for line in generator.generate_seq_c().splitlines():
-                _logger.debug("  %s", line)
-            _logger.debug(" -- END %s hash %s", hashes_dict.index(item_hash), item_hash)
-        last_hash = item_hash
-
-    if len(hashes_dict) >= 400:
-        _logger.info(
-            "The number of hashes %d is too large for compression, using fallback",
-            len(hashes_dict),
-        )
-        return SeqCGenerator.compress_generators(
-            seq_c_generators, declarations_generator
-        )
-    as_index_sequence = list(map(lambda x: hashes_dict.index(x), hashes))
-
-    _logger.debug(
-        "The form of the generators is %s", " ".join(map(str, as_index_sequence))
-    )
-
-    mtf_encoded = mtf_encode(as_index_sequence)
-    _logger.debug("mtf encoded %s", " ".join(map(str, mtf_encoded)))
-    flat_runs = find_runs(mtf_encoded)
-    _logger.debug("Found generator runs %s", flat_runs)
-
-    retval = SeqCGenerator()
-    good_runs = []
-
-    for top_run in flat_runs:
-        if top_run[2] >= 3:
-            run_end = top_run[1] + top_run[2]
-            run_length = top_run[0] + 1
-            num_repeats = round((top_run[2] + 1) / run_length)
-            run_start_index = run_end - num_repeats * run_length
-            runs_string = as_index_sequence[run_start_index:run_end]
-            the_run = as_index_sequence[run_end - run_length : run_end]
-            _logger.debug(
-                "The runs section from %d to %d contains %d runs of %s  and looks as follows %s",
-                run_start_index,
-                run_end,
-                num_repeats,
-                the_run,
-                runs_string,
-            )
-            good_runs.append((run_start_index, run_length, num_repeats))
-
-    index = 0
-    variable_added = False
-    while True:
-        if len(good_runs) == 0 or good_runs[0][0] > index:
-            item_hash = hashes[index]
-            dict_index = hashes_dict.index(item_hash)
-            _logger.debug(
-                "Emitting %d at position %d -  generator with hash %s",
-                dict_index,
-                index,
-                item_hash,
-            )
-            generator = hashes_back_converter[item_hash]
-            retval.append_statements_from(generator)
-            index += 1
-        else:
-            run = good_runs.pop(0)
-
-            variable_name = "repeat_count_comp"
-            if not variable_added:
-                declarations_generator.add_variable_declaration(
-                    variable_name, num_repeats
-                )
-                variable_added = True
-
-            loop_body = SeqCGenerator()
-            num_repeats = run[2]
-            run_length = run[1]
-            the_run_as_hashes = [hashes[index + offset] for offset in range(run_length)]
-            _logger.debug(
-                "Emitting run with %d of hashes %s at position %d",
-                num_repeats,
-                the_run_as_hashes,
-                index,
-            )
-            for generator_hash in the_run_as_hashes:
-                generator = hashes_back_converter[generator_hash]
-                loop_body.append_statements_from(generator)
-
-            retval.add_countdown_loop(variable_name, num_repeats, loop_body)
-            index += num_repeats * run_length
-
-        if index >= len(hashes):
-            break
-
-    return retval
-
-
-def mtf_encode(index_sequence: str) -> List[int]:
-    dict_set = set()
-    dictionary = []
-    for c in index_sequence:
-        if c not in dict_set:
-            dict_set.add(c)
-            dictionary.append(c)
-    compressed_text = []
-    rank = 0
-    for c in index_sequence:
-        rank = dictionary.index(c)
-        compressed_text.append(rank)
-
-        dictionary.pop(rank)
-        dictionary.insert(0, c)
-
-    return compressed_text
-
-
-def find_runs(data):
-    last_d = None
-    current_run_length = 1
-    current_run_start = 0
-    runs = []
-    for i, d in enumerate(data):
-        if last_d is None:
-            last_d = d
-        elif last_d == d:
-            current_run_length += 1
-        else:
-            current_run = (last_d, current_run_start, current_run_length)
-            runs.append(current_run)
-            current_run_length = 1
-            last_d = d
-            current_run_start = i
-    current_run = (d, current_run_start, current_run_length)
-    runs.append(current_run)
-    return runs
+    runs = defaultdict(list)  # word -> List[(start, Run)]
+    for index, offset in enumerate(offsets):
+        if offset is None:
+            continue
+        word = tuple(plaintext[index : index + offset])
+        if any(start < index <= start + r.span for start, r in runs[word]):
+            continue
+
+        run_length = 1
+        while index + (run_length + 1) * offset <= len(plaintext) and word == tuple(
+            plaintext[index + run_length * offset : index + (run_length + 1) * offset]
+        ):
+            run_length += 1
+        runs[word].append((index, Run(word, run_length)))
+
+    runs_flat = [(start, run) for run_list in runs.values() for start, run in run_list]
+
+    if len(runs_flat) == 0:
+        return plaintext
+
+    runs_flat.sort(key=lambda x: cost_function(x[1]))
+    best_run_start, best_run = runs_flat[0]
+    best_run_end = best_run_start + best_run.span
+
+    if cost_function(best_run) > 0:
+        return plaintext
+
+    if recurse:
+        best_run.word = compressor_core(best_run.word, cost_function, recurse)
+
+    return [
+        *compressor_core(plaintext[:best_run_start], cost_function, recurse),
+        best_run,
+        *compressor_core(plaintext[best_run_end:], cost_function, recurse),
+    ]
```

## laboneq/compiler/code_generator/sampled_event_handler.py

```diff
@@ -3,17 +3,17 @@
 
 from __future__ import annotations
 
 import logging
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Set
 
-from laboneq.compiler.code_generator.compressor import compress_generators
 from laboneq.compiler.code_generator.seq_c_generator import (
     SeqCGenerator,
+    merge_generators,
     string_sanitize,
 )
 from laboneq.compiler.code_generator.signatures import PlaybackSignature
 from laboneq.compiler.common.awg_sampled_event import (
     AWGEvent,
     AWGEventType,
     AWGSampledEventSequence,
@@ -189,15 +189,15 @@
         else:
             wave_index = self.wave_indices.lookup_index_by_wave_id(sig_string)
             if wave_index is None:
                 wave_index = self.wave_indices.create_index_for_wave(
                     sig_string, signal_type_for_wave_index
                 )
                 if wave_index is not None:
-                    self.seqc_tracker.add_assign_wave_index_statement(
+                    self.declarations_generator.add_assign_wave_index_statement(
                         self.device_type,
                         self.awg.signal_type.value,
                         sig_string,
                         wave_index,
                         play_wave_channel,
                     )
 
@@ -217,15 +217,15 @@
             else:
                 self.seqc_tracker.add_play_wave_statement(
                     self.device_type,
                     self.awg.signal_type.value,
                     sig_string,
                     play_wave_channel,
                 )
-            self.seqc_tracker.clear_deferred_function_calls()
+            self.seqc_tracker.flush_deferred_function_calls()
             self.seqc_tracker.current_time = sampled_event.end
         else:
             assert self.use_command_table
             if state in self.match_command_table_entries:
                 if self.match_command_table_entries[state] != (
                     signature,
                     wave_index,
@@ -514,61 +514,50 @@
             assert self.seqc_tracker.current_time % self.sequencer_step == 0
             self.current_sequencer_step = (
                 self.seqc_tracker.current_time // self.sequencer_step
             )
             self.seqc_tracker.add_variable_assignment(
                 "current_seq_step", self.current_sequencer_step
             )
-        self.seqc_tracker.append_loop_stack_generator(outer=True)
+        self.seqc_tracker.push_loop_stack_generator()
 
         if self.emit_timing_comments:
             self.seqc_tracker.add_comment(
                 f"PUSH LOOP {sampled_event.params} current time = {self.seqc_tracker.current_time}"
             )
 
         self.loop_stack.append(sampled_event)
 
     def handle_iterate(self, sampled_event: AWGEvent):
         if (
             self.seqc_tracker.current_loop_stack_generator().num_noncomment_statements()
             > 0
-            or len(self.seqc_tracker.deferred_function_calls) > 0
+            or self.seqc_tracker.deferred_function_calls.num_statements() > 0
         ):
             _logger.debug(
                 "  Processing ITERATE EVENT %s, loop stack is %s",
                 sampled_event,
                 self.loop_stack,
             )
             if self.emit_timing_comments:
                 self.seqc_tracker.add_comment(
                     f"ITERATE  {sampled_event.params}, current time = {self.seqc_tracker.current_time}"
                 )
             self.seqc_tracker.add_required_playzeros(sampled_event)
             self._increment_sequencer_step()
 
-            variable_name = string_sanitize(
-                "repeat_count_" + str(sampled_event.params["loop_id"])
-            )
-            if variable_name not in self.declared_variables:
-                self.declarations_generator.add_variable_declaration(variable_name)
-                self.declared_variables.add(variable_name)
-
             loop_generator = SeqCGenerator()
             open_generators = self.seqc_tracker.pop_loop_stack_generators()
             _logger.debug(
                 "  Popped %s, stack is now %s",
                 open_generators,
                 self.seqc_tracker.loop_stack_generators,
             )
-            loop_body = compress_generators(
-                open_generators, self.declarations_generator
-            )
-            loop_generator.add_countdown_loop(
-                variable_name, sampled_event.params["num_repeats"], loop_body
-            )
+            loop_body = merge_generators(open_generators)
+            loop_generator.add_repeat(sampled_event.params["num_repeats"], loop_body)
             if self.emit_timing_comments:
                 loop_generator.add_comment(f"Loop for {sampled_event.params}")
             start_loop_event = self.loop_stack.pop()
             delta = sampled_event.start - start_loop_event.start
             self.seqc_tracker.current_time = (
                 start_loop_event.start + sampled_event.params["num_repeats"] * delta
             )
@@ -634,15 +623,15 @@
                 "QA_DATA_PROCESSED"
                 if ev.params["local"]
                 else "ZSYNC_DATA_PQSC_REGISTER",
                 latency=f"current_seq_step + {latency}",
                 comment="Match handle " + handle,
             )
             self.seqc_tracker.add_timing_comment(ev.end)
-            self.seqc_tracker.clear_deferred_function_calls()
+            self.seqc_tracker.flush_deferred_function_calls()
             self.seqc_tracker.current_time = self.match_parent_event.end
             self.match_parent_event = None
 
     def handle_sampled_event(self, sampled_event: AWGEvent):
         signature = sampled_event.type
         if signature == AWGEventType.PLAY_WAVE:
             if not self.handle_playwave(sampled_event):
```

## laboneq/compiler/code_generator/seq_c_generator.py

```diff
@@ -1,27 +1,31 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from __future__ import annotations
+
 import functools
 import hashlib
 import logging
 import re
+import textwrap
 from enum import Enum
+from typing import Any, Dict, List, Optional
 
+from laboneq.compiler.code_generator.compressor import Run, compressor_core
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.core.exceptions import LabOneQException
 
 _logger = logging.getLogger(__name__)
 
 
 MAX_PLAY_ZERO_UHFQA = 131056
 MAX_PLAY_ZERO_HDAWG = 1048560
 
 MIN_PLAY_ZERO = 512 + 128
-PLAY_ZERO_COUNTER_VARIABLE = "play_zero_count"
 
 
 @functools.lru_cache()
 def string_sanitize(input):
     """Sanitize the input string, so it can be safely used as (part of) an identifier
     in seqC."""
 
@@ -40,36 +44,39 @@
 
     if s != input:
         s = f"{s}_{hashlib.md5(input.encode()).hexdigest()[:4]}"
 
     return s
 
 
+SeqCStatement = Dict[str, Any]
+
+
 class SeqCGenerator:
     def __init__(self):
         self._seq_c_text = ""
-        self._statements = []
-        self._needs_play_zero_counter = False
+        self._statements: List[SeqCStatement] = []
 
     def num_statements(self):
         return len(self._statements)
 
     def num_noncomment_statements(self):
         retval = 0
         for statement in self._statements:
             if statement["type"] != "comment":
                 retval += 1
         return retval
 
-    def append_statements_from(self, seq_c_generator):
+    def clear(self):
+        self._statements.clear()
+
+    def append_statements_from(self, seq_c_generator: SeqCGenerator):
         self._statements.extend(seq_c_generator._statements)
-        if seq_c_generator.needs_play_zero_counter():
-            self._needs_play_zero_counter = True
 
-    def add_statement(self, statement):
+    def add_statement(self, statement: SeqCStatement):
         self._statements.append(statement)
 
     def add_comment(self, comment_text):
         statement = {"type": "comment", "text": comment_text}
         self.add_statement(statement)
 
     def add_function_call_statement(self, name, args=[], assign_to=None):
@@ -97,30 +104,50 @@
                 "wave_id": wave_id,
                 "length": length,
                 "has_marker1": has_marker1,
                 "has_marker2": has_marker2,
             }
         )
 
-    def add_countdown_loop(self, variable_name, num_repeats, body):
-        if body is None:
-            raise Exception(f"Empty body for variable_name {variable_name}")
+    def estimate_complexity(self):
+        """Calculate a rough estimate for the complexity (~nr of instructions)
+
+        The point here is not to be accurate about every statement, but to correctly
+        gauge the size of loops etc."""
+        score = 0
+        for s in self._statements:
+            default = 1
+            if s.get("type") in ["do_while", "repeat"]:
+                default = 10
+            score += s.get("complexity", default)
+        return score
+
+    def add_repeat(self, num_repeats, body: SeqCGenerator):
+        assert body is not None
+        complexity = body.estimate_complexity() + 2  # penalty for loop overhead
         self.add_statement(
             {
-                "type": "countdown_loop",
-                "variable_name": variable_name,
+                "type": "repeat",
                 "num_repeats": num_repeats,
                 "body": body,
+                "complexity": complexity,
             }
         )
 
-    def add_do_while(self, condition, body):
-        if body is None:
-            raise Exception("Empty body for while loop")
-        self.add_statement({"type": "do_while", "condition": condition, "body": body})
+    def add_do_while(self, condition, body: SeqCGenerator):
+        assert body is not None
+        complexity = body.estimate_complexity() + 5  # penalty for loop overhead
+        self.add_statement(
+            {
+                "type": "do_while",
+                "condition": condition,
+                "body": body,
+                "complexity": complexity,
+            }
+        )
 
     def add_function_def(self, text):
         self.add_statement({"type": "function_def", "text": text})
 
     def add_variable_declaration(self, variable_name, initial_value=None):
         statement = {"type": "variable_declaration", "variable_name": variable_name}
         if initial_value is not None:
@@ -170,35 +197,38 @@
                 "type": "executeTableEntry",
                 "table_index": ct_index,
                 "latency": latency,
                 "comment": comment,
             }
         )
 
-    def add_play_zero_statement(self, num_samples, device_type, deferred_calls=None):
+    def add_play_zero_statement(
+        self,
+        num_samples,
+        device_type,
+        deferred_calls: Optional[SeqCGenerator] = None,
+    ):
         """Add a playZero command
 
         If the requested number of samples exceeds the allowed number of samples for
         a single playZero, a tight loop of playZeros will be emitted.
 
         If deferred_calls is passed, the deferred function calls are cleared in the
         context of the added playZero(s). The passed list will be drained.
         """
         if deferred_calls is None:
-            deferred_calls = []
-
-        assert isinstance(deferred_calls, list)
+            deferred_calls = SeqCGenerator()
 
         if isinstance(device_type, str):
             device_type = DeviceType(device_type)
 
         sample_multiple = device_type.sample_multiple
         if num_samples % sample_multiple != 0:
             raise Exception(
-                f"Emitting playZero({num_samples}), which is not divisble by {sample_multiple}, which it should be for {device_type}"
+                f"Emitting playZero({num_samples}), which is not divisible by {sample_multiple}, which it should be for {device_type}"
             )
         if num_samples < device_type.min_play_wave:
             raise LabOneQException(
                 f"Attempting to emit playZero({num_samples}), which is below the "
                 f"minimum waveform length {device_type.min_play_wave} of device "
                 f"'{device_type.value}' (sample multiple is {device_type.sample_multiple})"
             )
@@ -213,68 +243,64 @@
                 {
                     "type": "playZero",
                     "device_type": device_type,
                     "num_samples": samples,
                 }
             )
 
-        def clear_deferred_calls():
-            for call in deferred_calls:
-                self.add_function_call_statement(call["name"], call["args"])
-            del deferred_calls[:]
+        def flush_deferred_calls():
+            self.append_statements_from(deferred_calls)
+            deferred_calls.clear()
 
         if num_samples <= max_play_zero:
             statement_factory(num_samples)
-            clear_deferred_calls()
+            flush_deferred_calls()
         elif num_samples <= 2 * max_play_zero:
             # split in the middle
             half_samples = (num_samples // 2 // 16) * 16
             statement_factory(half_samples)
-            clear_deferred_calls()
+            flush_deferred_calls()
             statement_factory(num_samples - half_samples)
         else:  # non-unrolled loop
-            self._needs_play_zero_counter = True
             num_segments, rest = divmod(num_samples, max_play_zero)
             if 0 < rest < MIN_PLAY_ZERO:
                 chunk = (max_play_zero // 2 // 16) * 16
                 statement_factory(chunk)
-                clear_deferred_calls()
+                flush_deferred_calls()
                 num_samples -= chunk
                 num_segments, rest = divmod(num_samples, max_play_zero)
             if rest > 0:
                 statement_factory(rest)
-                clear_deferred_calls()
-            if deferred_calls:
+                flush_deferred_calls()
+            if deferred_calls.num_statements() > 0:
                 statement_factory(max_play_zero)
-                clear_deferred_calls()
+                flush_deferred_calls()
                 num_segments -= 1
             if num_segments == 1:
                 statement_factory(max_play_zero)
                 return
 
-            inner_loop = SeqCGenerator()
-            inner_loop.add_statement(
+            loop_body = SeqCGenerator()
+            loop_body.add_statement(
                 {
                     "type": "playZero",
                     "device_type": device_type,
                     "num_samples": max_play_zero,
                 }
             )
-            self.add_countdown_loop(
-                self.play_zero_counter_variable_name(), num_segments, inner_loop
-            )
+            self.add_repeat(num_segments, loop_body)
 
     def generate_seq_c(self):
         self._seq_c_text = ""
         for statement in self._statements:
             _logger.debug("processing statement %s", statement)
             self.emit_statement(statement)
         return self._seq_c_text
 
-    def emit_statement(self, statement):
+    def emit_statement(self, statement: SeqCStatement):
         if statement["type"] == "generic_statement":
             if "assign_to" in statement:
                 self._seq_c_text += f"{statement['assign_to']} = "
             self._seq_c_text += statement["function"] + "("
             if "args" in statement:
                 is_first = True
                 for arg in statement["args"]:
@@ -299,30 +325,28 @@
         elif statement["type"] == "variable_assignment":
             self._seq_c_text += statement["variable_name"]
             self._seq_c_text += " = " + str(statement["value"]) + ";\n"
         elif statement["type"] == "variable_increment":
             self._seq_c_text += statement["variable_name"]
             self._seq_c_text += " += " + str(statement["value"]) + ";\n"
 
-        elif statement["type"] == "countdown_loop":
-            self._seq_c_text += (
-                f"{statement['variable_name']} = {statement['num_repeats']};\n"
-            )
-            self._seq_c_text += "do {\n"
-            for line in statement["body"].generate_seq_c().splitlines():
-                self._seq_c_text += "  " + line + "\n"
-            self._seq_c_text += "  " + statement["variable_name"] + " -= 1;\n"
-            self._seq_c_text += "}\nwhile(" + statement["variable_name"] + ");\n"
-
         elif statement["type"] == "do_while":
             self._seq_c_text += "do {\n"
-            for line in statement["body"].generate_seq_c().splitlines():
-                self._seq_c_text += "  " + line + "\n"
+            self._seq_c_text += textwrap.indent(
+                statement["body"].generate_seq_c(), "  "
+            )
             self._seq_c_text += "}\nwhile(" + statement["condition"] + ");\n"
 
+        elif statement["type"] == "repeat":
+            self._seq_c_text += f"repeat ({statement['num_repeats']}) {{\n"
+            self._seq_c_text += textwrap.indent(
+                statement["body"].generate_seq_c(), "  "
+            )
+            self._seq_c_text += "}\n"
+
         elif statement["type"] == "assignWaveIndex":
             wave_channels = self._build_wave_channel_assignment(statement)
             self._seq_c_text += (
                 f'assignWaveIndex({wave_channels},{statement["wave_index"]});\n'
             )
         elif statement["type"] == "playWave":
             wave_channels = self._build_wave_channel_assignment(statement)
@@ -337,15 +361,15 @@
                 self._seq_c_text += f"  // {statement['comment']}"
             self._seq_c_text += "\n"
         elif statement["type"] == "comment":
             self._seq_c_text += "/* " + statement["text"] + " */\n"
         elif statement["type"] == "playZero":
             self._seq_c_text += f"playZero({statement['num_samples']});\n"
 
-    def _gen_wave_declaration_placeholder(self, statement) -> str:
+    def _gen_wave_declaration_placeholder(self, statement: SeqCStatement) -> str:
         dual_channel = statement["signal_type"] in ["iq", "double", "multi"]
         sig_string = statement["wave_id"]
         length = statement["length"]
         device_type = statement["device_type"]
         assert length >= device_type.min_play_wave
         makers_declaration1 = ""
         makers_declaration2 = ""
@@ -372,15 +396,15 @@
         elif dual_channel:
             return f"w{sig_string}_i,w{sig_string}_q"
         elif channel == 1:
             return f'1,"",2,w{sig_string}'
         else:
             return f"w{sig_string}"
 
-    def __key(self):
+    def _key(self):
         tuple_list = []
         for statement in self._statements:
             single_items = []
             for k, v in statement.items():
                 if v is not None:
                     value = v
                     if isinstance(v, SeqCGenerator):
@@ -389,44 +413,86 @@
                     elif (
                         isinstance(v, int)
                         or isinstance(v, float)
                         or isinstance(v, str)
                         or isinstance(v, Enum)
                     ):
                         single_items.append((k, value))
-                    elif "type" in v and v["type"] == "comment":
-                        pass
                     else:
                         single_items.append((k, tuple(value)))
-            if statement["type"] != "comment":
-                tuple_list.append(tuple(single_items))
+            tuple_list.append(tuple(single_items))
         return tuple(tuple_list)
 
-    def needs_play_zero_counter(self):
-        if self._needs_play_zero_counter:
-            return True
-        else:
-            for statement in self._statements:
-                for child in statement.values():
-                    if isinstance(child, SeqCGenerator):
-                        if child.needs_play_zero_counter():
-                            return True
-        return False
-
-    def play_zero_counter_variable_name(self):
-        return PLAY_ZERO_COUNTER_VARIABLE
-
     def __hash__(self):
-        return hash(self.__key())
+        return hash(self._key())
 
     def __eq__(self, other):
         if isinstance(other, SeqCGenerator):
-            return self.__key() == other.__key()
+            return self._key() == other._key()
         return NotImplemented
 
     def __repr__(self):
         retval = "SeqCGenerator("
         for statement in self._statements:
             retval += str(statement) + ","
 
         retval += ")"
         return retval
+
+    def compressed(self):
+        statement_hashes = [hash(k) for k in self._key()]
+        statement_by_hash = {}
+        for h, s in zip(statement_hashes, self._statements):
+            if h in statement_by_hash and statement_by_hash[h] != s:
+                _logger.warning("hash collision detected, skipping code compression")
+                return self
+            statement_by_hash[h] = s
+
+        def cost_function(r: Run):
+            complexity = sum(statement_by_hash[h].get("complexity", 1) for h in r.word)
+            return -(r.count - 1) * complexity + 2
+
+        compressed_statements = compressor_core(statement_hashes, cost_function)
+        retval = SeqCGenerator()
+        for cs in compressed_statements:
+            if isinstance(cs, Run):
+                body = SeqCGenerator()
+                for statement_hash in cs.word:
+                    body.add_statement(statement_by_hash[statement_hash])
+                retval.add_repeat(cs.count, body)
+            else:
+                retval.add_statement(statement_by_hash[cs])
+
+        return retval
+
+
+def merge_generators(generators, compress=True) -> SeqCGenerator:
+    generator_hashes = [hash(g) for g in generators]
+    # todo: cannot check for hash collisions, SeqCGenerator.__eq__ also uses hash
+    generator_by_hash = {h: g for h, g in zip(generator_hashes, generators)}
+
+    retval = SeqCGenerator()
+    if compress:
+
+        def cost_function(r: Run):
+            complexity = sum(generator_by_hash[h].estimate_complexity() for h in r.word)
+            return -(r.count - 1) * complexity + 2
+
+        compressed_generators = compressor_core(generator_hashes, cost_function)
+
+        for cg in compressed_generators:
+            if isinstance(cg, Run):
+                if len(cg.word) == 1:
+                    body = generator_by_hash[cg.word[0]]
+                else:
+                    body = SeqCGenerator()
+                    for gen_hash in cg.word:
+                        body.append_statements_from(generator_by_hash[gen_hash])
+                retval.add_repeat(cg.count, body.compressed())
+            else:
+                retval.append_statements_from(generator_by_hash[cg])
+
+        # optional: we might add a 2nd pass here on the merged generator, finding patterns
+        # that partially span across multiple of the original parts.
+        # retval = retval.compressed()
+
+    return retval
```

## laboneq/compiler/code_generator/seqc_tracker.py

```diff
@@ -1,24 +1,24 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
-from typing import Any, Dict, List, Union
+from typing import List
 
 from laboneq.compiler.code_generator.seq_c_generator import SeqCGenerator
 from laboneq.compiler.common.awg_sampled_event import AWGEvent
 from laboneq.compiler.common.device_type import DeviceType
 
 
 class SeqCTracker:
     def __init__(
         self,
         init_generator: SeqCGenerator,
-        deferred_function_calls: List[Union[str, Dict[str, List[Any]]]],
+        deferred_function_calls: SeqCGenerator,
         sampling_rate: float,
         delay: float,
         device_type: DeviceType,
         emit_timing_comments: bool,
         logger,
     ) -> None:
         self.deferred_function_calls = deferred_function_calls
@@ -55,40 +55,39 @@
             self.current_loop_stack_generator().add_play_zero_statement(
                 play_zero_samples, self.device_type, self.deferred_function_calls
             )
             self.current_time += play_zero_samples
 
         return self.current_time
 
-    def clear_deferred_function_calls(self):
+    def flush_deferred_function_calls(self):
         """Emit the deferred function calls *now*."""
-        if len(self.deferred_function_calls) > 0:
-            for call in self.deferred_function_calls:
-                self.current_loop_stack_generator().add_function_call_statement(
-                    call["name"], call["args"]
-                )
-            self.deferred_function_calls = []
+        if self.deferred_function_calls.num_statements() > 0:
+            self.current_loop_stack_generator().append_statements_from(
+                self.deferred_function_calls
+            )
+            self.deferred_function_calls.clear()
 
     def force_deferred_function_calls(self):
         """There may be deferred function calls issued *at the end of the sequence*.
         There will be no playWave or playZero that could flush them, so this function
         will force a flush.
 
         This function should not be needed anywhere but at the end of the sequence.
         (In the future, maybe at the end of a loop iteration?)
         """
-        if self.deferred_function_calls:
+        if self.deferred_function_calls.num_statements() > 0:
             # Flush any remaining deferred calls (ie those that should execute at the
             # end of the sequence)
             if self.device_type == DeviceType.SHFQA:
                 # SHFQA does not support waitWave()
                 self.add_play_zero_statement(32)
             else:
-                self.add_function_call_statement("waitWave", [])
-            self.clear_deferred_function_calls()
+                self.add_function_call_statement("waitWave")
+            self.flush_deferred_function_calls()
 
     def add_timing_comment(self, end_samples):
         if self.emit_timing_comments:
             start_time_ns = (
                 round((self.current_time / self.sampling_rate - self.delay) * 1e10) / 10
             )
             end_time_ns = (
@@ -101,15 +100,15 @@
     def add_comment(self, comment):
         self.current_loop_stack_generator().add_comment(comment)
 
     def add_function_call_statement(
         self, name, args=None, assign_to=None, deferred=False
     ):
         if deferred:
-            self.deferred_function_calls.append({"name": name, "args": args})
+            self.deferred_function_calls.add_function_call_statement(name, args)
         else:
             self.current_loop_stack_generator().add_function_call_statement(
                 name, args, assign_to
             )
 
     def add_play_zero_statement(self, num_samples):
         self.current_loop_stack_generator().add_play_zero_statement(
@@ -133,24 +132,26 @@
         self.current_loop_stack_generator().add_variable_assignment(
             variable_name, value
         )
 
     def add_variable_increment(self, variable_name, value):
         self.current_loop_stack_generator().add_variable_increment(variable_name, value)
 
-    def add_assign_wave_index_statement(
-        self, device_type: DeviceType, signal_type, wave_id, wave_index, channel
-    ):
-        self.current_loop_stack_generator().add_assign_wave_index_statement(
-            device_type, signal_type, wave_id, wave_index, channel
-        )
-
-    def append_loop_stack_generator(self, outer=False, always=False, generator=None):
+    # todo: remove `always` argument
+    def append_loop_stack_generator(self, always=False, generator=None):
         if not generator:
             generator = SeqCGenerator()
-        if outer:
-            self.loop_stack_generators.append([generator])
-        elif always or self.loop_stack_generators[-1][-1].num_statements() > 0:
+
+        top_of_stack = self.loop_stack_generators[-1]
+        if always or len(top_of_stack) == 0 or top_of_stack[-1].num_statements() > 0:
             self.loop_stack_generators[-1].append(generator)
 
+    def push_loop_stack_generator(self, generator=None):
+        self.loop_stack_generators.append([])
+        self.append_loop_stack_generator(generator)
+
     def pop_loop_stack_generators(self):
-        return self.loop_stack_generators.pop()
+        top_of_stack = self.loop_stack_generators.pop()
+        for i, gen in enumerate(top_of_stack):
+            compressed = gen.compressed()
+            top_of_stack[i] = compressed
+        return top_of_stack
```

## laboneq/compiler/common/signal_obj.py

```diff
@@ -11,22 +11,40 @@
 if TYPE_CHECKING:
     from laboneq.compiler.common.awg_info import AWGInfo
     from laboneq.compiler.common.device_type import DeviceType
 
 
 @dataclass(init=True, repr=True, order=True)
 class SignalObj:
+    """A collection of a signal's properties relevant for code generation. The delay
+    fields are in seconds and their meaning is as follows:
+    - start_delay: the delay from the trigger to the start of the sequence (lead time),
+      realized as initial playZeros; includes lead time and precompensation
+    - delay_signal: user-defined additional delay, realized by adding to the initial
+      playZeros; rounded to the sequencer grid (sample_multiple)
+    - total_delay: the sum of the above two fields, plus delays generated during code
+      generation, e.g., relative delay between a play and acquire pulse
+    - on_device_delay: delay on the device, realized by delay nodes and independent
+      from the sequencer, generated during code generation, e.g., relative delay between
+      a play and acquire pulse; in addition to potential port delays specified via the
+      calibration
+    - port_delay: port delay specified via the calibration; realized via the device node
+      in addition to potential on-device delays
+    """
+
     id: str
     sampling_rate: float
     start_delay: float
     delay_signal: float
     signal_type: str
     device_id: str
     device_type: DeviceType
     oscillator_frequency: float = None  # for software modulation only
     pulses: List = field(default_factory=list)
     channels: List = field(default_factory=list)
     awg: AWGInfo = None
     total_delay: float = None
     on_device_delay: float = 0
+    port_delay: float = 0
     mixer_type: Optional[MixerType] = None
     hw_oscillator: Optional[str] = None
+    is_qc: Optional[bool] = None
```

## laboneq/compiler/experiment_access/device_info.py

```diff
@@ -1,16 +1,18 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass
+from typing import Optional
 
 
 @dataclass
 class DeviceInfo:
     id: str
     device_type: str
     serial: str
     server: str
     interface: str
     reference_clock_source: str
+    is_qc: Optional[bool]
```

## laboneq/compiler/experiment_access/dsl_loader.py

```diff
@@ -66,26 +66,28 @@
             driver = type(device).__name__.lower()
             serial = device.address
             interface = device.interface
             is_global_leader = 0
             if global_leader_device_id == device.uid:
                 is_global_leader = 1
             reference_clock_source = getattr(device, "reference_clock_source", None)
+            is_qc = getattr(device, "is_qc", None)
 
             self.add_device(
                 device.uid,
                 driver,
                 serial,
                 server,
                 interface,
                 is_global_leader,
                 reference_clock,
                 reference_clock_source=None
                 if reference_clock_source is None
                 else reference_clock_source.value,
+                is_qc=is_qc,
             )
 
             for connection in device.connections:
                 multiplex_key = (
                     device.uid,
                     connection.local_port,
                     connection.direction.value,
```

## laboneq/compiler/experiment_access/experiment_dao.py

```diff
@@ -102,15 +102,15 @@
 
     def signals(self):
         return sorted([s["signal_id"] for s in self._data["signals"].values()])
 
     def devices(self):
         return [d["id"] for d in self._data["devices"].values()]
 
-    def global_leader_device(self):
+    def global_leader_device(self) -> str:
         try:
             return next(
                 d for d in self._data["devices"].values() if d.get("is_global_leader")
             )["id"]
         except StopIteration:
             return None
 
@@ -119,23 +119,24 @@
         return [
             "id",
             "device_type",
             "serial",
             "server",
             "interface",
             "reference_clock_source",
+            "is_qc",
         ]
 
-    def device_info(self, device_id):
+    def device_info(self, device_id) -> Optional[DeviceInfo]:
         device_info = self._data["devices"].get(device_id)
         if device_info is not None:
             return DeviceInfo(**{k: device_info[k] for k in self._device_info_keys()})
         return None
 
-    def device_infos(self):
+    def device_infos(self) -> List[DeviceInfo]:
         return [
             DeviceInfo(**{k: device_info[k] for k in self._device_info_keys()})
             for device_info in self._data["devices"].values()
         ]
 
     def device_reference_clock(self, device_id):
         return self._data["devices"][device_id].get("reference_clock")
```

## laboneq/compiler/experiment_access/json_dumper.py

```diff
@@ -31,15 +31,15 @@
 
     device_entries = {}
     reference_clock = None
     for device in experiment_dao.devices():
         device_info = experiment_dao.device_info(device)
 
         device_entry = {}
-        for key in ["id", "serial", "interface", "reference_clock_source"]:
+        for key in ["id", "serial", "interface", "reference_clock_source", "is_qc"]:
             if getattr(device_info, key) is not None:
                 device_entry[key] = getattr(device_info, key)
         device_entry["driver"] = device_info.device_type.lower()
 
         oscillator_ids = experiment_dao.device_oscillators(device)
 
         if len(oscillator_ids) > 0:
```

## laboneq/compiler/experiment_access/json_loader.py

```diff
@@ -82,21 +82,24 @@
                 "reference_clock_source" in device
                 and device["reference_clock_source"] is not None
             ):
                 reference_clock_source = device["reference_clock_source"]
             else:
                 reference_clock_source = None
 
+            is_qc = device.get("is_qc")
+
             self.add_device(
                 device["id"],
                 driver,
                 serial,
                 server,
                 interface,
                 reference_clock_source=reference_clock_source,
+                is_qc=is_qc,
             )
 
             if "oscillators_list" in device:
                 for oscillator_ref in device["oscillators_list"]:
                     self.add_device_oscillator(device["id"], oscillator_ref["$ref"])
 
     def _load_oscillator(self, experiment):
```

## laboneq/compiler/experiment_access/loader_base.py

```diff
@@ -119,24 +119,26 @@
         device_type,
         serial,
         server,
         interface,
         is_global_leader=None,
         reference_clock=None,
         reference_clock_source=None,
+        is_qc=None,
     ):
         self._devices[device_id] = {
             "id": device_id,
             "device_type": device_type,
             "serial": serial,
             "server": server,
             "interface": interface,
             "is_global_leader": is_global_leader,
             "reference_clock": reference_clock,
             "reference_clock_source": reference_clock_source,
+            "is_qc": is_qc,
         }
 
     def add_oscillator(self, oscillator_id, frequency, frequency_param, is_hardware):
         self._oscillators[oscillator_id] = {
             "id": oscillator_id,
             "frequency": frequency,
             "frequency_param": frequency_param,
```

## laboneq/compiler/new_scheduler/case_schedule.py

```diff
@@ -1,11 +1,11 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-from typing import Dict, Iterator, List, Optional
+from typing import Dict, Iterator, List
 
 from attrs import asdict, define
 
 from laboneq.compiler import CompilerSettings
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.common.play_wave_type import PlayWaveType
 from laboneq.compiler.new_scheduler.section_schedule import SectionSchedule
@@ -16,17 +16,20 @@
     state: int
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
+        assert self.length is not None
+        assert self.absolute_start is not None
+
         events = super().generate_event_list(
             start, max_events, id_tracker, expand_loops, settings
         )
         section_start = events[0]
         assert section_start["event_type"] == EventType.SECTION_START
         section_start["state"] = self.state
         return events
@@ -39,21 +42,22 @@
 
 class EmptyBranch(CaseSchedule):
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         section_start, *rest, section_end = super().generate_event_list(
             start, max_events, id_tracker, expand_loops, settings
         )
         assert self.length is not None
+        assert self.absolute_start is not None
         assert len(rest) == 0
         assert section_start["event_type"] == EventType.SECTION_START
         assert section_end["event_type"] == EventType.SECTION_END
         if max_events <= 2:
             return [section_start, section_end]
 
         d = {
@@ -87,9 +91,10 @@
                         **d,
                     },
                 ]
             )
 
         return [section_start, *delay_events, section_end]
 
-    def _calculate_timing(self, *_, **__):
+    def _calculate_timing(self, _schedule_data, start: int, *__, **___) -> int:
         self.length = self.grid
+        return start
```

## laboneq/compiler/new_scheduler/interval_schedule.py

```diff
@@ -23,24 +23,32 @@
     Internally, the schedule is represented as a tree. Nodes of the tree are instances
     of :`~.IntervalSchedule`. An `IntervalSchedule` is an abstraction of a 'box' that
     occupies a certain number of signals (`IntervalSchedule.signals`) for a specific
     duration (`IntervalSchedule.length`). In particular, an `IntervalSchedule` may
     represent a single pulse, or a section (with possible subsections). Loops also are
     similarly represented as nested schedules.
 
-    Notably, each `IntervalSchedule` does not store its start time. Instead, the parent
-    stores the start times of its children in `self.children_start`. These time stamps
-    are relative to the start time of the parent itself, which allows us to move an
-    entire sub-schedule (including its children) in time without touching any of its
-    attributes. This 'shifting' in time is valid as long as the start time of a sub-
+    Notably, each `IntervalSchedule` does initially not store its start time. Instead,
+    the parent stores the start times of its children in `self.children_start`. These
+    time stamps are relative to the start time of the parent itself, which allows us to
+    move an entire sub-schedule (including its children) in time without touching any of
+    its attributes. This 'shifting' in time is valid as long as the start time of a sub-
     schedule, in absolute terms, remains on the grid required by the sub-schedule
     (`IntervalSchedule.grid`). For example, if a section must be aligned to the _system
     grid_ of 4 ns, then we are free to move. One exception are match sections, which
     need a minimal distance to their acquire event; `_calculate_timing` thus has a
     parameter `start_may_change` to express that the given start time may not be final.
+
+    Gradually, as right-alignments and RepetitionMode.AUTO timings are resolved,
+    intervals are notified about the fact that their absolute start position (after the
+    trigger) is resolved and thus can, for example, create constraints for acquire/match
+    pairs. The absolute time (in case of loops for the first iteration) is stored in
+    `absolute_time`. While this property is somewhat redundant, it also serves as a flag
+    to indicate that the timing for this subtree has already be determined and thus
+    allows for an early stop.
     """
 
     #: The children of this interval.
     children: List[IntervalSchedule] = field(factory=list)
 
     #: The time grid along which the interval may be scheduled/shifted. Expressed in
     #: tiny samples.
@@ -59,14 +67,17 @@
 
     #: The signals reserved by this interval.
     signals: Set[str] = field(factory=set)
 
     #: The start points of the children *relative to the start of the interval itself*.
     children_start: Deferred[List[int]] = None
 
+    #: The absolute start time (since trigger) of the interval in tiny samples.
+    absolute_start: Deferred[int] = None
+
     #: Whether the schedule can be cached, for example, if no match statements are used
     #: in the section which may lead to timing differences.
     cacheable: bool = True
 
     def __attrs_post_init__(self):
         for child in self.children:
             self.grid = lcm(self.grid, child.grid)
@@ -88,24 +99,24 @@
                 self.cacheable = False
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         raise NotImplementedError
 
     def children_events(
         self,
         start: int,
         max_events: int,
-        settings: Optional[CompilerSettings],
+        settings: CompilerSettings,
         id_tracker: Iterator[int],
         expand_loops: bool,
     ) -> List[List[Dict]]:
 
         event_list_nested = []
         assert self.children_start is not None
         assert self.length is not None
@@ -126,23 +137,41 @@
         return event_list_nested
 
     def calculate_timing(
         self,
         schedule_data: ScheduleData,  # type: ignore # noqa: F821
         start: int,
         start_may_change: bool,
-    ):
+    ) -> int:
         if self.children_start is not None:
             # We have already calculated the timing.
-            return
+            return start
         self.children_start = [0] * len(self.children)
-        self._calculate_timing(schedule_data, start, start_may_change)
+        # Timing calculation may find that the suggested start is too early to fulfill
+        # constraints; give it a chance to return a better suiting start time
+        start = self._calculate_timing(schedule_data, start, start_may_change)
+        if not start_may_change:
+            self.on_absolute_start_time_fixed(start, schedule_data)
+        return start
 
-    def _calculate_timing(self, *_, **__):
+    def _calculate_timing(self, *_, **__) -> int:
         raise NotImplementedError()
 
+    def on_absolute_start_time_fixed(
+        self, start: int, schedule_data: ScheduleData  # type: ignore # noqa: F821
+    ):
+        """Notify schedule that its absolute start time has been determined, for
+        example for a child of a right-aligned section"""
+        if self.absolute_start is not None:
+            assert start == self.absolute_start
+            return
+        self.absolute_start = start
+        assert self.children_start is not None
+        for c, s in zip(self.children, self.children_start):
+            c.on_absolute_start_time_fixed(start + s, schedule_data)
+
     def __hash__(self):
         # Hashing an interval schedule is expensive! We need to recursively hash the
         # children, potentially traversing the entire section tree.
         # Using `IntervalSchedule` as keys in a dictionary, or storing it in a set is
         # most likely a bad idea.
         raise NotImplementedError
```

## laboneq/compiler/new_scheduler/loop_iteration_schedule.py

```diff
@@ -1,13 +1,13 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
-from typing import Dict, Iterator, List, Optional
+from typing import Dict, Iterator, List
 
 from attrs import asdict, define, evolve
 
 from laboneq.compiler.common.compiler_settings import CompilerSettings
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.new_scheduler.section_schedule import SectionSchedule
 
@@ -27,18 +27,19 @@
         pass
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.length is not None
+        assert self.absolute_start is not None
         common = {
             "section_name": self.section,
             "iteration": self.iteration,
             "num_repeats": self.num_repeats,
             "nesting_level": 0,
         }
         end = start + self.length
```

## laboneq/compiler/new_scheduler/loop_schedule.py

```diff
@@ -22,15 +22,15 @@
     sweep_parameters: List[Dict]
     iterations: int
     repetition_mode: Optional[RepetitionMode]
     repetition_time: Optional[int]
 
     def _calculate_timing(
         self, schedule_data: ScheduleData, loop_start: int, start_may_change: bool  # type: ignore # noqa: F821
-    ):
+    ) -> int:
         adjusted_rep_time = (
             None
             if self.repetition_time is None
             else ceil_to_grid(self.repetition_time, self.grid)
         )
 
         def check_repetition_time(child_length):
@@ -98,25 +98,27 @@
                         longest = length
             if repetition_mode == RepetitionMode.AUTO:
                 for c in self.children:
                     assert isinstance(c, SectionSchedule)
                     c.adjust_length(longest)
                 self.children_start = [longest * i for i in range(len(self.children))]
             self._calculate_length(schedule_data)
+        return loop_start
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.children_start is not None
         assert self.length is not None
+        assert self.absolute_start is not None
 
         # We'll later wrap the child events in some extra events, see below.
         max_events -= 3
 
         if not self.compressed:  # unrolled loop
             children_events = list(
                 self.children_events(
```

## laboneq/compiler/new_scheduler/match_schedule.py

```diff
@@ -1,55 +1,195 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-from typing import Dict, Iterator, List, Optional
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Dict, Iterable, Iterator, List
 
 from attrs import define
+from zhinst.utils.feedback_model import (
+    FeedbackPath,
+    PQSCMode,
+    QAType,
+    QCCSFeedbackModel,
+    SGType,
+    get_feedback_system_description,
+)
 
 from laboneq.compiler import CompilerSettings
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.new_scheduler.case_schedule import CaseSchedule
-from laboneq.compiler.new_scheduler.schedule_data import ScheduleData
 from laboneq.compiler.new_scheduler.section_schedule import SectionSchedule
+from laboneq.compiler.new_scheduler.utils import ceil_to_grid
 from laboneq.core.exceptions.laboneq_exception import LabOneQException
 
+if TYPE_CHECKING:
+    from laboneq.compiler.new_scheduler.schedule_data import ScheduleData
+
+
+def _compute_start_with_latency(
+    schedule_data: ScheduleData,
+    start: int,
+    local: bool,
+    handle: str,
+    section: str,
+    signals: Iterable[str],
+    grid: int,
+) -> int:
+    acquire_pulse = schedule_data.acquire_pulses.get(handle)
+    if not acquire_pulse:
+        raise LabOneQException(
+            f"No acquire found for Match section '{section}' with handle"
+            f" '{handle}'."
+        )
+    acquire_pulse = acquire_pulse[-1]
+    if acquire_pulse.absolute_start is None:
+        # For safety reasons; this should never happen, i.e., being caught before
+        raise LabOneQException(
+            f"Match section '{section}' with handle '{handle}' can not be"
+            " scheduled because the corresponding acquire is within"
+            " a right-aligned section or within a loop with repetition mode AUTO."
+        )
+    assert acquire_pulse.length is not None
+
+    earliest_execute_table_entry = 0
+
+    # Calculate the end of the integration in samples from trigger. The following
+    # elements need to be considered:
+    # - The start time (in samples from trigger) of the acquisition
+    # - The length of the integration kernel
+    # - The lead time of the acquisition AWG
+    # - The setting of the delay_signal parameter for the acquisition AWG
+    # - The setting of the port_delay parameter for the acquisition device
+
+    qa_signal_obj = schedule_data.signal_objects[acquire_pulse.pulse.signal_id]
+
+    qa_device_type = qa_signal_obj.device_type
+    qa_sampling_rate = qa_signal_obj.sampling_rate
+
+    if qa_signal_obj.is_qc:
+        toolkit_qatype = QAType.SHFQC
+    else:
+        toolkit_qatype = {"shfqa": QAType.SHFQA, "shfqc": QAType.SHFQC}.get(
+            qa_device_type.str_value
+        )
+    if toolkit_qatype is None:
+        raise LabOneQException("Feedback not supported for an aquisition on a UHFQA.")
+
+    acq_start = acquire_pulse.absolute_start * schedule_data.TINYSAMPLE
+    acq_length = acquire_pulse.length * schedule_data.TINYSAMPLE
+    qa_lead_time = qa_signal_obj.start_delay or 0.0
+    qa_delay_signal = qa_signal_obj.delay_signal or 0.0
+    qa_port_delay = qa_signal_obj.port_delay or 0.0
+
+    acquire_end_in_samples = round(
+        (acq_start + acq_length + qa_lead_time + qa_delay_signal + qa_port_delay)
+        * qa_sampling_rate
+    )
+
+    for signal in signals:
+        sg_signal_obj = schedule_data.signal_objects[signal]
+        sg_device_type = sg_signal_obj.device_type
+        if sg_signal_obj.is_qc:
+            toolkit_sgtype = SGType.SHFQC
+        else:
+            toolkit_sgtype = {
+                "hdawg": SGType.HDAWG,
+                "shfsg": SGType.SHFSG,
+                "shfqc": SGType.SHFQC,
+            }[sg_device_type.str_value]
+
+        time_of_arrival_at_register = QCCSFeedbackModel(
+            description=get_feedback_system_description(
+                generator_type=toolkit_sgtype,
+                analyzer_type=toolkit_qatype,
+                pqsc_mode=None if local else PQSCMode.REGISTER_FORWARD,
+                feedback_path=FeedbackPath.INTERNAL if local else FeedbackPath.ZSYNC,
+            )
+        ).get_latency(acquire_end_in_samples)
+
+        sg_seq_rate = schedule_data.sampling_rate_tracker.sequencer_rate_for_device(
+            sg_signal_obj.device_id
+        )
+        sg_seq_dt_for_latency_in_ts = round(
+            1 / (2 * sg_seq_rate * schedule_data.TINYSAMPLE)
+        )
+        latency_in_ts = time_of_arrival_at_register * sg_seq_dt_for_latency_in_ts
+
+        # Calculate the shift of compiler zero time for the SG; we may subtract this
+        # from the time of arrival (which is measured since the trigger) to get the
+        # start point in compiler time. The following elements need to be considered:
+        # - The lead time of the acquisition AWG
+        # - The setting of the delay_signal parameter for the acquisition AWG
+        # - The time of arrival computed above
+        # todo(JL): Check whether also the port_delay can be added - probably not.
+
+        sg_lead_time = sg_signal_obj.start_delay or 0.0
+        sg_delay_signal = sg_signal_obj.delay_signal or 0.0
+
+        earliest_execute_table_entry = max(
+            earliest_execute_table_entry,
+            ceil_to_grid(
+                latency_in_ts
+                - round((sg_lead_time + sg_delay_signal) / schedule_data.TINYSAMPLE),
+                grid,
+            ),
+        )
+
+    return max(earliest_execute_table_entry, start)
+
 
 @define(kw_only=True, slots=True)
 class MatchSchedule(SectionSchedule):
     handle: str
     local: bool
 
     def __attrs_post_init__(self):
         super().__attrs_post_init__()
         self.cacheable = False
 
     def _calculate_timing(
         self, schedule_data: ScheduleData, start: int, start_may_change
-    ):
+    ) -> int:
         if start_may_change:
             raise LabOneQException(
-                f"Match Section '{self.section}' may not be a subsection of a right-aligned section."
+                f"Match section '{self.section}' with handle '{self.handle}' may not be"
+                " a subsection of a right-aligned section or within a loop with"
+                " repetition mode AUTO."
             )
 
+        start = _compute_start_with_latency(
+            schedule_data,
+            start,
+            self.local,
+            self.handle,
+            self.section,
+            self.signals,
+            self.grid,
+        )
+
         for c in self.children:
             assert isinstance(c, CaseSchedule)
-            c.calculate_timing(schedule_data, start, start_may_change)
+            child_start = c.calculate_timing(schedule_data, start, start_may_change)
+            assert child_start == start
             # Start of children stays at 0
 
         self._calculate_length(schedule_data)
+        return start
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.length is not None
+        assert self.absolute_start is not None
         events = super().generate_event_list(
             start, max_events, id_tracker, expand_loops, settings
         )
         if len(events) == 0:
             return []
         section_start_event = events[0]
         assert section_start_event["event_type"] == EventType.SECTION_START
```

## laboneq/compiler/new_scheduler/oscillator_schedule.py

```diff
@@ -1,11 +1,11 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-from typing import Dict, Iterator, List, Optional
+from typing import Dict, Iterator, List
 
 from attrs import define
 
 from laboneq.compiler import CompilerSettings
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.new_scheduler.interval_schedule import IntervalSchedule
 
@@ -26,18 +26,19 @@
     iteration: int
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.length is not None
+        assert self.absolute_start is not None
         retval = []
         for param, osc, value in zip(self.params, self.oscillators, self.values):
             start_id = next(id_tracker)
             retval.extend(
                 [
                     {
                         "event_type": EventType.SET_OSCILLATOR_FREQUENCY_START,
@@ -57,13 +58,14 @@
                         "id": next(id_tracker),
                         "chain_element_id": start_id,
                     },
                 ]
             )
         return retval
 
-    def _calculate_timing(self, *_, **__):
+    def _calculate_timing(self, _schedule_data, start: int, *__, **___) -> int:
         # Length must be set via parameter, so nothing to do here
         assert self.length is not None
+        return start
 
     def __hash__(self):
         super().__hash__()
```

## laboneq/compiler/new_scheduler/phase_reset_schedule.py

```diff
@@ -1,12 +1,12 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 
-from typing import Dict, Iterator, List, Optional, Tuple
+from typing import Dict, Iterator, List, Tuple
 
 from attrs import define
 
 from laboneq.compiler import CompilerSettings
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.new_scheduler.interval_schedule import IntervalSchedule
 
@@ -18,17 +18,19 @@
     reset_sw_oscillators: bool
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
+        assert self.length is not None
+        assert self.absolute_start is not None
         events = [
             {
                 "event_type": EventType.RESET_HW_OSCILLATOR_PHASE,
                 "time": start,
                 "section_name": self.section,
                 "id": next(id_tracker),
                 "duration": duration,
@@ -45,13 +47,14 @@
                     "section_name": self.section,
                     "id": next(id_tracker),
                 }
             )
 
         return events
 
-    def _calculate_timing(self, *_, **__):
+    def _calculate_timing(self, _schedule_data, start: int, *__, **___) -> int:
         # Length must be set via parameter, so nothing to do here
         assert self.length is not None
+        return start
 
     def __hash__(self):
         super().__hash__()
```

## laboneq/compiler/new_scheduler/pulse_schedule.py

```diff
@@ -31,18 +31,19 @@
     markers: Any = None
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.length is not None
+        assert self.absolute_start is not None
         params_list = []
         for f in ("length_param", "amplitude_param", "phase_param", "offset_param"):
             if getattr(self.pulse, f) is not None:
                 params_list.append(getattr(self.pulse, f))
 
         play_wave_id = self.pulse.pulse_id or "delay"
 
@@ -152,43 +153,62 @@
                 "event_type": EventType.PLAY_END,
                 "time": start + self.length,
                 "id": next(id_tracker),
                 **d,
             },
         ]
 
-    def _calculate_timing(self, *_, **__):
+    def _calculate_timing(
+        self,
+        schedule_data: ScheduleData,  # type: ignore # noqa: F821
+        start: int,
+        start_may_change: bool,
+    ) -> int:
         # Length must be set via parameter, so nothing to do here
         assert self.length is not None
 
+        if (
+            self.is_acquire
+            and self.pulse is not None
+            and self.pulse.acquire_params is not None
+            and self.pulse.acquire_params.handle
+        ):
+            schedule_data.acquire_pulses.setdefault(
+                self.pulse.acquire_params.handle, []
+            ).append(self)
+
+        return start
+
     def __hash__(self):
         return super().__hash__()
 
 
 @define(kw_only=True, slots=True)
 class PrecompClearSchedule(IntervalSchedule):
     pulse: PulseSchedule
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.length is not None
+        assert self.absolute_start is not None
         return [
             {
                 "event_type": EventType.RESET_PRECOMPENSATION_FILTERS,
                 "time": start,
                 "signal_id": self.pulse.pulse.signal_id,
                 "section_name": self.pulse.section,
                 "id": next(id_tracker),
             }
         ]
 
-    def _calculate_timing(self, *_, **__):
+    def _calculate_timing(self, _schedule_data, start: int, *__, **___) -> int:
         self.length = 0
+        return start
 
     def __hash__(self):
         super().__hash__()
```

## laboneq/compiler/new_scheduler/reserve_schedule.py

```diff
@@ -7,16 +7,17 @@
 
 
 class ReserveSchedule(IntervalSchedule):
     @classmethod
     def create(cls, signal, grid):
         return cls(grid=grid, signals={signal})
 
-    def _calculate_timing(self, *_, **__):
+    def _calculate_timing(self, _schedule_data, start: int, *__, **___) -> int:
         self.length = 0
+        return start
 
     def generate_event_list(self, *_, **__) -> List[Dict]:
         assert self.length is not None
         return []
 
     def __hash__(self):
         super().__hash__()
```

## laboneq/compiler/new_scheduler/root_schedule.py

```diff
@@ -1,44 +1,44 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-from typing import Dict, Iterator, List, Optional
+from typing import Dict, Iterator, List
 
 from laboneq.compiler import CompilerSettings
 from laboneq.compiler.new_scheduler.interval_schedule import IntervalSchedule
 from laboneq.compiler.new_scheduler.utils import ceil_to_grid
 
 
 class RootSchedule(IntervalSchedule):
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.length is not None
+        assert self.absolute_start is not None
         children_events = self.children_events(
             start, max_events - 2, settings, id_tracker, expand_loops
         )
 
         return [e for l in children_events for e in l]
 
     def _calculate_timing(
         self,
         schedule_data,  # type: ignore # noqa: F821
         start: int,
         start_may_change: bool,
-    ):
+    ) -> int:
         length = 0
-        for child, child_start in zip(
-            self.children,
-            self.children_start,  # pyright: ignore[reportGeneralTypeIssues]
-        ):
-            child.calculate_timing(schedule_data, start + child_start, False)
+        for child in self.children:
+            child.calculate_timing(schedule_data, 0, False)
             assert child.length is not None
             length = max(length, child.length)
+            child.on_absolute_start_time_fixed(0, schedule_data)
         self.length = ceil_to_grid(length, self.grid)
+        return start
 
     def __hash__(self):
         super().__hash__()
```

## laboneq/compiler/new_scheduler/schedule_data.py

```diff
@@ -1,21 +1,27 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Dict, List
 
 if TYPE_CHECKING:
     from laboneq.compiler.common.compiler_settings import CompilerSettings
+    from laboneq.compiler.common.signal_obj import SignalObj
     from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
+    from laboneq.compiler.new_scheduler.pulse_schedule import PulseSchedule
+    from laboneq.compiler.scheduler.sampling_rate_tracker import SamplingRateTracker
 
 
 @dataclass
 class ScheduleData:
     experiment_dao: ExperimentDAO
-    settings: Optional[CompilerSettings]
+    sampling_rate_tracker: SamplingRateTracker
+    settings: CompilerSettings
+    acquire_pulses: Dict[str, List[PulseSchedule]] = field(default_factory=dict)
+    signal_objects: Dict[str, SignalObj] = field(default_factory=dict)
     TINYSAMPLE: float = field(init=False)
 
     def __post_init__(self):
-        self.TINYSAMPLE = getattr(self.settings, "TINYSAMPLE", 1 / 3600000e6)
+        self.TINYSAMPLE = self.settings.TINYSAMPLE
```

## laboneq/compiler/new_scheduler/scheduler.py

```diff
@@ -1,18 +1,29 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
+import copy
 import dataclasses
 import functools
 import itertools
 import logging
 from dataclasses import replace
-from typing import Any, Dict, FrozenSet, Iterable, List, Optional, Set, Tuple
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Dict,
+    FrozenSet,
+    Iterable,
+    List,
+    Optional,
+    Set,
+    Tuple,
+)
 
 import numpy as np
 
 from laboneq._observability.tracing import trace
 from laboneq.compiler.common.compiler_settings import CompilerSettings
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.common.event_type import EventType
@@ -36,58 +47,76 @@
     PrecompClearSchedule,
     PulseSchedule,
 )
 from laboneq.compiler.new_scheduler.reserve_schedule import ReserveSchedule
 from laboneq.compiler.new_scheduler.root_schedule import RootSchedule
 from laboneq.compiler.new_scheduler.schedule_data import ScheduleData
 from laboneq.compiler.new_scheduler.section_schedule import SectionSchedule
-from laboneq.compiler.new_scheduler.utils import ceil_to_grid, lcm, round_to_grid
+from laboneq.compiler.new_scheduler.utils import (
+    assert_valid,
+    ceil_to_grid,
+    lcm,
+    round_to_grid,
+    to_tinysample,
+)
 from laboneq.compiler.scheduler.sampling_rate_tracker import SamplingRateTracker
 from laboneq.core.exceptions import LabOneQException
 from laboneq.core.types.enums import RepetitionMode, SectionAlignment
 
+if TYPE_CHECKING:
+    from laboneq.compiler.common.signal_obj import SignalObj
+
 _logger = logging.getLogger(__name__)
 
 
 @dataclasses.dataclass
 class RepetitionInfo:
     section: str
     mode: RepetitionMode
     time: Optional[float]
 
 
+# from more_itertools
+def pairwise(iterator):
+    a, b = itertools.tee(iterator)
+    next(b, None)
+    yield from zip(a, b)
+
+
 class Scheduler:
     def __init__(
         self,
         experiment_dao: ExperimentDAO,
         sampling_rate_tracker: SamplingRateTracker,
+        signal_objects: Dict[str, SignalObj],
         # For compatibility with old scheduler, remove once we remove that
         _clock_settings: Optional[Dict] = None,
         settings: Optional[CompilerSettings] = None,
     ):
         self._schedule_data = ScheduleData(
             experiment_dao=experiment_dao,
             settings=settings or CompilerSettings(),
+            sampling_rate_tracker=sampling_rate_tracker,
+            signal_objects=signal_objects,
         )
-
-        self._scheduled_sections = {}
+        self._experiment_dao = experiment_dao
         self._sampling_rate_tracker = sampling_rate_tracker
-        self._system_grid = self.grid(*self._schedule_data.experiment_dao.signals())[1]
+        self._TINYSAMPLE = self._schedule_data.TINYSAMPLE
+
+        self._system_grid = self.grid(*self._experiment_dao.signals())[1]
         self._root_schedule: Optional[IntervalSchedule] = None
+        self._scheduled_sections = {}
 
     @trace("scheduler.run()", {"version": "v2"})
     def run(self, nt_parameters=None):
         if nt_parameters is None:
             nt_parameters = {}
         self._root_schedule = self._schedule_root(nt_parameters)
         _logger.info("Schedule completed")
 
-    def round_to_tinysamples(self, t):
-        return None if t is None else round(t / self._schedule_data.TINYSAMPLE)
-
     def generate_event_list(self, expand_loops: bool, max_events: int):
         event_list = self._start_events()
 
         if self._root_schedule is not None:
             id_tracker = itertools.count()
             event_list.extend(
                 self._root_schedule.generate_event_list(
@@ -102,26 +131,26 @@
             # assign every event an id
             for event in event_list:
                 if "id" not in event:
                     event["id"] = next(id_tracker)
 
         # convert time from units of tiny samples to seconds
         for event in event_list:
-            event["time"] = event["time"] * self._schedule_data.TINYSAMPLE
+            event["time"] = event["time"] * self._TINYSAMPLE
 
-        calculate_osc_phase(event_list, self._schedule_data.experiment_dao)
+        calculate_osc_phase(event_list, self._experiment_dao)
 
         return event_list
 
     def _start_events(self):
         retval = []
 
         # Add initial events to reset the NCOs.
         # Todo (PW): Drop once system tests have been migrated from legacy behaviour.
-        for device_info in self._schedule_data.experiment_dao.device_infos():
+        for device_info in self._experiment_dao.device_infos():
             try:
                 device_type = DeviceType(device_info.device_type)
             except ValueError:
                 # Not every device has a corresponding DeviceType (e.g. PQSC)
                 continue
             if not device_type.supports_reset_osc_phase:
                 continue
@@ -138,15 +167,15 @@
     def event_timing(self, expand_loops=False, max_events: Optional[int] = None):
         if max_events is None:
             # inf is not an int, but a good enough substitute!
             max_events = float("inf")
         return self.generate_event_list(expand_loops, max_events)
 
     def _schedule_root(self, nt_parameters: Dict[str, float]) -> Optional[RootSchedule]:
-        root_sections = self._schedule_data.experiment_dao.root_rt_sections()
+        root_sections = self._experiment_dao.root_rt_sections()
         if len(root_sections) == 0:
             return None
 
         self._repetition_info = self._resolve_repetition_time(root_sections)
 
         # todo: we do currently not actually support multiple root sections in the DSL.
         #  Some of our tests do however do this. For now, we always run all root
@@ -155,14 +184,23 @@
 
         signals = set()
         for c in schedules:
             signals.update(c.signals)
 
         root_schedule = RootSchedule(grid=1, signals=signals, children=schedules)  # type: ignore
         root_schedule.calculate_timing(self._schedule_data, 0, False)
+
+        for handle, acquire_pulses in self._schedule_data.acquire_pulses.items():
+            for a, b in pairwise(acquire_pulses):
+                if assert_valid(a.absolute_start) > assert_valid(b.absolute_start):
+                    _logger.warn(
+                        "Topological order of the acquires for handle"
+                        f" {handle} does not match time order."
+                    )
+
         return root_schedule
 
     def _schedule_section(
         self,
         section_id: str,
         current_parameters: Dict[str, float],
     ) -> SectionSchedule:
@@ -170,24 +208,24 @@
 
         ``current_parameters`` represents the parameter context from the parent.
         """
 
         try:
             # todo: do not hash the entire current_parameters dict, but just the param values
             # todo: reduce key to those parameters actually required by the section
-            return self._scheduled_sections[
-                (section_id, frozenset(current_parameters.items()))
-            ]
+            return copy.deepcopy(
+                self._scheduled_sections[
+                    (section_id, frozenset(current_parameters.items()))
+                ]
+            )
         except KeyError:
             pass
 
-        section_info = self._schedule_data.experiment_dao.section_info(section_id)
-        sweep_parameters = self._schedule_data.experiment_dao.section_parameters(
-            section_id
-        )
+        section_info = self._experiment_dao.section_info(section_id)
+        sweep_parameters = self._experiment_dao.section_parameters(section_id)
         for param in sweep_parameters:
             if "values" not in param or param["values"] is None:
                 param["values"] = (
                     param["start"] + np.arange(section_info.count) * param["step"]
                 )
 
         is_loop = section_info.has_repeat
@@ -218,16 +256,16 @@
         self, sweep_parameters: Set[str], signals: Set[str]
     ) -> Dict[str, SweptHardwareOscillator]:
         """Collect all hardware oscillators with a frequency swept by one of the
         given parameters, and that modulate one of the given signals. The keys of the
         returned dict are the parameter names."""
         oscillator_param_lookup = dict()
         for signal in signals:
-            signal_info = self._schedule_data.experiment_dao.signal_info(signal)
-            oscillator = self._schedule_data.experiment_dao.signal_oscillator(signal)
+            signal_info = self._experiment_dao.signal_info(signal)
+            oscillator = self._experiment_dao.signal_oscillator(signal)
 
             # Not every signal has an oscillator (e.g. flux lines), so check for None
             if oscillator is None:
                 continue
             param = oscillator.frequency_param
             if param in sweep_parameters and oscillator.hardware:
                 if (
@@ -280,17 +318,15 @@
                 all_parameters=current_parameters,
                 sweep_parameters=[],
                 swept_hw_oscillators={},
             )
             children_schedules.append(prototype)
         else:
             compressed = False
-            signals = self._schedule_data.experiment_dao.section_signals_with_children(
-                section_id
-            )
+            signals = self._experiment_dao.section_signals_with_children(section_id)
             swept_hw_oscillators = self._swept_hw_oscillators(
                 {p["id"] for p in sweep_parameters}, signals
             )
 
             for iteration in range(section_info.count):
                 new_parameters = {
                     param["id"]: (
@@ -317,15 +353,15 @@
 
         return LoopSchedule.from_section_schedule(
             schedule,
             compressed=compressed,
             sweep_parameters=sweep_parameters,
             iterations=section_info.count,
             repetition_mode=repetition_mode,
-            repetition_time=self.round_to_tinysamples(repetition_time),
+            repetition_time=to_tinysample(repetition_time, self._TINYSAMPLE),
         )
 
     def _schedule_oscillator_frequency_step(
         self,
         swept_hw_oscillators: Dict[str, SweptHardwareOscillator],
         iteration: int,
         sweep_parameters: List[Dict],
@@ -347,21 +383,19 @@
             osc = swept_hw_oscillators.get(param["id"])
             if osc is None:
                 continue
             values.append(param["values"][iteration])
             swept_oscs_list.append(osc)
             params.append(param["id"])
             device_id = osc.device
-            device_info = self._schedule_data.experiment_dao.device_info(device_id)
+            device_info = self._experiment_dao.device_info(device_id)
             device_type = DeviceType(device_info.device_type)
             length = max(
                 length,
-                int(
-                    device_type.oscillator_set_latency / self._schedule_data.TINYSAMPLE
-                ),
+                int(device_type.oscillator_set_latency / self._TINYSAMPLE),
             )
             signals.add(osc.signal)
 
         return OscillatorFrequencyStepSchedule(
             length=length,
             signals=signals,
             grid=grid,
@@ -378,33 +412,31 @@
         section_id: str,
         grid: int,
         signals: FrozenSet[str],
         hw_signals: FrozenSet[str],
     ) -> List[PhaseResetSchedule]:
         reset_sw_oscillators = (
             len(hw_signals) > 0
-            or self._schedule_data.experiment_dao.section_info(
-                section_id
-            ).averaging_type
+            or self._experiment_dao.section_info(section_id).averaging_type
             == "hardware"
         )
 
         if not reset_sw_oscillators and len(hw_signals) == 0:
             return []
 
         length = 0
         hw_osc_devices = {}
         for signal in hw_signals:
-            device = self._schedule_data.experiment_dao.device_from_signal(signal)
+            device = self._experiment_dao.device_from_signal(signal)
             device_type = DeviceType(
-                self._schedule_data.experiment_dao.device_info(device).device_type
+                self._experiment_dao.device_info(device).device_type
             )
             if not device_type.supports_reset_osc_phase:
                 continue
-            duration = device_type.reset_osc_duration / self._schedule_data.TINYSAMPLE
+            duration = device_type.reset_osc_duration / self._TINYSAMPLE
             hw_osc_devices[device] = duration
             length = max(length, duration)
 
         hw_osc_devices = [(k, v) for k, v in hw_osc_devices.items()]
         length = ceil_to_grid(length, grid)
 
         if reset_sw_oscillators:
@@ -448,43 +480,44 @@
         children_schedules = self._collect_children_schedules(
             section_id, all_parameters
         )
 
         for c in children_schedules:
             signals.update(c.signals)
 
-        section_info = self._schedule_data.experiment_dao.section_info(section_id)
+        section_info = self._experiment_dao.section_info(section_id)
         hw_osc_reset_signals = set()
         if section_info.reset_oscillator_phase:
             # todo: This behaves differently than the legacy scheduler.
             #  The old scheduler would reset ALL devices in the setup.
             #  Unfortunately, the section grid of the loop (and hence of the phase
             #  reset) was still defined by the *section signals*. This would potentially
             #  lead to problems when resetting an otherwise unused device that cannot
             #  align with the loop grid.
             #  The new scheduler does not reset devices with unused signals.
-            for (
-                signal
-            ) in self._schedule_data.experiment_dao.section_signals_with_children(
+            for signal in self._experiment_dao.section_signals_with_children(
                 section_id
             ):
-                osc_info = self._schedule_data.experiment_dao.signal_oscillator(signal)
+                osc_info = self._experiment_dao.signal_oscillator(signal)
                 if osc_info is not None and osc_info.hardware:
                     hw_osc_reset_signals.add(signal)
 
         for _, osc in swept_hw_oscillators.items():
             signals.add(osc.signal)
 
         # escalate the grid to sequencer grid
         # todo: Currently we do this unconditionally. This is something we might want to
         #  relax in the future
         _, grid = self.grid(*signals)
 
-        osc_phase_reset = self._schedule_phase_reset(
-            section_id, grid, frozenset(signals), frozenset(hw_osc_reset_signals)
+        # Deepcopy here because of caching
+        osc_phase_reset = copy.deepcopy(
+            self._schedule_phase_reset(
+                section_id, grid, frozenset(signals), frozenset(hw_osc_reset_signals)
+            )
         )
 
         if len(swept_hw_oscillators):
             osc_sweep = [
                 self._schedule_oscillator_frequency_step(
                     swept_hw_oscillators,
                     iteration,
@@ -522,15 +555,15 @@
         the system grid can be enforced via the DSL.
         """
         right_align = section_info.align == SectionAlignment.RIGHT.value
         signals = set()
         for c in children:
             signals.update(c.signals)
 
-        signals.update(self._schedule_data.experiment_dao.section_signals(section_id))
+        signals.update(self._experiment_dao.section_signals(section_id))
         play_after = section_info.play_after or []
         if isinstance(play_after, str):
             play_after = [play_after]
 
         signal_grid, sequencer_grid = self.grid(*signals)
 
         signal_grids = {self.grid(s)[0] for s in signals}
@@ -545,15 +578,15 @@
         trigger_output = self._compute_trigger_output(section_info)
         if len(trigger_output):
             grid = lcm(grid, sequencer_grid)
 
         schedule = SectionSchedule(
             grid=grid,
             sequencer_grid=sequencer_grid,
-            length=self.round_to_tinysamples(section_info.length),
+            length=to_tinysample(section_info.length, self._TINYSAMPLE),
             signals=signals,
             children=children,
             play_after=play_after,
             right_aligned=right_align,
             section=section_id,
             trigger_output=trigger_output,
         )
@@ -585,24 +618,24 @@
                         "Note that only RT sweep parameters are currently supported here."
                     ) from e
             return value
 
         offset = resolve_value_or_parameter("offset", 0.0)
         length = resolve_value_or_parameter("length", None)
         if length is None:
-            pulse_def = self._schedule_data.experiment_dao.pulse(pulse.pulse_id)
+            pulse_def = self._experiment_dao.pulse(pulse.pulse_id)
             if pulse_def is not None:
                 assert pulse_def.length is None
                 if pulse_def.samples is None:
                     raise LabOneQException(
                         f"Cannot determine length of pulse '{pulse.pulse_id}' in section "
                         f"'{section}'. Either specify the length at the pulse definition, "
                         f"when playing the pulse, or by specifying the samples."
                     )
-                length = len(pulse_def.samples) * grid * self._schedule_data.TINYSAMPLE
+                length = len(pulse_def.samples) * grid * self._TINYSAMPLE
             else:
                 assert offset is not None
                 length = 0.0
 
         amplitude = resolve_value_or_parameter("amplitude", 1.0)
         if abs(amplitude) > 1.0 + 1e-9:
             raise LabOneQException(
@@ -636,20 +669,18 @@
         play_pulse_params = None
         if pulse.play_pulse_parameters is not None:
             play_pulse_params = pulse.play_pulse_parameters.copy()
             resolve_pulse_params(play_pulse_params)
 
         scheduled_length = length + offset
 
-        length_int = round_to_grid(
-            scheduled_length / self._schedule_data.TINYSAMPLE, grid
-        )
-        offset_int = round_to_grid(offset / self._schedule_data.TINYSAMPLE, grid)
+        length_int = round_to_grid(scheduled_length / self._TINYSAMPLE, grid)
+        offset_int = round_to_grid(offset / self._TINYSAMPLE, grid)
 
-        osc = self._schedule_data.experiment_dao.signal_oscillator(pulse.signal_id)
+        osc = self._experiment_dao.signal_oscillator(pulse.signal_id)
         if osc is None:
             freq = None
         elif not osc.hardware and osc.frequency_param is not None:
             try:
                 freq = current_parameters[osc.frequency_param]
             except KeyError as e:
                 raise LabOneQException(
@@ -657,15 +688,15 @@
                     f"requires the parameter '{osc.frequency_param}' to set the frequency."
                 ) from e
         elif osc is None or osc.hardware:
             freq = None
         else:
             freq = osc.frequency if osc is not None else None
 
-        signal_info = self._schedule_data.experiment_dao.signal_info(pulse.signal_id)
+        signal_info = self._experiment_dao.signal_info(pulse.signal_id)
         is_acquire = signal_info.signal_type == "integration"
         markers = pulse.markers
 
         return PulseSchedule(
             grid=grid,
             length=length_int,
             signals={pulse.signal_id},
@@ -738,32 +769,34 @@
 
         play_after = section_info.play_after or []
         if isinstance(play_after, str):
             play_after = [play_after]
 
         return MatchSchedule(
             grid=grid,
-            length=self.round_to_tinysamples(section_info.length),
+            length=to_tinysample(section_info.length, self._schedule_data.TINYSAMPLE),
             sequencer_grid=grid,
             signals=signals,
             children=children_schedules,
             right_aligned=False,
             section=section_id,
             play_after=play_after,
             handle=handle,
             local=local,
         )
 
     def _schedule_case(self, section_id, current_parameters) -> CaseSchedule:
         try:
             # todo: do not hash the entire current_parameters dict, but just the param values
             # todo: reduce key to those parameters actually required by the section
-            return self._scheduled_sections[
-                (section_id, frozenset(current_parameters.items()))
-            ]
+            return copy.deepcopy(
+                self._scheduled_sections[
+                    (section_id, frozenset(current_parameters.items()))
+                ]
+            )
         except KeyError:
             pass
 
         section_info = self._schedule_data.experiment_dao.section_info(section_id)
 
         assert not section_info.has_repeat  # case must not be a loop
         assert section_info.handle is None
```

## laboneq/compiler/new_scheduler/section_schedule.py

```diff
@@ -1,13 +1,13 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Dict, Iterator, List, Optional, Set, Tuple
+from typing import TYPE_CHECKING, Dict, Iterator, List, Set, Tuple
 
 from attrs import define, field
 
 from laboneq.compiler.common.compiler_settings import CompilerSettings
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.new_scheduler.interval_schedule import IntervalSchedule
 from laboneq.compiler.new_scheduler.pulse_schedule import PrecompClearSchedule
@@ -102,16 +102,21 @@
                     )
                 except StopIteration:
                     raise RuntimeError(
                         "The precompensation clear refers to a pulse that could not be "
                         "found."
                     )
             start = ceil_to_grid(start, c.grid)
+            start = (
+                c.calculate_timing(
+                    schedule_data, absolute_start + start, start_may_change
+                )
+                - absolute_start
+            )
             self.children_start[i] = start
-            c.calculate_timing(schedule_data, absolute_start + start, start_may_change)
             for s in c.signals:
                 current_signal_start[s] = start + c.length
 
     def _arrange_right_aligned(
         self,
         schedule_data: ScheduleData,
         absolute_start: int,
@@ -123,15 +128,18 @@
         for c in self.children:
             pa_names = getattr(c, "play_after", None)
             if pa_names:
                 pa_section = getattr(c, "section")
                 for pa_name in pa_names:
                     play_before.setdefault(pa_name, []).append(pa_section)
         for i, c in reversed(list(enumerate(self.children))):
-            c.calculate_timing(schedule_data, absolute_start, True)
+            offset = (
+                c.calculate_timing(schedule_data, absolute_start, True) - absolute_start
+            )
+            assert offset == 0
             assert c.length is not None
             start = (
                 min((current_signal_end.setdefault(s, 0) for s in c.signals), default=0)
                 - c.length
             )
             pb_section = getattr(c, "section", None)
             if pb_section is not None:
@@ -162,27 +170,28 @@
             min((v for v in self.children_start if v is not None), default=0), self.grid
         )
 
         self.children_start = [start - section_start for start in self.children_start]
 
     def _calculate_timing(
         self, schedule_data: ScheduleData, start: int, start_may_change
-    ):
+    ) -> int:
         children_index_by_name = {
             child.section: i
             for i, child in enumerate(self.children)
             if isinstance(child, SectionSchedule)
         }
         if not self.right_aligned:
             self._arrange_left_aligned(
                 schedule_data, start, children_index_by_name, start_may_change
             )
         else:
             self._arrange_right_aligned(schedule_data, start, children_index_by_name)
         self._calculate_length(schedule_data)
+        return start
 
     def _calculate_length(self, schedule_data: ScheduleData):
         assert self.children_start is not None
         if len(self.children):
             length = ceil_to_grid(
                 max(
                     (
@@ -211,18 +220,19 @@
             self.length = length
 
     def generate_event_list(
         self,
         start: int,
         max_events: int,
         id_tracker: Iterator[int],
-        expand_loops=False,
-        settings: Optional[CompilerSettings] = None,
+        expand_loops,
+        settings: CompilerSettings,
     ) -> List[Dict]:
         assert self.length is not None
+        assert self.absolute_start is not None
 
         # We'll wrap the child events in the section start and end events
         max_events -= 2
 
         trigger_set_events = []
         trigger_clear_events = []
         for trigger_signal, bit in self.trigger_output:
@@ -274,15 +284,15 @@
             },
         ]
 
     def children_events(
         self,
         start: int,
         max_events: int,
-        settings: Optional[CompilerSettings],
+        settings: CompilerSettings,
         id_tracker: Iterator[int],
         expand_loops,
         subsection_events=True,
     ) -> List[List[Dict]]:
         assert self.children_start is not None
 
         if subsection_events:
```

## laboneq/compiler/new_scheduler/utils.py

```diff
@@ -1,14 +1,15 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import functools
 import math
+from typing import Optional, TypeVar
 
 import numpy as np
 
 
 @functools.lru_cache(64)
 def lcm(a, b):
     return int(np.lcm(a or 1, b or 1))
@@ -20,7 +21,19 @@
 
 def ceil_to_grid(value, grid: int):
     return math.ceil(value / grid) * grid
 
 
 def floor_to_grid(value, grid: int):
     return math.floor(value / grid) * grid
+
+
+def to_tinysample(t: Optional[float], tinysample: float) -> Optional[int]:
+    return None if t is None else round(t / tinysample)
+
+
+T = TypeVar("T")
+
+
+def assert_valid(obj: Optional[T]) -> T:
+    assert obj is not None
+    return obj
```

## laboneq/compiler/scheduler/scheduler.py

```diff
@@ -21,14 +21,15 @@
 
 from laboneq._observability.tracing import trace
 from laboneq.compiler.common.compiler_settings import CompilerSettings
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.common.play_wave_type import PlayWaveType
 from laboneq.compiler.common.pulse_parameters import encode_pulse_parameters
+from laboneq.compiler.common.signal_obj import SignalObj
 from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
 from laboneq.compiler.experiment_access.param_ref import ParamRef
 from laboneq.compiler.experiment_access.pulse_def import PulseDef
 from laboneq.compiler.experiment_access.section_graph import SectionGraph
 from laboneq.compiler.scheduler.event_graph import EventGraph, EventRelation, node_info
 from laboneq.compiler.scheduler.event_graph_builder import (
     ChainElement,
@@ -136,14 +137,15 @@
 
 
 class Scheduler:
     def __init__(
         self,
         experiment_dao: ExperimentDAO,
         sampling_rate_tracker: SamplingRateTracker,
+        signal_objects: Dict[str, SignalObj],
         clock_settings: Optional[Dict] = None,
         settings: Optional[CompilerSettings] = None,
     ):
         self._experiment_dao = experiment_dao
         self._sampling_rate_tracker = sampling_rate_tracker
         self._clock_settings = clock_settings or {}
         self._settings = settings or CompilerSettings()
```

## laboneq/compiler/workflow/compiler.py

```diff
@@ -18,14 +18,15 @@
 )
 from laboneq.compiler.common import compiler_settings
 from laboneq.compiler.common.awg_info import AWGInfo
 from laboneq.compiler.common.awg_signal_type import AWGSignalType
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.common.signal_obj import SignalObj
 from laboneq.compiler.common.trigger_mode import TriggerMode
+from laboneq.compiler.experiment_access.device_info import DeviceInfo
 from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
 from laboneq.compiler.new_scheduler.scheduler import Scheduler as NewScheduler
 from laboneq.compiler.scheduler.sampling_rate_tracker import SamplingRateTracker
 from laboneq.compiler.scheduler.scheduler import Scheduler
 from laboneq.compiler.workflow.precompensation_helpers import (
     compute_precompensation_delays_on_grid,
     compute_precompensations_and_delays,
@@ -67,14 +68,15 @@
         self._leader_properties = LeaderProperties()
         self._clock_settings = {}
         self._integration_unit_allocation = None
         self._awgs: _AWGMapping = {}
         self._precompensations: Dict[
             str, Dict[str, Union[Dict[str, Any], float]]
         ] = None
+        self._signal_objects: Dict[str, SignalObj] = {}
 
         _logger.info("Starting LabOne Q Compiler run...")
         self._check_tinysamples()
 
     @classmethod
     def from_user_settings(cls, settings: dict) -> "Compiler":
         return cls(compiler_settings.filter_user_settings(settings))
@@ -99,15 +101,15 @@
             self._experiment_dao = ExperimentDAO(
                 None, experiment["setup"], experiment["experiment"]
             )
         else:
             self._experiment_dao = ExperimentDAO(experiment)
 
     def _analyze_setup(self):
-        def get_first_instr_of(device_infos, type):
+        def get_first_instr_of(device_infos: List[DeviceInfo], type) -> DeviceInfo:
             return next((instr for instr in device_infos if instr.device_type == type))
 
         device_infos = self._experiment_dao.device_infos()
         device_type_list = [i.device_type for i in device_infos]
         type_counter = Counter(device_type_list)
         has_pqsc = type_counter["pqsc"] > 0
         has_hdawg = type_counter["hdawg"] > 0
@@ -208,26 +210,30 @@
                     if first_shfqa.reference_clock_source is None:
                         self._clock_settings[first_shfqa.id] = "internal"
 
         self._clock_settings["use_2GHz_for_HDAWG"] = has_shf
         self._leader_properties.global_leader = leader
 
     def _process_experiment(self, experiment):
-        self.use_experiment(experiment)
-        self._analyze_setup()
         self._calc_osc_numbering()
         self._calc_awgs()
-        _logger.debug("Processing Sections:::::::")
+        self._calc_shfqa_generator_allocation()
+
         self._sampling_rate_tracker = SamplingRateTracker(
             self._experiment_dao, self._clock_settings
         )
+        self._calc_integration_unit_allocation()
+        self._precompensations = self._calc_precompensations()
+        self._signal_objects = self._generate_signal_objects()
+        _logger.debug("Processing Sections:::::::")
 
         self._scheduler = self.Scheduler(
             self._experiment_dao,
             self._sampling_rate_tracker,
+            self._signal_objects,
             self._clock_settings,
             self._settings,
         )
         self._scheduler.run()
 
     @staticmethod
     def _get_total_rounded_delay(delay, signal_id, device_type, sampling_rate):
@@ -251,127 +257,23 @@
                 delay_rounded * 1e9,
                 device_type.sample_multiple,
             )
         return delay_rounded
 
     @trace("compiler.generate-code()")
     def _generate_code(self):
-        self._calc_awgs()
-        self._calc_shfqa_generator_allocation()
-        self._precompensations = compute_precompensations_and_delays(
-            self._experiment_dao
-        )
-        compute_precompensation_delays_on_grid(
-            self._precompensations,
-            self._experiment_dao,
-            self._clock_settings["use_2GHz_for_HDAWG"],
-        )
-
         code_generator = CodeGenerator(self._settings)
         self._code_generator = code_generator
 
-        for signal_id in self._experiment_dao.signals():
-
-            signal_info = self._experiment_dao.signal_info(signal_id)
-            delay_signal = signal_info.delay_signal
-
-            device_type = DeviceType(signal_info.device_type)
-            device_id = signal_info.device_id
-
-            sampling_rate = self._sampling_rate_tracker.sampling_rate_for_device(
-                device_id
-            )
-            start_delay = self.get_lead_delay(
-                device_type,
-                self._leader_properties.is_desktop_setup,
-                self._clock_settings["use_2GHz_for_HDAWG"],
-            )
-            start_delay += self._precompensations[signal_id]["computed_delay_signal"]
-
-            if delay_signal is not None:
-                delay_signal = self._get_total_rounded_delay(
-                    delay_signal, signal_id, device_type, sampling_rate
-                )
-            else:
-                delay_signal = 0
-
-            awg = self.get_awg(signal_id)
-            awg.trigger_mode = TriggerMode.NONE
-            device_info = self._experiment_dao.device_info(device_id)
-            try:
-                awg.reference_clock_source = self._clock_settings[device_id]
-            except KeyError:
-                awg.reference_clock_source = device_info.reference_clock_source
-            if self._leader_properties.is_desktop_setup:
-                awg.trigger_mode = {
-                    DeviceType.HDAWG: TriggerMode.DIO_TRIGGER,
-                    DeviceType.SHFSG: TriggerMode.INTERNAL_TRIGGER_WAIT,
-                    DeviceType.SHFQA: TriggerMode.INTERNAL_TRIGGER_WAIT,
-                    DeviceType.UHFQA: TriggerMode.DIO_WAIT,
-                }.get(device_type, TriggerMode.NONE)
-            awg.sampling_rate = sampling_rate
-
-            signal_type = signal_info.signal_type
-
-            _logger.debug(
-                "Adding signal %s with signal type %s", signal_id, signal_type
-            )
-
-            oscillator_frequency = None
-
-            oscillator_info = self._experiment_dao.signal_oscillator(signal_id)
-            if (
-                oscillator_info is not None
-                and not oscillator_info.hardware
-                and signal_info.modulation
-            ):
-                oscillator_frequency = oscillator_info.frequency
-            channels = copy.deepcopy(signal_info.channels)
-            if signal_id in self._integration_unit_allocation:
-                channels = copy.deepcopy(
-                    self._integration_unit_allocation[signal_id]["channels"]
-                )
-            elif signal_id in self._shfqa_generator_allocation:
-                channels = copy.deepcopy(
-                    self._shfqa_generator_allocation[signal_id]["channels"]
-                )
-            hw_oscillator = (
-                oscillator_info.id
-                if oscillator_info is not None and oscillator_info.hardware
-                else None
-            )
-
-            mixer_type = MixerType.IQ
-            if (
-                device_type == DeviceType.UHFQA
-                and oscillator_info
-                and oscillator_info.hardware
-            ):
-                mixer_type = MixerType.UHFQA_ENVELOPE
-            elif signal_type in ("single",):
-                mixer_type = None
-
-            signal_obj = SignalObj(
-                id=signal_id,
-                sampling_rate=sampling_rate,
-                start_delay=start_delay,
-                delay_signal=delay_signal,
-                signal_type=signal_type,
-                device_id=device_id,
-                awg=awg,
-                device_type=device_type,
-                oscillator_frequency=oscillator_frequency,
-                channels=channels,
-                mixer_type=mixer_type,
-                hw_oscillator=hw_oscillator,
-            )
+        for signal_obj in self._signal_objects.values():
             code_generator.add_signal(signal_obj)
 
         _logger.debug("Preparing events for code generator")
         events = self._scheduler.event_timing(expand_loops=False)
+
         code_generator.gen_acquire_map(events, self._experiment_dao)
         code_generator.gen_seq_c(
             events,
             {k: self._experiment_dao.pulse(k) for k in self._experiment_dao.pulses()},
         )
         self._command_table_match_offsets = code_generator.command_table_match_offsets()
         self._feedback_connections = code_generator.feedback_connections()
@@ -572,14 +474,126 @@
         device_id = signal_info.device_id
         device_type = DeviceType(signal_info.device_type)
         awg_number = Compiler.calc_awg_number(signal_info.channels[0], device_type)
         if signal_info.signal_type == "integration" and device_type != DeviceType.SHFQA:
             awg_number = 0
         return self._awgs[device_id][awg_number]
 
+    def _calc_precompensations(self):
+        precompensations = compute_precompensations_and_delays(self._experiment_dao)
+        compute_precompensation_delays_on_grid(
+            precompensations,
+            self._experiment_dao,
+            self._clock_settings["use_2GHz_for_HDAWG"],
+        )
+        return precompensations
+
+    def _generate_signal_objects(self):
+        signal_objects = {}
+        for signal_id in self._experiment_dao.signals():
+
+            signal_info = self._experiment_dao.signal_info(signal_id)
+            delay_signal = signal_info.delay_signal
+
+            device_type = DeviceType(signal_info.device_type)
+            device_id = signal_info.device_id
+
+            sampling_rate = self._sampling_rate_tracker.sampling_rate_for_device(
+                device_id
+            )
+            start_delay = get_lead_delay(
+                self._settings,
+                device_type,
+                self._leader_properties.is_desktop_setup,
+                self._clock_settings["use_2GHz_for_HDAWG"],
+            )
+            start_delay += self._precompensations[signal_id]["computed_delay_signal"]
+
+            if delay_signal is not None:
+                delay_signal = self._get_total_rounded_delay(
+                    delay_signal, signal_id, device_type, sampling_rate
+                )
+            else:
+                delay_signal = 0
+
+            awg = self.get_awg(signal_id)
+            awg.trigger_mode = TriggerMode.NONE
+            device_info = self._experiment_dao.device_info(device_id)
+            try:
+                awg.reference_clock_source = self._clock_settings[device_id]
+            except KeyError:
+                awg.reference_clock_source = device_info.reference_clock_source
+            if self._leader_properties.is_desktop_setup:
+                awg.trigger_mode = {
+                    DeviceType.HDAWG: TriggerMode.DIO_TRIGGER,
+                    DeviceType.SHFSG: TriggerMode.INTERNAL_TRIGGER_WAIT,
+                    DeviceType.SHFQA: TriggerMode.INTERNAL_TRIGGER_WAIT,
+                    DeviceType.UHFQA: TriggerMode.DIO_WAIT,
+                }.get(device_type, TriggerMode.NONE)
+            awg.sampling_rate = sampling_rate
+
+            signal_type = signal_info.signal_type
+
+            _logger.debug(
+                "Adding signal %s with signal type %s", signal_id, signal_type
+            )
+
+            oscillator_frequency = None
+
+            oscillator_info = self._experiment_dao.signal_oscillator(signal_id)
+            if (
+                oscillator_info is not None
+                and not oscillator_info.hardware
+                and signal_info.modulation
+            ):
+                oscillator_frequency = oscillator_info.frequency
+            channels = copy.deepcopy(signal_info.channels)
+            if signal_id in self._integration_unit_allocation:
+                channels = copy.deepcopy(
+                    self._integration_unit_allocation[signal_id]["channels"]
+                )
+            elif signal_id in self._shfqa_generator_allocation:
+                channels = copy.deepcopy(
+                    self._shfqa_generator_allocation[signal_id]["channels"]
+                )
+            hw_oscillator = (
+                oscillator_info.id
+                if oscillator_info is not None and oscillator_info.hardware
+                else None
+            )
+
+            mixer_type = MixerType.IQ
+            if (
+                device_type == DeviceType.UHFQA
+                and oscillator_info
+                and oscillator_info.hardware
+            ):
+                mixer_type = MixerType.UHFQA_ENVELOPE
+            elif signal_type in ("single",):
+                mixer_type = None
+
+            signal_obj = SignalObj(
+                id=signal_id,
+                sampling_rate=sampling_rate,
+                start_delay=start_delay,
+                delay_signal=delay_signal,
+                signal_type=signal_type,
+                device_id=device_id,
+                awg=awg,
+                device_type=device_type,
+                oscillator_frequency=oscillator_frequency,
+                channels=channels,
+                port_delay=self._experiment_dao.port_delay(signal_id),
+                mixer_type=mixer_type,
+                hw_oscillator=hw_oscillator,
+                is_qc=device_info.is_qc,
+            )
+            signal_objects[signal_id] = signal_obj
+        return signal_objects
+
     def calc_outputs(self, signal_delays: SignalDelays):
         all_channels = {}
 
         flipper = [1, 0]
 
         for signal_id in self._experiment_dao.signals():
             signal_info = self._experiment_dao.signal_info(signal_id)
@@ -1084,16 +1098,17 @@
         else:
             _logger.debug("END %s", src["filename"])
 
     @trace("compiler.run()")
     def run(self, data) -> CompiledExperiment:
         _logger.debug("ES Compiler run")
 
+        self.use_experiment(data)
+        self._analyze_setup()
         self._process_experiment(data)
-        self._calc_integration_unit_allocation()
 
         self._generate_code()
         self._generate_recipe()
 
         retval = self.compiler_output()
 
         total_seqc_lines = 0
@@ -1108,36 +1123,42 @@
             except KeyError:
                 pass
         _logger.info("Total sample points generated: %d", total_samples)
 
         _logger.info("Finished LabOne Q Compiler run.")
         return retval
 
-    def get_lead_delay(self, device_type, desktop_setup, hdawg_uses_2GHz):
-        if not isinstance(device_type, DeviceType):
-            raise Exception(f"Device type {device_type} is not of type DeviceType")
-        if device_type == DeviceType.HDAWG:
-            if not desktop_setup:
-                if hdawg_uses_2GHz:
-                    return self._settings.HDAWG_LEAD_PQSC_2GHz
-                else:
-                    return self._settings.HDAWG_LEAD_PQSC
+
+def get_lead_delay(
+    settings: compiler_settings.CompilerSettings,
+    device_type: DeviceType,
+    desktop_setup: bool,
+    hdawg_uses_2GHz: bool,
+):
+    if not isinstance(device_type, DeviceType):
+        raise RuntimeError(f"Device type {device_type} is not of type DeviceType")
+    if device_type == DeviceType.HDAWG:
+        if not desktop_setup:
+            if hdawg_uses_2GHz:
+                return settings.HDAWG_LEAD_PQSC_2GHz
             else:
-                if hdawg_uses_2GHz:
-                    return self._settings.HDAWG_LEAD_DESKTOP_SETUP_2GHz
-                else:
-                    return self._settings.HDAWG_LEAD_DESKTOP_SETUP
-        elif device_type == DeviceType.UHFQA:
-            return self._settings.UHFQA_LEAD_PQSC
-        elif device_type == DeviceType.SHFQA:
-            return self._settings.SHFQA_LEAD_PQSC
-        elif device_type == DeviceType.SHFSG:
-            return self._settings.SHFSG_LEAD_PQSC
+                return settings.HDAWG_LEAD_PQSC
         else:
-            raise Exception(f"Unsupported device type {device_type}")
+            if hdawg_uses_2GHz:
+                return settings.HDAWG_LEAD_DESKTOP_SETUP_2GHz
+            else:
+                return settings.HDAWG_LEAD_DESKTOP_SETUP
+    elif device_type == DeviceType.UHFQA:
+        return settings.UHFQA_LEAD_PQSC
+    elif device_type == DeviceType.SHFQA:
+        return settings.SHFQA_LEAD_PQSC
+    elif device_type == DeviceType.SHFSG:
+        return settings.SHFSG_LEAD_PQSC
+    else:
+        raise RuntimeError(f"Unsupported device type {device_type}")
 
 
 def find_obj_by_id(object_list, id):
     for i in object_list:
         if i["id"] == id:
             return i
```

## laboneq/compiler/workflow/recipe_generator.py

```diff
@@ -1,17 +1,22 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from __future__ import annotations
+
 import logging
-from typing import Dict, Optional
+from typing import TYPE_CHECKING, Dict, Optional
 
 from laboneq.compiler.code_generator.measurement_calculator import IntegrationTimes
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
 
+if TYPE_CHECKING:
+    from laboneq.compiler.workflow.compiler import LeaderProperties
+
 _logger = logging.getLogger(__name__)
 
 
 class RecipeGenerator:
     def __init__(self):
         self._recipe = {}
         self._recipe[
@@ -103,15 +108,18 @@
     def _find_initialization(self, device_uid):
         for initialization in self._recipe["experiment"]["initializations"]:
             if initialization["device_uid"] == device_uid:
                 return initialization
         return None
 
     def add_connectivity_from_experiment(
-        self, experiment_dao, leader_properties, clock_settings
+        self,
+        experiment_dao: ExperimentDAO,
+        leader_properties: LeaderProperties,
+        clock_settings,
     ):
         if leader_properties.global_leader is not None:
             initialization = self._find_initialization(leader_properties.global_leader)
             initialization["config"]["repetitions"] = 1
             initialization["config"]["holdoff"] = 0
             if leader_properties.is_desktop_setup:
                 initialization["config"]["dio_mode"] = "hdawg_leader"
@@ -258,15 +266,20 @@
             "signal_type": signal_type,
             "qa_signal_id": qa_signal_id,
             "command_table_match_offset": command_table_match_offset,
             "feedback_register": feedback_register,
         }
         initialization["awgs"].append(awg)
 
-    def from_experiment(self, experiment_dao, leader_properties, clock_settings):
+    def from_experiment(
+        self,
+        experiment_dao: ExperimentDAO,
+        leader_properties: LeaderProperties,
+        clock_settings,
+    ):
         self.add_devices_from_experiment(experiment_dao)
         self.add_connectivity_from_experiment(
             experiment_dao, leader_properties, clock_settings
         )
 
     def add_simultaneous_acquires(
         self, simultaneous_acquires: Dict[float, Dict[str, str]]
```

## laboneq/contrib/example_helpers/example_notebook_helper.py

```diff
@@ -3,14 +3,15 @@
 
 """ Helper functions for definition of device setup and calibration settings
 """
 
 from laboneq.contrib.example_helpers.descriptors.hdawg_uhfqa_pqsc import (
     descriptor_hdawg_uhfqa_pqsc,
 )
+from laboneq.contrib.example_helpers.descriptors.shfqc import descriptor_shfqc
 from laboneq.contrib.example_helpers.descriptors.shfsg_shfqa_hdawg_pqsc import (
     descriptor_shfsg_shfqa_hdawg_pqsc,
 )
 from laboneq.core.types.enums import ModulationType
 from laboneq.dsl.calibration import Oscillator, SignalCalibration
 from laboneq.dsl.device import DeviceSetup
 
@@ -114,19 +115,20 @@
 
 
 # Function returning a calibrated device setup
 def create_device_setup(generation=2):
     """
     Function returning a calibrated device setup
     """
+    if generation == 3:
+        descriptor = descriptor_shfqc
     if generation == 2:
         descriptor = descriptor_shfsg_shfqa_hdawg_pqsc
     elif generation == 1:
         descriptor = descriptor_hdawg_uhfqa_pqsc
-
     else:
         raise ValueError("Invalid instrument generation given")
 
     # device_setup = DeviceSetup.from_yaml(
     device_setup = DeviceSetup.from_descriptor(
         descriptor,
         server_host="my_ip_address",  # IP address of the LabOne dataserver used to communicate with the instruments
```

## laboneq/contrib/example_helpers/plotting/plot_helpers.py

```diff
@@ -46,14 +46,15 @@
     ]
 
     xs = []
     y1s = []
     labels1 = []
     y2s = []
     labels2 = []
+    titles = []
     for signal in mapped_signals:
         mapped_path = compiled_experiment.experiment.signals[
             signal
         ].mapped_logical_signal_path
 
         full_path = re.sub(r"/logical_signal_groups/", "", mapped_path)
         signal_group_name = re.sub(r"/[^/]*$", "", full_path)
@@ -71,26 +72,35 @@
             .physical_channel,
             start=start_time,
             output_length=length,
             get_trigger=True,
             get_frequency=True,
         )
 
+        physcial_channel = (
+            compiled_experiment.device_setup.logical_signal_groups[signal_group_name]
+            .logical_signals[signal_line_name]
+            .physical_channel.uid.replace("_", " ")
+            .replace("/", ": ")
+        )
+
         if "iq_channel" in str(
             physical_channel_path.type
         ).lower() and "input" not in str(physical_channel_path.name):
             try:
                 if my_snippet.time is not None:
                     xs.append(my_snippet.time)
 
                     y1s.append(my_snippet.wave.real)
                     labels1.append(f"{signal} I")
 
                     y2s.append(my_snippet.wave.imag)
                     labels2.append(f"{signal} Q")
+
+                    titles.append(f"{physcial_channel} - {signal}".upper())
             except Exception:
                 pass
 
         if (
             "iq_channel" not in str(physical_channel_path.type).lower()
             or "input" in physical_channel_path.name
         ):
@@ -99,54 +109,60 @@
                     time_length = len(my_snippet.time)
 
                     xs.append(my_snippet.time)
 
                     y1s.append(my_snippet.wave.real)
                     labels1.append(f"{signal}")
 
+                    titles.append(f"{physcial_channel} - {signal}".upper())
+
                     empty_array = np.empty((1, time_length))
                     empty_array.fill(np.nan)
                     y2s.append(empty_array[0])
                     labels2.append(None)
 
             except Exception:
                 pass
 
-    colors = plt.rcParams["axes.prop_cycle"]()
-
     fig, axes = plt.subplots(
         nrows=len(y1s),
         sharex=False,
         figsize=(plot_width, len(mapped_signals) * plot_height),
     )
 
-    if len(mapped_signals) > 1:
-        for axs, x, y1, y2, label1, label2 in zip(
-            axes.flat, xs, y1s, y2s, labels1, labels2
+    colors = plt.rcParams["axes.prop_cycle"]()
+
+    if len(xs) > 1:
+        for axs, x, y1, y2, label1, label2, title in zip(
+            axes.flat, xs, y1s, y2s, labels1, labels2, titles
         ):
             # Get the next color from the cycler
             c = next(colors)["color"]
             axs.plot(x, y1, label=label1, color=c)
             c = next(colors)["color"]
             axs.plot(x, y2, label=label2, color=c)
             axs.set_ylabel(yaxis_label)
             axs.set_xlabel(xaxis_label)
+            axs.set_title(title)
             axs.legend(loc="upper right")
             axs.ticklabel_format(axis="both", style="sci", scilimits=(0, 0))
             axs.grid(True)
 
-    elif len(mapped_signals) == 1:
-        for x, y1, y2, label1, label2 in zip(xs, y1s, y2s, labels1, labels2):
+    elif len(xs) == 1:
+        for x, y1, y2, label1, label2, title in zip(
+            xs, y1s, y2s, labels1, labels2, titles
+        ):
             # Get the next color from the cycler
             c = next(colors)["color"]
             axes.plot(x, y1, label=label1, color=c)
             c = next(colors)["color"]
             axes.plot(x, y2, label=label2, color=c)
             axes.set_ylabel(yaxis_label)
             axes.set_xlabel(xaxis_label)
+            axes.set_title(title)
             axes.legend(loc="upper right")
             axes.ticklabel_format(axis="both", style="sci", scilimits=(0, 0))
             axes.grid(True)
 
     fig.tight_layout()
     # fig.legend(loc="upper left")
     plt.show()
```

## laboneq/controller/communication.py

```diff
@@ -187,15 +187,15 @@
 
 @dataclass
 class ServerQualifier:
     dry_run: bool = True
     host: str = None
     port: int = None
     api_level: int = None
-    ignore_lab_one_version_error: bool = False
+    ignore_version_mismatch: bool = False
 
 
 class DaqWrapper(ZiApiWrapperBase):
     def __init__(self, name, server_qualifier: ServerQualifier):
         super().__init__(name)
         self._server_qualifier = server_qualifier
         self._awg_module_wrappers: List[AwgModuleWrapper] = []
@@ -223,25 +223,25 @@
 
         path = "/zi/about/version"
         version_str = self.batch_get([DaqNodeGetAction(self, path)])[path]
         try:
             self._dataserver_version = LabOneVersion(version_str)
         except ValueError:
             err_msg = f"Version {version_str} is not supported by LabOne Q."
-            if server_qualifier.ignore_lab_one_version_error:
+            if server_qualifier.ignore_version_mismatch:
                 _logger.warning("Ignoring that %s", err_msg)
                 self._dataserver_version = LabOneVersion.LATEST
             else:
                 raise LabOneQControllerException(err_msg)
 
         [major, minor] = zi.__version__.split(".")[0:2]
         zi_python_version = f"{major}.{minor}"
         if zi_python_version != version_str:
             err_msg = f"Version of dataserver ({version_str}) and zi python ({zi_python_version}) do not match."
-            if self.server_qualifier.ignore_lab_one_version_error:
+            if self.server_qualifier.ignore_version_mismatch:
                 _logger.warning("Ignoring that %s", err_msg)
             else:
                 raise LabOneQControllerException(err_msg)
 
         _logger.info(
             "Connected to Zurich Instruments LabOne Data Server version %s at %s:%s",
             version_str,
```

## laboneq/controller/controller.py

```diff
@@ -69,15 +69,15 @@
 class ControllerRunParameters:
     shut_down: bool = False
     dry_run: bool = False
     disconnect: bool = False
     working_dir: str = "laboneq_output"
     setup_filename = None
     servers_filename = None
-    ignore_lab_one_version_error = False
+    ignore_version_mismatch = False
 
 
 # atexit hook
 def _stop_controller(controller: "Controller"):
     controller.shut_down()
 
 
@@ -88,15 +88,15 @@
         device_setup: DeviceSetup = None,
         user_functions: Dict[str, Callable] = None,
     ):
         self._run_parameters = run_parameters or ControllerRunParameters()
         self._devices = DeviceCollection(
             device_setup,
             self._run_parameters.dry_run,
-            self._run_parameters.ignore_lab_one_version_error,
+            self._run_parameters.ignore_version_mismatch,
         )
 
         self._last_connect_check_ts: float = None
 
         # Waves which are uploaded to the devices via pulse replacements
         self._current_waves = []
         self._user_functions: Dict[str, Callable] = user_functions
@@ -442,14 +442,22 @@
         if (
             self._last_connect_check_ts is None
             or now - self._last_connect_check_ts > CONNECT_CHECK_HOLDOFF
         ):
             self._devices.connect(self._is_using_standalone_compiler)
         self._last_connect_check_ts = now
 
+    def disable_outputs(
+        self,
+        device_uids: List[str] = None,
+        logical_signals: List[str] = None,
+        unused_only: bool = False,
+    ):
+        self._devices.disable_outputs(device_uids, logical_signals, unused_only)
+
     def shut_down(self):
         _logger.info("Shutting down all devices...")
         self._devices.shut_down()
         _logger.info("Successfully Shut down all devices.")
 
     def disconnect(self):
         _logger.info("Disconnecting from all devices and servers...")
@@ -597,15 +605,15 @@
         def __init__(self, controller: Controller):
             super().__init__(looping_mode=LoopingMode.EXECUTE)
             self.controller = controller
             self.step_param_nodes = []
             self.nt_loop_indices: List[int] = []
 
         def set_handler(self, path: str, value):
-            dev = self.controller._devices.find_by_path(path)
+            dev = self.controller._devices.find_by_node_path(path)
             self.step_param_nodes.append(
                 DaqNodeSetAction(
                     dev._daq, path, value, caching_strategy=CachingStrategy.NO_CACHE
                 )
             )
 
         def user_func_handler(self, func_name: str, args: Dict[str, Any]):
```

## laboneq/controller/devices/device_collection.py

```diff
@@ -1,16 +1,29 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
 import re
+from collections import defaultdict
 from copy import deepcopy
-from typing import TYPE_CHECKING, Callable, Dict, Iterator, List, Optional, Tuple, cast
+from typing import (
+    TYPE_CHECKING,
+    Callable,
+    Dict,
+    Iterator,
+    List,
+    Optional,
+    Set,
+    Tuple,
+    cast,
+)
+
+from zhinst.utils.api_compatibility import check_dataserver_device_compatibility
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeSetAction,
     DaqWrapper,
     DaqWrapperDryRun,
     ServerQualifier,
@@ -45,19 +58,19 @@
 
 
 class DeviceCollection:
     def __init__(
         self,
         device_setup: DeviceSetup,
         dry_run: bool,
-        ignore_lab_one_version_error: bool = False,
+        ignore_version_mismatch: bool = False,
     ):
         self._ds = DeviceSetupDAO(deepcopy(device_setup))
         self._dry_run = dry_run
-        self._ignore_lab_one_version_error = ignore_lab_one_version_error
+        self._ignore_version_mismatch = ignore_version_mismatch
         self._daqs: Dict[str, DaqWrapper] = {}
         self._devices: Dict[str, DeviceZI] = {}
 
     @property
     def all(self) -> Iterator[Tuple[str, DeviceZI]]:
         for uid, device in self._devices.items():
             yield uid, device
@@ -78,15 +91,15 @@
         device = self._devices.get(device_uid)
         if device is None:
             raise LabOneQControllerException(
                 f"Could not find device object for the device uid '{device_uid}'"
             )
         return device
 
-    def find_by_path(self, path: str):
+    def find_by_node_path(self, path: str) -> DeviceZI:
         m = re.match(r"^/?(DEV\d+)/.+", path.upper())
         if m is None:
             raise LabOneQControllerException(
                 f"Path '{path}' is not referring to any device"
             )
         serial = m.group(1).lower()
         for dev in self._devices.values():
@@ -209,14 +222,52 @@
     def disconnect(self):
         self.reset_monitor()
         for device in self._devices.values():
             device.disconnect()
         self._devices = {}
         self._daqs = {}
 
+    def disable_outputs(
+        self,
+        device_uids: List[str] = None,
+        logical_signals: List[str] = None,
+        unused_only: bool = False,
+    ):
+        # Set of outputs to disable or skip (depending on the 'invert' param) per device.
+        # Rationale for the logic: the actual number of outputs is only known by the connected
+        # device object, here we can only determine the outputs mapped in the device setup.
+        outputs_per_device: Dict[str, Optional[Set[int]]] = {}
+
+        if logical_signals is None:
+            invert = True
+            known_device_uids = [uid for uid, _ in self.all]
+            if device_uids is None:
+                device_uids = known_device_uids
+            else:
+                device_uids = [uid for uid in device_uids if uid in known_device_uids]
+            for device_uid in device_uids:
+                outputs_per_device[device_uid] = (
+                    self._ds.get_device_used_outputs(device_uid)
+                    if unused_only
+                    else set()
+                )
+        else:
+            invert = False
+            assert device_uids is None and not unused_only
+            for ls_path in logical_signals:
+                device_uid, outputs = self._ds.resolve_ls_path_outputs(ls_path)
+                if device_uid is not None:
+                    outputs_per_device.setdefault(device_uid, set()).update(outputs)
+
+        all_actions: List[DaqNodeSetAction] = []
+        for device_uid, outputs in outputs_per_device.items():
+            device = self.find_by_uid(device_uid)
+            all_actions.extend(device.disable_outputs(outputs, invert))
+        batch_set(all_actions)
+
     def shut_down(self):
         for device in self._devices.values():
             device.shut_down()
 
     def free_allocations(self):
         for device in self._devices.values():
             device.free_allocations()
@@ -234,15 +285,31 @@
         for daq in self._daqs.values():
             daq.node_monitor.stop()
 
     def reset_monitor(self):
         for daq in self._daqs.values():
             daq.node_monitor.reset()
 
+    def _validate_dataserver_device_fw_compatibility(self):
+        """Validate dataserver and device firmware compatibility."""
+        if not (self._dry_run or self._ignore_version_mismatch):
+            daq_dev_addrs = defaultdict(list)
+            for dev in self._ds.instruments:
+                daq_dev_addrs[dev.server_uid].append(dev.address)
+            for daq_uid, dev_addrs in daq_dev_addrs.items():
+                try:
+                    check_dataserver_device_compatibility(
+                        self._daqs.get(daq_uid)._zi_api_object, dev_addrs
+                    )
+                except Exception as error:
+                    raise LabOneQControllerException(str(error)) from error
+
     def _prepare_devices(self, is_using_standalone_compiler):
+        self._validate_dataserver_device_fw_compatibility()
+
         def make_device_qualifier(
             instrument: ZIStandardInstrument, daq: DaqWrapper, gen2: bool
         ) -> DeviceQualifier:
             driver = instrument.calc_driver()
             options = DeviceOptions(
                 **instrument.calc_options(),
                 is_using_standalone_compiler=is_using_standalone_compiler,
@@ -260,14 +327,15 @@
                 dry_run=self._dry_run, driver=driver, server=daq, options=options
             )
 
         updated_devices: Dict[str, DeviceZI] = {}
         for instrument in self._ds.instruments:
             daq = self._daqs.get(instrument.server_uid)
             device_qualifier = make_device_qualifier(instrument, daq, self._ds.has_shf)
+
             if device_qualifier.dry_run:
                 dry_run_daq: DaqWrapperDryRun = daq
                 dry_run_daq.map_device_type(device_qualifier)
             device = self._devices.get(instrument.uid)
             if device is None or device.device_qualifier != device_qualifier:
                 device = DeviceFactory.create(device_qualifier)
             device.remove_all_links()
@@ -305,15 +373,15 @@
     def _prepare_daqs(self):
         def make_server_qualifier(server: DataServer):
             return ServerQualifier(
                 dry_run=self._dry_run,
                 host=server.host,
                 port=int(server.port),
                 api_level=int(server.api_level),
-                ignore_lab_one_version_error=self._ignore_lab_one_version_error,
+                ignore_version_mismatch=self._ignore_version_mismatch,
             )
 
         updated_daqs: Dict[str, DaqWrapper] = {}
         for server_uid, server in self._ds.servers:
             server_qualifier = make_server_qualifier(server)
             existing = self._daqs.get(server_uid)
             if existing is not None and existing.server_qualifier == server_qualifier:
```

## laboneq/controller/devices/device_hdawg.py

```diff
@@ -1,19 +1,23 @@
 # Copyright 2019 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
 from enum import IntEnum
-from typing import Any, Dict, List, Optional, Tuple
+from typing import Any, Dict, List, Optional, Set, Tuple
 
 import numpy as np
 
-from laboneq.controller.communication import DaqNodeAction, DaqNodeSetAction
+from laboneq.controller.communication import (
+    CachingStrategy,
+    DaqNodeAction,
+    DaqNodeSetAction,
+)
 from laboneq.controller.devices.device_zi import DeviceZI
 from laboneq.controller.devices.zi_node_monitor import (
     Command,
     Condition,
     NodeControlBase,
     Prepare,
     Response,
@@ -94,14 +98,30 @@
         # and only 1 oscillator per channel pair without MF option.
         max_per_group = 4 if self._multi_freq else 1
         if previously_allocated >= max_per_group:
             return None
         osc_index_base = osc_group * max_per_group
         return osc_index_base + previously_allocated
 
+    def disable_outputs(
+        self, outputs: Set[int], invert: bool
+    ) -> List[DaqNodeSetAction]:
+        channels_to_disable: List[DaqNodeSetAction] = []
+        for ch in range(self._channels):
+            if (ch in outputs) != invert:
+                channels_to_disable.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/sigouts/{ch}/on",
+                        0,
+                        caching_strategy=CachingStrategy.NO_CACHE,
+                    )
+                )
+        return channels_to_disable
+
     def _nodes_to_monitor_impl(self) -> List[str]:
         nodes = []
         nodes.extend([node.path for node in self.clock_source_control_nodes()])
         nodes.extend([node.path for node in self.system_freq_control_nodes()])
         for awg in range(self._get_num_awgs()):
             nodes.append(f"/{self.serial}/awgs/{awg}/enable")
             nodes.append(f"/{self.serial}/awgs/{awg}/ready")
```

## laboneq/controller/devices/device_setup_dao.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from functools import cached_property
-from typing import Iterator, Tuple
+from typing import Iterator, Set, Tuple
 
 from laboneq.dsl.device.device_setup import DeviceSetup
 from laboneq.dsl.device.instruments.shfqa import SHFQA
 from laboneq.dsl.device.instruments.shfsg import SHFSG
 from laboneq.dsl.device.instruments.zi_standard_instrument import ZIStandardInstrument
 from laboneq.dsl.device.servers.data_server import DataServer
 
@@ -29,7 +29,42 @@
 
     @cached_property
     def has_shf(self):
         for instrument in self._device_setup.instruments:
             if isinstance(instrument, (SHFQA, SHFSG)):
                 return True
         return False
+
+    def resolve_ls_path_outputs(self, ls_path: str) -> Tuple[str, Set[int]]:
+        device_uid: str = None
+        outputs: Set[int] = set()
+        for instrument in self._device_setup.instruments:
+            for conn in instrument.connections:
+                if conn.remote_path == ls_path:
+                    if device_uid is None:
+                        device_uid = instrument.uid
+                    output_port = instrument.output_by_uid(conn.local_port)
+                    dev_outputs = (
+                        []
+                        if output_port is None or output_port.physical_port_ids is None
+                        else output_port.physical_port_ids
+                    )
+                    outputs.update([int(o) for o in dev_outputs])
+            if device_uid is not None:
+                # ignore the never-should-happen case when ls is mapped to multiple devices
+                break
+        return device_uid, outputs
+
+    def get_device_used_outputs(self, device_uid: str) -> Set[int]:
+        used_outputs: Set[int] = set()
+        for instrument in self._device_setup.instruments:
+            if instrument.uid == device_uid:
+                for conn in instrument.connections:
+                    output_port = instrument.output_by_uid(conn.local_port)
+                    dev_outputs = (
+                        []
+                        if output_port is None or output_port.physical_port_ids is None
+                        else output_port.physical_port_ids
+                    )
+                    used_outputs.update([int(o) for o in dev_outputs])
+                break
+        return used_outputs
```

## laboneq/controller/devices/device_shfqa.py

```diff
@@ -1,15 +1,15 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
 import time
-from typing import Any, Dict, List, Optional, Tuple
+from typing import Any, Dict, List, Optional, Set, Tuple
 
 import numpy as np
 from numpy import typing as npt
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
@@ -137,14 +137,30 @@
         if previously_allocated >= 1:
             return None
         return previously_allocated
 
     def _make_osc_path(self, channel: int, index: int) -> str:
         return f"/{self.serial}/qachannels/{channel}/oscs/{index}/freq"
 
+    def disable_outputs(
+        self, outputs: Set[int], invert: bool
+    ) -> List[DaqNodeSetAction]:
+        channels_to_disable: List[DaqNodeSetAction] = []
+        for ch in range(self._channels):
+            if (ch in outputs) != invert:
+                channels_to_disable.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/qachannels/{ch}/output/on",
+                        0,
+                        caching_strategy=CachingStrategy.NO_CACHE,
+                    )
+                )
+        return channels_to_disable
+
     def _nodes_to_monitor_impl(self) -> List[str]:
         nodes = []
         for awg in range(self._get_num_awgs()):
             nodes.extend(
                 [
                     f"/{self.serial}/qachannels/{awg}/generator/enable",
                     f"/{self.serial}/qachannels/{awg}/generator/ready",
```

## laboneq/controller/devices/device_shfsg.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
-from typing import Any, Dict, List, Optional
+from typing import Any, Dict, List, Optional, Set
 
 import numpy
 from numpy import typing as npt
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
@@ -127,14 +127,30 @@
         if previously_allocated >= 8:
             return None
         return previously_allocated
 
     def _make_osc_path(self, channel: int, index: int) -> str:
         return f"/{self.serial}/sgchannels/{channel}/oscs/{index}/freq"
 
+    def disable_outputs(
+        self, outputs: Set[int], invert: bool
+    ) -> List[DaqNodeSetAction]:
+        channels_to_disable: List[DaqNodeSetAction] = []
+        for ch in range(self._channels):
+            if (ch in outputs) != invert:
+                channels_to_disable.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/sgchannels/{ch}/output/on",
+                        0,
+                        caching_strategy=CachingStrategy.NO_CACHE,
+                    )
+                )
+        return channels_to_disable
+
     def _nodes_to_monitor_impl(self) -> List[str]:
         nodes = []
         for awg in range(self._get_num_awgs()):
             nodes.append(f"/{self.serial}/sgchannels/{awg}/awg/enable")
             nodes.append(f"/{self.serial}/sgchannels/{awg}/awg/ready")
         return nodes
```

## laboneq/controller/devices/device_uhfqa.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
-from typing import Any, Dict, List, Optional
+from typing import Any, Dict, List, Optional, Set
 
 import numpy as np
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeGetAction,
@@ -41,14 +41,15 @@
 
 
 class DeviceUHFQA(DeviceZI):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.dev_type = "UHFQA"
         self.dev_opts = ["AWG", "DIG", "QA"]
+        self._channels = 2
         self._use_internal_clock = True
 
     def _get_num_awgs(self):
         return 1
 
     def _osc_group_by_channel(self, channel: int) -> int:
         return channel
@@ -56,14 +57,30 @@
     def _get_next_osc_index(
         self, osc_group: int, previously_allocated: int
     ) -> Optional[int]:
         if previously_allocated >= 1:
             return None
         return previously_allocated
 
+    def disable_outputs(
+        self, outputs: Set[int], invert: bool
+    ) -> List[DaqNodeSetAction]:
+        channels_to_disable: List[DaqNodeSetAction] = []
+        for ch in range(self._channels):
+            if (ch in outputs) != invert:
+                channels_to_disable.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/sigouts/{ch}/on",
+                        0,
+                        caching_strategy=CachingStrategy.NO_CACHE,
+                    )
+                )
+        return channels_to_disable
+
     def _nodes_to_monitor_impl(self) -> List[str]:
         nodes = [f"/{self.serial}/system/extclk"]
         for awg in range(self._get_num_awgs()):
             nodes.append(f"/{self.serial}/awgs/{awg}/enable")
             nodes.append(f"/{self.serial}/awgs/{awg}/ready")
         return nodes
```

## laboneq/controller/devices/device_zi.py

```diff
@@ -98,16 +98,16 @@
 class DeviceZI(ABC):
     def __init__(self, device_qualifier: DeviceQualifier):
         self._device_qualifier: DeviceQualifier = device_qualifier
         self._downlinks: Dict[str, Tuple[str, ReferenceType[DeviceZI]]] = {}
         self._uplinks: Dict[str, ReferenceType[DeviceZI]] = {}
 
         self._daq: DaqWrapper = device_qualifier.server
-        self.dev_type = None
-        self.dev_opts = []
+        self.dev_type: str = None
+        self.dev_opts: List[str] = []
         self._connected = False
         self._allocated_oscs: List[AllocatedOscillator] = []
         self._allocated_awgs: Set[int] = set()
         self._nodes_to_monitor = None
         self._sampling_rate = None
 
         self._is_using_standalone_compiler = (
@@ -320,14 +320,30 @@
                 awg_module._api_wrapper("finish")
                 awg_module._api_wrapper("clear")
             self._awg_modules = []
 
         self._daq.disconnectDevice(self.serial)
         self._connected = False
 
+    def disable_outputs(
+        self, outputs: Set[int], invert: bool
+    ) -> List[DaqNodeSetAction]:
+        """Returns actions to disable the specified outputs for the device.
+
+        outputs: set(int)
+            - When 'invert' is False: set of outputs to disable.
+            - When 'invert' is True: set of used outputs to be skipped, remaining
+            outputs will be disabled.
+
+        invert: bool
+            Controls how 'outputs' argument is interpreted, see above. Special case: set
+            to True along with empty 'outputs' to disable all outputs.
+        """
+        return []
+
     def shut_down(self):
         _logger.debug(
             "%s: Turning off signal output (stub, not implemented).", self.dev_repr
         )
 
     def free_allocations(self):
         self._allocated_oscs.clear()
```

## laboneq/controller/devices/zi_emulator.py

```diff
@@ -95,16 +95,16 @@
 class NodeInfo:
     "Node descriptor to use in node definitions."
     type: NodeType = NodeType.FLOAT
     default: Optional[Any] = None
     read_only: bool = False
     handler: Callable[[NodeBase], None] = None
     # For DYNAMIC nodes
-    getter: Callable[[Any], None] = None
-    setter: Callable[[], Any] = None
+    getter: Callable[[], Any] = None
+    setter: Callable[[Any], None] = None
 
     def make_node(self) -> NodeBase:
         "Constructs concrete node instance from a node descriptor."
         if self.type == NodeType.DYNAMIC:
             node = NodeType.DYNAMIC.value(
                 read_only=self.read_only,
                 handler=self.handler,
@@ -298,14 +298,22 @@
             priority=0,
             action=self._ref_clock_switched,
             argument=(node.value,),
         )
 
     def _node_def(self) -> Dict[str, NodeInfo]:
         nd = {
+            "features/devtype": NodeInfo(
+                type=NodeType.STR,
+                default=self._dev_opts.get("features/devtype", "HDAWG8"),
+            ),
+            "features/options": NodeInfo(
+                type=NodeType.STR,
+                default=self._dev_opts.get("features/options", "MF\nME\nSKW"),
+            ),
             "system/clocks/sampleclock/status": NodeInfo(type=NodeType.INT, default=0),
             "system/clocks/sampleclock/freq": NodeInfo(
                 type=NodeType.FLOAT, default=2.4e9, handler=DevEmuHDAWG._sample_clock
             ),
             "system/clocks/referenceclock/source": NodeInfo(
                 type=NodeType.INT, default=0, handler=DevEmuHDAWG._ref_clock
             ),
@@ -372,14 +380,22 @@
 
     def _elf_upload(self, node: NodeBase):
         self._set_val("awgs/0/ready", 0)
         self._scheduler.enter(delay=0.001, priority=0, action=self._awg_ready)
 
     def _node_def(self) -> Dict[str, NodeInfo]:
         nd = {
+            "features/devtype": NodeInfo(
+                type=NodeType.STR,
+                default=self._dev_opts.get("features/devtype", "UHFQA"),
+            ),
+            "features/options": NodeInfo(
+                type=NodeType.STR,
+                default=self._dev_opts.get("features/options", "AWG\nDIG\nQA"),
+            ),
             "awgs/0/enable": NodeInfo(
                 type=NodeType.INT, default=0, handler=DevEmuUHFQA._awg_execute
             ),
             "awgs/0/elf/data": NodeInfo(
                 type=NodeType.VECTOR_INT, default=[], handler=DevEmuUHFQA._elf_upload
             ),
             "awgs/0/ready": NodeInfo(type=NodeType.INT, default=0),
@@ -517,15 +533,26 @@
                     type=NodeType.VECTOR_COMPLEX
                 )
         return nd
 
 
 class DevEmuSHFQA(DevEmuSHFQABase):
     def _node_def(self) -> Dict[str, NodeInfo]:
-        return self._node_def_qa()
+        nd = {
+            "features/devtype": NodeInfo(
+                type=NodeType.STR,
+                default=self._dev_opts.get("features/devtype", "SHFQA4"),
+            ),
+            "features/options": NodeInfo(
+                type=NodeType.STR,
+                default=self._dev_opts.get("features/options", ""),
+            ),
+        }
+        nd.update(self._node_def_qa())
+        return nd
 
 
 class DevEmuSHFSGBase(DevEmuHW):
     def _awg_stop_sg(self, channel: int):
         self._set_val(f"sgchannels/{channel}/awg/enable", 0)
 
     def _awg_execute_sg(self, node: NodeBase, channel: int):
```

## laboneq/dsl/laboneq_facade.py

```diff
@@ -18,17 +18,15 @@
 
 
 class LabOneQFacade:
     @staticmethod
     def connect(session: Session):
         run_parameters = ctrl.ControllerRunParameters()
         run_parameters.dry_run = session._connection_state.emulated
-        run_parameters.ignore_lab_one_version_error = (
-            session._ignore_lab_one_version_error
-        )
+        run_parameters.ignore_version_mismatch = session._ignore_version_mismatch
 
         controller = ctrl.Controller(
             run_parameters=run_parameters,
             device_setup=session._device_setup,
             user_functions=session._user_functions,
         )
         controller.connect()
```

## laboneq/dsl/session.py

```diff
@@ -1,26 +1,29 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
-import functools
 import json
 import logging
 from copy import deepcopy
 from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Union
 
 from numpy import typing as npt
 
 from laboneq._observability.tracing import trace
 from laboneq.controller.toolkit_adapter import ToolkitDevices
 from laboneq.core.exceptions import LabOneQException
 from laboneq.core.types import CompiledExperiment
 from laboneq.dsl.calibration import Calibration
 from laboneq.dsl.device import DeviceSetup
+from laboneq.dsl.device.io_units.logical_signal import (
+    LogicalSignalRef,
+    resolve_logical_signal_ref,
+)
 from laboneq.dsl.experiment import Experiment
 from laboneq.dsl.laboneq_facade import LabOneQFacade
 from laboneq.dsl.result import Results
 from laboneq.dsl.serialization import Serializer
 
 if TYPE_CHECKING:
     from laboneq.controller import Controller
@@ -41,50 +44,26 @@
     The session holds
         * the wiring definition of the devices
         * the experiment definition that should be run on the devices
         * the calibration of the devices for experiment
         * the compiled experiment
         * the result of the executed experiment
 
-    The Session is a statefull object that hold all of the above. The expected steps to interact with the session are:
+    The Session is a stateful object that hold all of the above. The expected steps to interact with the session are:
         * initial state (construction)
         * setting the device setup (optionally during construction)
         * (optional) setting the calibration of the devices
         * connecting to the devices (or the emulator)
         * compiling the experiment
         * running the experiment
         * accessing the results of the last run experiment
 
     The session is serializable in every state.
     """
 
-    class _SessionDeco:
-        """Collection of decorators specific to the Session class"""
-
-        @staticmethod
-        def entrypoint(func):
-            """Decorator for Session public methods.
-
-            Add this decorator to every public method of the Session,
-            that may be directly called by the user. These methods
-            may also call each other, and the decorator ensures that
-            in case of an occasional error, the 1st method (directly
-            called by the user) is reported in the error message,
-            even if the error happens inside a nested method call.
-            """
-
-            @functools.wraps(func)
-            def wrapper(self, *args, **kwargs):
-                self._call_stack.append(func.__name__)
-                res = func(self, *args, **kwargs)
-                self._call_stack.pop()
-                return res
-
-            return wrapper
-
     def __init__(
         self,
         device_setup: DeviceSetup = None,
         log_level: int = logging.INFO,
         performance_log=False,
         configure_logging=True,
         _last_results=None,
@@ -109,16 +88,14 @@
             Removed `max_simulation_time` instance variable.
         """
         self._device_setup = device_setup if device_setup else DeviceSetup()
         self._controller: Controller = None
         self._connection_state: ConnectionState = ConnectionState()
         self._experiment_definition = experiment
         self._compiled_experiment = compiled_experiment
-        # Keeps call stack of public methods (when calling each other)
-        self._call_stack: List[str] = list()
         self._last_results = _last_results
         if configure_logging:
             LabOneQFacade.init_logging(
                 log_level=log_level, performance_log=performance_log
             )
             self._logger = logging.getLogger(__name__)
             self._logger.setLevel(log_level)
@@ -166,94 +143,149 @@
                             case the session is not connected to the devices.
         """
         if message is None:
             message = ""
         if self._connection_state.connected:
             return True
         default_message = (
-            f"Session not connected.\n"
-            f"{self._call_stack[0]}() requires an established connection to devices in order to execute the experiment.\n"
-            f"Call connect() first. Use connect(do_emulation=True) if you want to emulate the devices' behavior only."
+            "Session not connected.\n"
+            "The call requires an established connection to devices in order to execute the experiment.\n"
+            "Call connect() first. Use connect(do_emulation=True) if you want to emulate the devices' behavior only."
         )
         message = message or default_message
         if fail:
             raise LabOneQException(message)
         self.logger.error(message)
         return False
 
-    @_SessionDeco.entrypoint
     def register_user_function(self, func, name: str = None):
         """Registers a user function to be referred from the experiment's `call` operation.
 
         Args:
             func (function): User function that is registered.
             name (str):     Optional name to use as the argument to experiment's `call` operation to refer to this
                             function. If not provided, function name will be used.
         """
 
         if name is None:
             name = func.__name__
         self._user_functions[name] = func
 
-    @_SessionDeco.entrypoint
     @trace("session.connect()")
     def connect(
-        self, do_emulation=False, ignore_lab_one_version_error=False
+        self,
+        do_emulation=False,
+        ignore_version_mismatch=False,
     ) -> ConnectionState:
         """Connects the session to the QCCS system.
 
         Args:
             do_emulation (bool): Specifies if the session should connect to a emulator
                                  (in the case of 'True') or the real system (in the case of 'False').
 
-            ignore_lab_one_version_error (bool): Ignore LabOne and LabOne Q version mismatch error.
+            ignore_version_mismatch (bool): Ignore version mismatches.
+                If set to `False` (default), the following checks are made for compatibility:
+
+                - Check LabOne and LabOne Q version compatibility.
+                - Check LabOne and Zurich Instruments' devices firmware version compatibility.
+
+                The following states raises an exception:
+
+                - Device firmware requires an update
+                - Device firmware requires an downgrade
+                - Device update is in progress
+
+                It is suggested to keep the versions aligned and up-to-date to avoid any unexpected behaviour.
+
+                .. versionchanged:: 2.4
+                    Renamed `ignore_lab_one_version_error` to `ignore_version_mismatch` and include
+                    LabOne and device firmware version compatibility check.
+
         """
-        self._ignore_lab_one_version_error = ignore_lab_one_version_error
+        self._ignore_version_mismatch = ignore_version_mismatch
         if (
             self._connection_state.connected
             and self._connection_state.emulated != do_emulation
         ):
             self.disconnect()
         self._connection_state.emulated = do_emulation
         LabOneQFacade.connect(self)
         self._connection_state.connected = True
         return self._connection_state
 
-    @_SessionDeco.entrypoint
     def disconnect(self) -> ConnectionState:
         """Disconnects the session from the devices."""
         self._connection_state.connected = False
         LabOneQFacade.disconnect(self)
         return self._connection_state
 
+    def disable_outputs(
+        self,
+        devices: Union[str, List[str]] = None,
+        signals: Union[LogicalSignalRef, List[LogicalSignalRef]] = None,
+        unused_only: bool = False,
+    ):
+        """Turns off / disables the device outputs.
+
+        Args:
+            devices (list): Optional. Device or list of devices, if not specified - all devices.
+                            All or unused (see 'unused_only') outputs of these devices will be
+                            disabled. Can't be used together with 'signals'.
+            signals (list): Optional. Logical signal or a list of logical signals. Outputs mapped
+                            by these logical signals will be disabled. Can't be used together
+                            with 'devices' or 'unused_only'.
+            unused_only (bool): Optional. If set to True, only outputs not mapped by any logical
+                            signals will be disabled. Can't be used together with 'signals'.
+        """
+        if devices is not None and signals is not None:
+            raise LabOneQException(
+                "Ambiguous outputs specification: disable_outputs() accepts either 'devices' or "
+                "'signals', but not both."
+            )
+        if unused_only and signals is not None:
+            raise LabOneQException(
+                "Ambiguous outputs specification: disable_outputs() accepts either 'signals' or "
+                "'unused_only=True', but not both."
+            )
+        if devices is not None and not isinstance(devices, list):
+            devices = [devices]
+        if signals is not None and not isinstance(signals, list):
+            signals = [signals]
+        if signals is not None:
+            signals = [resolve_logical_signal_ref(s) for s in signals]
+        self._controller.disable_outputs(devices, signals, unused_only)
+
     @property
     def connection_state(self) -> ConnectionState:
         """State of the connection."""
         return self._connection_state
 
-    @_SessionDeco.entrypoint
     @trace("session.compile()")
     def compile(
         self,
         experiment: Experiment,
         compiler_settings: Dict = None,
     ) -> Optional[CompiledExperiment]:
         """Compiles the specified experiment and stores it in the compiled_experiment property.
 
+        Requires connected LabOneQ session (`session.connect()`) either with or without emulation mode.
+
         Args:
             experiment: Experiment instance that should be compiled.
             compiler_settings: Extra options passed to the compiler.
 
+        .. versionchanged:: 2.4
+
+            Raises error if `Session` is not connected.
+
         .. versionchanged:: 2.0
 
             Removed `do_simulation` argument. Use :class:`~.OutputSimulator` instead.
         """
-        if not self._assert_connected(fail=False):
-            return
-
+        self._assert_connected(fail=True)
         self._experiment_definition = experiment
         self._compiled_experiment = LabOneQFacade.compile(
             self, self.logger, compiler_settings=compiler_settings
         )
         self._last_results = None
         return self._compiled_experiment
 
@@ -261,22 +293,23 @@
     def compiled_experiment(self) -> Optional[CompiledExperiment]:
         """Access to the compiled experiment.
 
         The compiled experiment can be assigned to a different session if the device setup is matching.
         """
         return self._compiled_experiment
 
-    @_SessionDeco.entrypoint
     @trace("session.run()")
     def run(
         self,
         experiment: Optional[Union[Experiment, CompiledExperiment]] = None,
     ) -> Optional[Results]:
         """Executes the compiled experiment.
 
+        Requires connected LabOneQ session (`session.connect()`) either with or without emulation mode.
+
         If no experiment is specified, the last compiled experiment is run.
         If an experiment is specified, the provided experiment is assigned to the
         internal experiment of the session.
 
         .. versionchanged:: 2.0
 
             Removed `do_simulation` argument. Use :class:`~.OutputSimulator` instead.
@@ -286,71 +319,80 @@
                 run. The experiment will be compiled if it has not been yet. If no
                 experiment is specified the previously assigned and compiled experiment
                 is used.
 
         Returns:
             A `Results` object in case of success. `None` if the session is not
             connected.
+
+        .. versionchanged:: 2.4
+
+            Raises error if `Session` is not connected.
         """
+        self._assert_connected(fail=True)
         if experiment:
             if isinstance(experiment, CompiledExperiment):
                 self._compiled_experiment = experiment
             else:
                 self.compile(experiment)
 
-        if not self._assert_connected(fail=False):
-            return
-
         self._last_results = Results(
             experiment=self.experiment,
             device_setup=self.device_setup,
             compiled_experiment=self.compiled_experiment,
             acquired_results={},
             user_func_results={},
             execution_errors=[],
         )
         LabOneQFacade.run(self)
         return self.results
 
-    @_SessionDeco.entrypoint
     def submit(
         self,
         experiment: Optional[Union[Experiment, CompiledExperiment]] = None,
-        queue: Callable[[str, CompiledExperiment, DeviceSetup], Any] = None,
+        queue: Callable[[str, Optional[CompiledExperiment], DeviceSetup], Any] = None,
     ) -> Results:
         """Asynchronously submit experiment to the given queue.
 
         If no experiment is specified, the last compiled experiment is run.
         If an experiment is specified, the provided experiment is assigned to the
         internal experiment of the session.
 
         Args:
             experiment: Optional. Experiment instance that should be
                 run. The experiment will be compiled if it has not been yet. If no
                 experiment is specified the previously assigned and compiled experiment
                 is used.
             queue: The name of connector to a queueing system which should do the actual
                 run on a setup. `queue` must be callable with the signature
-                ``(name: str, experiment: CompiledExperiment, device_setup: DeviceSetup)``
+                ``(name: str, experiment: Optional[CompiledExperiment], device_setup: DeviceSetup)``
                 which returns an object with which users can query results.
 
         Returns:
             An object with which users can query results. Details depend on the
             implementation of the queue.
         """
 
         if experiment:
             if isinstance(experiment, CompiledExperiment):
                 self._compiled_experiment = experiment
+                return queue(
+                    experiment.experiment.uid,
+                    self.compiled_experiment,
+                    self.device_setup,
+                )
             else:
+                self._assert_connected(fail=True)
                 self.compile(experiment)
+                return queue(
+                    experiment.uid, self.compiled_experiment, self.device_setup
+                )
+        else:
+            return queue("", self.compiled_experiment, self.device_setup)
 
-        return queue(experiment.uid, self.compiled_experiment, self.device_setup)
-
-    @_SessionDeco.entrypoint
     def replace_pulse(
         self, pulse_uid: str | Pulse, pulse_or_array: npt.ArrayLike | Pulse
     ):
         LabOneQFacade.replace_pulse(self, pulse_uid, pulse_or_array)
 
     def get_results(self) -> Results:
         """
```

## laboneq/dsl/device/io_units/logical_signal.py

```diff
@@ -1,14 +1,15 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from contextlib import contextmanager
 from dataclasses import dataclass
-from typing import Optional
+from typing import Optional, Union
 
+from laboneq.core.exceptions.laboneq_exception import LabOneQException
 from laboneq.core.types.enums import IODirection
 from laboneq.dsl.calibration import MixerCalibration, SignalCalibration
 from laboneq.dsl.calibration.calibratable import Calibratable
 from laboneq.dsl.device.io_units.physical_channel import (
     PHYSICAL_CHANNEL_CALIBRATION_FIELDS,
     PhysicalChannel,
 )
@@ -317,7 +318,26 @@
             # calibration is empty, no need to hold on to it
             with self._suspend_callback():
                 self._calibration = None
 
     @property
     def physical_channel(self):
         return self._physical_channel
+
+
+LogicalSignalRef = Union[LogicalSignal, str]
+
+
+def resolve_logical_signal_ref(logical_signal_ref: LogicalSignalRef) -> str:
+    if logical_signal_ref is None:
+        return None
+    if isinstance(logical_signal_ref, str):
+        return logical_signal_ref
+    if (
+        not isinstance(logical_signal_ref, LogicalSignal)
+        or logical_signal_ref.path is None
+    ):
+        raise LabOneQException(
+            "Invalid LogicalSignal: Seems like the logical signal is not part of a qubit setup. "
+            "Make sure the object is retrieved from a device setup."
+        )
+    return logical_signal_ref.path
```

## laboneq/dsl/experiment/experiment.py

```diff
@@ -6,15 +6,15 @@
 from collections import deque
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Any, Deque, Dict, List, Optional, Union
 
 from laboneq.core.exceptions import LabOneQException
 from laboneq.core.types.enums import DSLVersion
 from laboneq.dsl.calibration.calibration import Calibration
-from laboneq.dsl.device.io_units.logical_signal import LogicalSignal
+from laboneq.dsl.device.io_units.logical_signal import LogicalSignalRef
 from laboneq.dsl.enums import (
     AcquisitionType,
     AveragingMode,
     ExecutionType,
     RepetitionMode,
 )
 from laboneq.dsl.experiment.pulse import Pulse
@@ -55,15 +55,15 @@
                 if isinstance(s, str):
                     signals_dict[s] = ExperimentSignal(uid=s)
                 else:
                     signals_dict[s.uid] = s
             self.signals = signals_dict
 
     def add_signal(
-        self, uid: str = None, connect_to: Union[LogicalSignal, str] = None
+        self, uid: str = None, connect_to: LogicalSignalRef = None
     ) -> ExperimentSignal:
         """Add an experiment signal to the experiment.
 
         :param uid: The unique id of the new experiment signal (optional).
         :type uid: UID = str
         :param connect_to:
             The `LogicalSignal` this experiment signal shall be connected to.
@@ -102,17 +102,15 @@
         :param uid: The unique id of the experiment signal to check for.
         :type uid: UID = str
         :return (bool): `True` if the experiment signal is defined in this
             experiment, `False` otherwise.
         """
         return uid in self.signals.keys()
 
-    def map_signal(
-        self, experiment_signal_uid: str, logical_signal: Union[LogicalSignal, str]
-    ):
+    def map_signal(self, experiment_signal_uid: str, logical_signal: LogicalSignalRef):
         """Connect an experiment signal to a logical signal.
 
         In order to relate an experiment signal to a logical signal defined in a
         device setup (:class:`~.DeviceSetup`), you need to make
         a connection between these two types of signals.
 
         :param experiment_signal_uid: The unique id of the experiment signal to
@@ -128,15 +126,15 @@
                 f"Unknown experiment signal: {experiment_signal_uid}. Call experiment.experiment_signals to get a "
                 f"list of experiment signals defined in this experiment. Call experiment.add_signal() to add a signal "
                 f"prior to connect id to a LogicalSignal. "
             )
 
         self.signals[experiment_signal_uid].map(logical_signal)
 
-    def reset_signal_map(self, signal_map: Dict[str, Union[LogicalSignal, str]] = None):
+    def reset_signal_map(self, signal_map: Dict[str, LogicalSignalRef] = None):
         """Reset i.e. disconnect all defined signal connections."""
 
         for signal in self.signals.values():
             signal.disconnect()
         if signal_map:
             self.set_signal_map(signal_map)
 
@@ -172,20 +170,20 @@
     def get_signal_map(self) -> Dict[str, str]:
         return {
             signal.uid: signal.mapped_logical_signal_path
             for signal in self.signals.values()
             if signal.is_mapped()
         }
 
-    def set_signal_map(self, signal_map: Dict[str, Union[LogicalSignal, str]]):
-        for signal_uid, logical_signal_uid in signal_map.items():
+    def set_signal_map(self, signal_map: Dict[str, LogicalSignalRef]):
+        for signal_uid, logical_signal_ref in signal_map.items():
             if signal_uid not in self.signals.keys():
                 self._signal_not_found_error(signal_uid, "Cannot apply signal map.")
 
-            self.signals[signal_uid].map(to=logical_signal_uid)
+            self.signals[signal_uid].map(to=logical_signal_ref)
 
     # Calibration ....................................
 
     def _signal_not_found_error(self, signal_uid: str, msg: str = None):
         if msg is None:
             msg = ""
         raise LabOneQException(
```

## laboneq/dsl/experiment/experiment_signal.py

```diff
@@ -1,15 +1,18 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 from typing import Optional
 
-from laboneq.core.exceptions import LabOneQException
 from laboneq.dsl.calibration import MixerCalibration, SignalCalibration
+from laboneq.dsl.device.io_units.logical_signal import (
+    LogicalSignalRef,
+    resolve_logical_signal_ref,
+)
 
 experiment_signal_id = 0
 
 
 def experiment_signal_id_generator():
     global experiment_signal_id
     retval = f"s{experiment_signal_id}"
@@ -24,15 +27,15 @@
     uid: str
     calibration: Optional[SignalCalibration]
     mapped_logical_signal_path: Optional[str]
 
     def __init__(
         self,
         uid=None,
-        map_to=None,
+        map_to: LogicalSignalRef = None,
         calibration=None,
         oscillator=None,
         amplitude: float = None,
         port_delay: float = None,
         delay_signal: float = None,
         mixer_calibration=None,
         precompensation=None,
@@ -77,23 +80,16 @@
         self.map(map_to)
         if mapped_logical_signal_path is not None:
             self.map(mapped_logical_signal_path)
 
     def is_mapped(self):
         return self.mapped_logical_signal_path is not None
 
-    def map(self, to):
-        if isinstance(to, str):
-            self.mapped_logical_signal_path = to
-        else:
-            if to is not None and (not hasattr(to, "path") or to.path is None):
-                raise LabOneQException(
-                    "Invalid LogicalSignal: Seems like the logical signal is not part of a qubit setup. Make sure the object is retrieved from a device setup."
-                )
-            self.mapped_logical_signal_path = to.path if to is not None else None
+    def map(self, to: LogicalSignalRef):
+        self.mapped_logical_signal_path = resolve_logical_signal_ref(to)
 
     def disconnect(self):
         """Disconnect the experiment signal from the logical signal."""
         self.mapped_logical_signal_path = None
 
     @property
     def mixer_calibration(self):
```

## laboneq/simulator/seqc_parser.py

```diff
@@ -18,14 +18,15 @@
 from pycparser.c_ast import (
     ID,
     Assignment,
     BinaryOp,
     Constant,
     Decl,
     DoWhile,
+    For,
     FuncCall,
     FuncDef,
     If,
     Node,
     UnaryOp,
 )
 from pycparser.c_parser import CParser
@@ -243,27 +244,35 @@
 
     elif isinstance(item, DoWhile):
         endless_guard = 10000
         while True:
             for subitem in item.stmt.children():
                 parse_item(subitem[1], runtime)
             variable_value = 0
-            condition_variable_name = "UNKNOWN"
             try:
                 variables = runtime.variables
                 condition_variable_name = item.cond.name
                 variable_value = int(variables[condition_variable_name]["value"])
             except AttributeError:
                 pass
 
             if variable_value <= 0:
                 break
             endless_guard -= 1
             if endless_guard <= 0:
                 raise RuntimeError("Endless guard triggered")
+    elif isinstance(item, For):
+        if item.cond is not None or item.next is not None:
+            raise NotImplementedError("for loops not supported in the simulator")
+
+        # if cond and next are None, assume the for loop is just encoding a seqc repeat
+        n = int(parse_expression(item.init, runtime))
+        for i in range(n):
+            for subitem in item.stmt.children():
+                parse_item(subitem[1], runtime)
     if (
         runtime.max_time is not None
         and runtime._last_play_start_samples()[0] / runtime.descriptor.sampling_rate
         > runtime.max_time
     ):
         # Stop, once a time-span event encountered, that is entirely outside the simulation region.
         # This is important, as any point-in-time events before must be captured. This last time-span
@@ -441,14 +450,16 @@
             "startQAResult": self.startQAResult,
             "configFreqSweep": self.configFreqSweep,
             "setSweepStep": self.setSweepStep,
             "setOscFreq": self.setOscFreq,
             "setTrigger": self.setTrigger,
             "setPrecompClear": self.setPrecompClear,
             "waitWave": self.waitWave,
+            "waitDIOTrigger": self.waitDIOTrigger,
+            "waitZSyncTrigger": self.waitZSyncTrigger,
         }
         self.variables = {}
         self.seqc_simulation = SeqCSimulation()
         self.times = {}
         self.times_at_port = {}
         self.descriptor = descriptor
         self.waves = waves
@@ -844,14 +855,34 @@
                 start_samples=time_samples,
                 length_samples=0,
                 operation=Operation.WAIT_WAVE,
                 args=[],
             )
         )
 
+    def _start_trigger(self):
+        # Here the assumption is that before the start trigger event, only playZeros
+        # could potentially affect timings, so we only remove the effect of playZero
+        # events. Besides, only one start trigger event is assumed.
+        back_shift_samples = 0
+        filtered_events = []
+        for ev in self.seqc_simulation.events:
+            if ev.operation == Operation.PLAY_ZERO:
+                back_shift_samples += ev.length_samples
+            else:
+                ev.start_samples -= back_shift_samples
+                filtered_events.append(ev)
+        self.seqc_simulation.events = filtered_events
+
+    def waitDIOTrigger(self):
+        self._start_trigger()
+
+    def waitZSyncTrigger(self):
+        self._start_trigger()
+
 
 def find_device(recipe, device_uid):
     for device in recipe["devices"]:
         if device["device_uid"] == device_uid:
             return device
     return None
 
@@ -997,14 +1028,27 @@
             return ""
         else:
             return match.group(1)
 
     user_functions = regex.sub(_replacer, user_functions)
     main = regex.sub(_replacer, main)
 
+    # repeat(n) {...} is not valid C, and topples the parser. Replace it with `for(n;;) {...}`.
+    # Note that the result does not correspond to the usual C for-loop semantics.
+    # This is fine though, as we do not emit 'regular' for loops from L1Q.
+    pattern = r"repeat\s*\((\d+)\)\s*{"
+    regex = re.compile(pattern, re.MULTILINE | re.DOTALL)
+
+    def replace_repeat(match_obj):
+        if match_obj.group(1) is not None:
+            n = match_obj.group(1)
+            return f"for({n};;) {{"
+
+    main = regex.sub(replace_repeat, main)
+
     # Define SeqC built-ins and wrap program into function
     # to make the program syntactically correct for C parser.
     if len(main) > 0:
         source = (
             f"typedef int var;\n"
             f"typedef const char* wave;\n"
             f"typedef const char* string;\n"
```

## Comparing `laboneq-2.3.0.dist-info/LICENSE` & `laboneq-2.4.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `laboneq-2.3.0.dist-info/METADATA` & `laboneq-2.4.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: laboneq
-Version: 2.3.0
+Version: 2.4.0
 Summary: Zurich Instruments LabOne Q software framework for quantum computing control
 Author-email: Zurich Instruments Development Team <info@zhinst.com>
 License: Apache 2.0
 Project-URL: Homepage, https://github.com/zhinst/laboneq
 Keywords: quantum,sdk,zhinst
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
@@ -38,17 +38,17 @@
 Requires-Dist: pycparser
 Requires-Dist: python-box
 Requires-Dist: pyyaml
 Requires-Dist: requests
 Requires-Dist: rustworkx
 Requires-Dist: scipy
 Requires-Dist: sortedcollections
-Requires-Dist: zhinst-core (==23.2.41338)
+Requires-Dist: zhinst-core (==23.2.42414)
 Requires-Dist: zhinst-toolkit (~=0.5.0)
-Requires-Dist: zhinst-utils (~=0.2.0)
+Requires-Dist: zhinst-utils (~=0.3.0)
 
 ![LabOne Q logo](https://github.com/zhinst/laboneq/raw/main/docs/images/Logo_LabOneQ.png)
 
 
 # LabOne Q
 
 [LabOne Q](https://www.zhinst.com/quantum-computing-systems/labone-q) is Zurich
```

## Comparing `laboneq-2.3.0.dist-info/RECORD` & `laboneq-2.4.0.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,139 +1,139 @@
-laboneq/VERSION.txt,sha256=QPM0qCXSu8tde96GOEMlDxMx4MqzDSLWvaM-Iq7CypY,5
+laboneq/VERSION.txt,sha256=B7cWS4CxDuWfVq1kZeO2ws8Se_7Cb8K3FjgCCxnX9cg,5
 laboneq/__init__.py,sha256=xb0bbmhv6-zquNTknTRURgHIU1VG11TJVgz5svWkvzI,306
 laboneq/_token.py,sha256=D2wS1TbZ6-CzF73l5kd6Wilcm18IPyymygB6VakHyRc,2829
 laboneq/_version.py,sha256=zaxeCShR641vx5bH27_dVdirv71bA2i9ciFcH4A2krE,238
 laboneq/simple.py,sha256=C_pJmGq56erohy1tXvTNVhPypqlf0xsl4Anz1qLXJrY,1392
 laboneq/_observability/__init__.py,sha256=rcsPn8d52W6G9ZGkI8TPrEtwSJ2WbQN_Urc2DiIaUDg,184
 laboneq/_observability/tracing/__init__.py,sha256=rEFK2BFplAYa8ZHwQpiaVKv9EaSDrUWKHBplg-AmzGE,538
 laboneq/_observability/tracing/_noop_tracer.py,sha256=z7yhOOaTwCbWTQVQJ3i0SPCYsvd2wdbngf7ygoPJVCE,893
 laboneq/_observability/tracing/_tracer.py,sha256=vqgWJiy17tpzSMIOFXgkXHg9oQotbM8Jd-cWjNyVvk0,2309
 laboneq/compiler/__init__.py,sha256=PQOZ0TyWFSH0U7NJZnaYtO62iQW7DGgEV5KQD0lyKVw,444
 laboneq/compiler/fastlogging.py,sha256=SCJykQ5V_qvRPvWkkDZOqFexmazzhW-fbP2jkglOUkA,204
-laboneq/compiler/qccs-schema_2_5_0.json,sha256=4wCGc0EGyuyCfxQMZCDMeMyDFTUZSZVFAsRW-m6nu9A,22466
+laboneq/compiler/qccs-schema_2_5_0.json,sha256=YauxP1Z39AGXi5lUB7eKRLsRxsllayxNlzeyHQBGOSY,22524
 laboneq/compiler/remote.py,sha256=Fyb1RaWU-JBudPSv3LN56yQhYndduOchiai2brTE1WA,666
 laboneq/compiler/code_generator/__init__.py,sha256=s8ihwbuWxGpCAMjnsBXQ0kdoXGqT-B8doSsk850gQA0,654
 laboneq/compiler/code_generator/analyze_events.py,sha256=xA7nDePKXzxQHeR4m95cOmN0CBTR6KY5T3mccT7bBM8,18645
 laboneq/compiler/code_generator/analyze_playback.py,sha256=x4GitPjYDZuSsDWxAeQgFD-2fCltVFiYWTPDnsCdaJw,28581
-laboneq/compiler/code_generator/code_generator.py,sha256=0Gdk_6qYM8zExgMUwvn4Fwx-s51b44-doF6hVQH2YmM,64344
+laboneq/compiler/code_generator/code_generator.py,sha256=Y16IhjEpk4Xo6d1wTsoLXtz18XVBoCIG6Rmd3bt2isM,64112
 laboneq/compiler/code_generator/command_table_tracker.py,sha256=jXD4Ep8SMIgS_DNqgdfnGujma-oRhRZcvFcIa-AkAXc,4026
-laboneq/compiler/code_generator/compressor.py,sha256=sZ4gWu20ZaB7r6_Y136byCKJ7R2gAD1nfLdeCK9d4OU,6917
+laboneq/compiler/code_generator/compressor.py,sha256=LH8CQY53TbJzcZ5ckroZnFgoAFT3rL81cKXWVHELxVM,2727
 laboneq/compiler/code_generator/feedback_register_allocator.py,sha256=iXuwHFa9g5YQriNqLHXoHIzkBanyR8XnD9C0mw6sPQU,1414
 laboneq/compiler/code_generator/interval_calculator.py,sha256=7dyk02iUdPHyzS4DU6JvkTKn36yWpUE2lhvUynY0aYQ,10355
 laboneq/compiler/code_generator/measurement_calculator.py,sha256=LkgLsVU-majR3ogXvGyuCItb7iNW6Q9QrssJS1gX-Rk,18617
-laboneq/compiler/code_generator/sampled_event_handler.py,sha256=i8qiXsLjkU5HEu_Yb7gI0QyvPdsoCryHbm0Bfg9xBG0,30091
-laboneq/compiler/code_generator/seq_c_generator.py,sha256=dtMVWxFxGg6u7HURC0N9F7G9oR78YnMtkBCqBx-hBiY,15940
-laboneq/compiler/code_generator/seqc_tracker.py,sha256=ki7uv9HfdIXViaSa-gXy-Xl2seTwK20wyOAEavF-zLo,6160
+laboneq/compiler/code_generator/sampled_event_handler.py,sha256=c9JocBLk6H_kdQpeVbpGfdQW87FjkMfPh-odBvh1Wvg,29598
+laboneq/compiler/code_generator/seq_c_generator.py,sha256=ZQfRlFHAK2nKefoy4cJD6d9SZvGGFsXJ5iYLjoDi6Zk,18104
+laboneq/compiler/code_generator/seqc_tracker.py,sha256=a2Jmd7ZZmG3eYleoaqDKEq1H4ntydacdpU59PBTbjVg,6129
 laboneq/compiler/code_generator/signatures.py,sha256=2Ez4Tw_IbmQ2pwkpVMoWKsAuyy6h0mpRIWVUNVMb6-E,7741
 laboneq/compiler/code_generator/utils.py,sha256=KJtRJg6wE8FPALrG4B8H7GRZa_7WqOrXroWW8kgSdBA,3500
 laboneq/compiler/code_generator/wave_index_tracker.py,sha256=700LQq60nX9Btcn9bj2SDn674qRmsxy_Nz6yy0qx1Y0,1476
 laboneq/compiler/common/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/common/awg_info.py,sha256=djhjq5t8JruHRi9hKk4rtBVH4KfMWRkuamcypmhP6WA,1093
 laboneq/compiler/common/awg_sampled_event.py,sha256=IWSNsuACjHMJIvQpwSOY4-yMfQEyAyB9rY1myA1xcJc,1903
 laboneq/compiler/common/awg_signal_type.py,sha256=aXiZ_K-yaG1pPPUMh5IpOXn2rQJngQnTzwqP1LExtT8,480
 laboneq/compiler/common/compiler_settings.py,sha256=KKBWEH8ZQ10AGaniDKZvpE9sv2eicYNlnYweORJ6EYs,3983
 laboneq/compiler/common/device_type.py,sha256=qKT5nHiHA9RrmX-NzAOXMo6ubQ_BKOdjC0PngAXHET0,4547
 laboneq/compiler/common/event_type.py,sha256=VJiiMUTbZHTetjnBPEPyoSVREczPAjTTxA7d7GbjN9M,1532
 laboneq/compiler/common/play_wave_type.py,sha256=9olrAuZqSSq-3fDpUCwbH2IC2F1mYaZ64H_NG0J6eXM,229
 laboneq/compiler/common/pulse_parameters.py,sha256=zhIljy4MHaBGSFYR-28ksDetM39C5p006e8flU21ZWE,580
-laboneq/compiler/common/signal_obj.py,sha256=1PBfxlHeXzCdMmCF04WgTLSNS8-Wp8wJXpKv1llxJx8,953
+laboneq/compiler/common/signal_obj.py,sha256=IW9XWj_z2rL3yKR9IOpwJsqRs7_yQnjg2zyhzDNxyHs,2052
 laboneq/compiler/common/trigger_mode.py,sha256=PfV_HskFUlk99bsngdjYz-b137e2qA6e1TNqA0Bjvbs,400
 laboneq/compiler/experiment_access/__init__.py,sha256=mb9ULouZiKIforKo2d458L6pvf0LmV4PXhmKhPBUj7g,154
 laboneq/compiler/experiment_access/acquire_info.py,sha256=bQrMObuyxABUpGTc0ubuUvOs15KzKJzos1dPw4B_PYs,222
 laboneq/compiler/experiment_access/cache.py,sha256=aCJLqqHMPPNk7k-ngo3GaeWQWMYq8THvSv-UL8gUVHs,602
-laboneq/compiler/experiment_access/device_info.py,sha256=h2cEwK0ZhO94kauhd_67Xs9BTW1ghvOQN8NCUa8ivYY,295
-laboneq/compiler/experiment_access/dsl_loader.py,sha256=sUV47RGDofyrNw9WMwCnP6Rmf4K3UX_Zt69KTO3fRX8,41960
-laboneq/compiler/experiment_access/experiment_dao.py,sha256=smpplRW8KfSSaF96O1KwA1b_llweTYpkR70IreGBteU,16225
-laboneq/compiler/experiment_access/json_dumper.py,sha256=c28dGtrcUoiqHszcjYiHsrGkQ0Uuw_u_mlml63szcQ8,13914
-laboneq/compiler/experiment_access/json_loader.py,sha256=2Cl1Oeloz0CJ2OBrJIHk6D3A_icNeUexjuaJC4gUXD0,20890
-laboneq/compiler/experiment_access/loader_base.py,sha256=GSd58mKuzEXu7UvMqAxHPg4XqOi2ofBp067Mb4IlwHI,6134
+laboneq/compiler/experiment_access/device_info.py,sha256=HQBj1WpSt8TwHX5G_kE-1m5ulJ06-j_hdIIVamxHQDI,349
+laboneq/compiler/experiment_access/dsl_loader.py,sha256=1rg_cs1axD4PWt-djJIY9AtFdHLRNzkjRMTCSj2Z9vk,42040
+laboneq/compiler/experiment_access/experiment_dao.py,sha256=5MG64Xs14smIr0WgBREpoasfn6S1mpQBIAINJlBj4oc,16297
+laboneq/compiler/experiment_access/json_dumper.py,sha256=hxoXcg22dxPkSKiLwvfUSby3eKiHRglHQkPb7DZxycI,13923
+laboneq/compiler/experiment_access/json_loader.py,sha256=khRSAonzS8_9xZe28ib0BkkzFTwvLAsrpds5XadgmP4,20960
+laboneq/compiler/experiment_access/loader_base.py,sha256=FEFxOs-_tS8ZMbLRAeaY7jDkFV6EmJvgxoKirI7kFo8,6182
 laboneq/compiler/experiment_access/marker.py,sha256=2Okj9Q_Ukk02B-Z7_WDM6nHN-nuXw3qFjUNaw8LUMsI,270
 laboneq/compiler/experiment_access/oscillator_info.py,sha256=15pG8WPRsSvJYgsX5Z3GiOWnABVCRXY5n6jLEZfewzw,260
 laboneq/compiler/experiment_access/param_ref.py,sha256=wqyyzAiSIEu2GVeNdZc-MtvdhdSDp1Quch8qBVIPppw,197
 laboneq/compiler/experiment_access/pulse_def.py,sha256=HgUWmq0wyU1HWjBz2pADa8WhrQSnTsQN62zbkzbK_vA,1263
 laboneq/compiler/experiment_access/section_graph.py,sha256=0bIQle4g1adY8Ke7DjBG143Y4eWbTakO6YXdHzS3Tw8,21550
 laboneq/compiler/experiment_access/section_info.py,sha256=vRIw7KvrlNhXjh8ynUjGUer_DVJPxdo9FGBdDMWVuUY,851
 laboneq/compiler/experiment_access/section_signal_pulse.py,sha256=ZGgbvNW3v-qIgyvcW34Lk31hyhFeNb_UjE6uIUXd8os,1069
 laboneq/compiler/experiment_access/signal_info.py,sha256=HLkN-Kq2vZrh5tg92RA3ZSSYaiRXXQecw01-NtXGR_Q,387
 laboneq/compiler/new_scheduler/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/compiler/new_scheduler/case_schedule.py,sha256=rFDTK5-BQFB9tIPJTIvONOsDP6rcXnPSiuJ5yCbG4Fg,3133
-laboneq/compiler/new_scheduler/interval_schedule.py,sha256=DbL9eRFi2d3pZmXUPKxtrVx6s5LecYGRukCXdOC-Ivo,5890
-laboneq/compiler/new_scheduler/loop_iteration_schedule.py,sha256=alW0RLhGZfeBVYUNgCpt---6fS2LdEYwEZYC3kbMsMU,3317
-laboneq/compiler/new_scheduler/loop_schedule.py,sha256=fVHdhrY8Upt8fQxwD9qMVCRnotX4vemvYDkbqzYaovA,8531
-laboneq/compiler/new_scheduler/match_schedule.py,sha256=AzJ_3kBZ7kusC06dQvyeneZTCKHUH4MUfmZNzjeq0a8,2016
-laboneq/compiler/new_scheduler/oscillator_schedule.py,sha256=wNPD2XjVcun0gdPJjnx9p9NxUhZVvZ0zWk4VOyueUiY,2180
-laboneq/compiler/new_scheduler/phase_reset_schedule.py,sha256=KCphlGtuM54ddDblNz4G5tFD0GVsTtrVQMwFe7CuD-Q,1654
+laboneq/compiler/new_scheduler/case_schedule.py,sha256=hx2y33Cwjm484ZW3fYzheuQEjgg1dvJHMxfRzWIITR8,3269
+laboneq/compiler/new_scheduler/interval_schedule.py,sha256=x9ZbMhVZxoDjLHs5SbbgTpvf7YhDsIFJCr75ATr-_Io,7443
+laboneq/compiler/new_scheduler/loop_iteration_schedule.py,sha256=oWQaNGxixdxnkSDbdxfNMboMxTwD0GWf3V80kaeKcpg,3331
+laboneq/compiler/new_scheduler/loop_schedule.py,sha256=kUzQ3v-2Ca-w5f0nqxM1yIUjeYWKL5o6HPe7LNe9qyA,8588
+laboneq/compiler/new_scheduler/match_schedule.py,sha256=_cl7dYmEKLf7Y7KU306aUSXeUHQrE1yyeTY4pT2l3IM,7197
+laboneq/compiler/new_scheduler/oscillator_schedule.py,sha256=80LLDWtu12iseHHvKoysfzDRCYnK8EkJjK2sgZFdcqA,2252
+laboneq/compiler/new_scheduler/phase_reset_schedule.py,sha256=lVXrMB-CFdC4_QLeFiqsp2C0iX2BIpRavuJj1tp-lsI,1765
 laboneq/compiler/new_scheduler/preorder_map.py,sha256=0e1zQEuUs6sc9PWRzl0cTHhvKAwx549njQtGQ8BFhLM,1820
 laboneq/compiler/new_scheduler/pulse_phase.py,sha256=poXl-PKFIO7X_xN3Qjqo-NWC-svaom3dWjetfKEsw8c,3821
-laboneq/compiler/new_scheduler/pulse_schedule.py,sha256=z_zA7iEyo26BTikzSFsTX08O51bsHlxIXqO4oMxz3GM,6376
-laboneq/compiler/new_scheduler/reserve_schedule.py,sha256=ZhRagWpUXkLwgn3M7rNbnYP-1xXBXUYizVl2kKiTD7U,567
-laboneq/compiler/new_scheduler/root_schedule.py,sha256=6kl_JbTm5H8ZBL5RP-b8Jm4U7txwuzxigilll6mHzCk,1404
-laboneq/compiler/new_scheduler/schedule_data.py,sha256=lLto_aYrGNCfAiKzlkSMYa5YLBygj8exc4g40O-kJHI,630
-laboneq/compiler/new_scheduler/scheduler.py,sha256=S9exfa_d0zIeQM6UFCBcQyapDKKPMebF-Lpy1uvvWYM,39182
-laboneq/compiler/new_scheduler/section_schedule.py,sha256=r69FbAS97HA6HGwNCu5-6PJw-5PcPo1lZ3qXI2nBYgo,12975
-laboneq/compiler/new_scheduler/utils.py,sha256=yvHLrDZ8Sa1gH1qmYmb3dNXndnJb2X9fOujuOByP_Qg,483
+laboneq/compiler/new_scheduler/pulse_schedule.py,sha256=kw_8NWNRTNcSqGCdHxyhjwwTfAMlhsJ3KrtKcyzPRRY,6962
+laboneq/compiler/new_scheduler/reserve_schedule.py,sha256=ML-aqZlwj8_TpUV8lVdZuvdEtr3JahjYGIu6EvUXM38,625
+laboneq/compiler/new_scheduler/root_schedule.py,sha256=ni57ni5v4d5sBTYolt364x0mM_BIKA_dcifP2w8lnp8,1375
+laboneq/compiler/new_scheduler/schedule_data.py,sha256=qt6GHxcfsYPiCgM9doBV48XFTkcje-w1D7B8A2KyNXU,1016
+laboneq/compiler/new_scheduler/scheduler.py,sha256=ZDAvf3cAq_kOz3R-1IvNr3x-R3eZ_NKmk7vElvdAxX4,39737
+laboneq/compiler/new_scheduler/section_schedule.py,sha256=6x2PPJykhWnIBaclojjpkp54eY8XPN3rpXTxB1KkblE,13207
+laboneq/compiler/new_scheduler/utils.py,sha256=buFGd2oxNFr3hfGc8fx_dyMCbxTwimiSOuxCqeqSDRk,757
 laboneq/compiler/scheduler/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/scheduler/event_graph.py,sha256=N3jMW3wW_aX4123B3WxKMIcDr-CmZvZqshc-mTE0Vh0,12943
 laboneq/compiler/scheduler/event_graph_builder.py,sha256=aoT1FIXGZ601gGL-d4awtztWmEtdglOcZyXYEJC4EcE,24682
 laboneq/compiler/scheduler/sampling_rate_tracker.py,sha256=taR4AdTTaYNXfaEgM5hZNhL2VbcGnJCkx9gt4xAJg9E,1949
-laboneq/compiler/scheduler/scheduler.py,sha256=0XjM6mlUZ1rF3D7F3avEAQD4cLtNNVJHLDybWtYycA0,115469
+laboneq/compiler/scheduler/scheduler.py,sha256=W0rMofmnGEeG9pbFQMcfPDd5BUZCQ4O3zBqzT_boZRI,115572
 laboneq/compiler/workflow/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/compiler/workflow/compiler.py,sha256=eyBguvFvrOhPxxXEndiCM08rd2T1eKGrslyoVZoCaCY,48281
+laboneq/compiler/workflow/compiler.py,sha256=75atImHpWlSUC3Jc9LjivpSFl-ypFjzi9vfdx4ES4Nw,48911
 laboneq/compiler/workflow/precompensation_helpers.py,sha256=dpRw6dGJcsDAv0uI48cfzso75IYHNVfP1NUkRhD-giI,12424
-laboneq/compiler/workflow/recipe_generator.py,sha256=pABAUGBgEAvyKEZSmcYFCxZ5Rrt2ln-mbtZ4K_o0-R4,11479
+laboneq/compiler/workflow/recipe_generator.py,sha256=a0cNO2fAOVhrJCm8M28qqmFe7MuAC0jTbPTSe5atSEo,11747
 laboneq/contrib/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py,sha256=dII-ZVAa3HumwKfHYGiARVBDCjaqJhGFy55XAjOPiaM,4511
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py,sha256=3RjtFb3sxYokBP92COK53gCmBrCk9ubs8_xOb75fem4,3379
 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/bloch_simulator.py,sha256=VzPR_c7CCIf80jMKiYSVXYZH_BIDv3KYipLaDPqGSxw,2833
 laboneq/contrib/example_helpers/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
-laboneq/contrib/example_helpers/example_notebook_helper.py,sha256=mdUHBcUec4DK9lHQk_MTW6kGLxpMWwmByK-jY9jkAhM,6132
+laboneq/contrib/example_helpers/example_notebook_helper.py,sha256=ufTkf4Uygm1ajgv2-feNBwj2HR2ewas730S9FuddKOs,6272
 laboneq/contrib/example_helpers/feedback_helper.py,sha256=pqth_zVGWqEJz7DBdv3EUryfWbqOWCmneF6PyRNLQV0,4116
 laboneq/contrib/example_helpers/qubit_helper.py,sha256=Eh2UVnSrGlBy7nmxRcCWpQL2GG2fCrA1A6582UbYWqg,3581
 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py,sha256=JKYF-5BXJJ3aBc4fEOOGnbheh9LPX4wir-xZCMrrzTs,8830
 laboneq/contrib/example_helpers/data_analysis/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/example_helpers/data_analysis/data_analysis.py,sha256=8eNR-b89_rs0odyNcWmH0DlTZ9zZHYI1wjIRCy8buSs,6670
 laboneq/contrib/example_helpers/descriptors/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/example_helpers/descriptors/hdawg.py,sha256=Q8Asxnt3x1Jl84nrTahjOgx-Ao_TWYdbIFf4WZdAkCU,502
 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py,sha256=CzjRnXjw4v_WMtSvY5xZbmLztyEHfAQlzMbgvZ8cAmE,956
 laboneq/contrib/example_helpers/descriptors/shfqc.py,sha256=J3yEwcXPHlwylmhXmjztNwxr3idEkRrt7v9eTZPMp2k,1345
 laboneq/contrib/example_helpers/descriptors/shfsg.py,sha256=hFcFls-QkY7tQdvQ9y5K25UHsuWcV-nIxwOwyn_42JM,1377
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py,sha256=mDvjBkffwNTOI0ZZggySTmVdjFejzZx3nGdwQctLTZY,1930
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py,sha256=N6W7sxG0HnjqS4xbfxqeUK60b4eYdrnN-57qk7Xkkiw,1618
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py,sha256=kZcUW_hQ_yUziYa7aPNi0iRZ5wWwTcYxqD8DDQYQnNg,2383
 laboneq/contrib/example_helpers/plotting/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
-laboneq/contrib/example_helpers/plotting/plot_helpers.py,sha256=1KboB12KX6-X3sRbviYkXhKntCD-LGBXIrwkqv1-zko,6098
+laboneq/contrib/example_helpers/plotting/plot_helpers.py,sha256=YH0AJlCXvV7ixAu9y61tXIiDWLcnZG2loQSAcigpePs,6620
 laboneq/controller/__init__.py,sha256=gPuU9BwcRA-VFMRLtIzd9Y-KvLQhYv0czaGuo-uimjc,308
 laboneq/controller/cache.py,sha256=sI4qtTQurYPWzMp7iW1oKwQp_GVftQX9isDkTNZ-bDE,1479
-laboneq/controller/communication.py,sha256=ubslF7og_i56C-d5Xrrlc1S7me6Gzi0AgbUVIDTxufM,14834
-laboneq/controller/controller.py,sha256=_nmGdEr45Lp21bXXrrKYAJaC_GQ2ZRDK6jIBhkUNxj0,33043
+laboneq/controller/communication.py,sha256=nZux8F5Y18777VqLMk3_nwhJB3H1iDIvinoDuo4ZOAA,14819
+laboneq/controller/controller.py,sha256=ahN7Lb-9gUSv-W5ALUGNGXjwhLmtpuvpngsklZdIYTk,33283
 laboneq/controller/laboneq_logging.py,sha256=esE9zHGFnANO-cBb2Im6s1UtyL2loZU-VMdpBUchPvk,4504
 laboneq/controller/protected_session.py,sha256=v4T5NsQxE57E22hJltIumOnLAoBms0D7ZTtUYjGHGGM,337
 laboneq/controller/recipe_1_4_0.py,sha256=xzds1pM2-nZxO756G8zbGd2itWhdvyh2N2tXh2ZHYK0,14870
 laboneq/controller/recipe_enums.py,sha256=uNjZPJci2KCleSh2zNYTOkUEfBpBK0spOU16GvaWj6Y,638
 laboneq/controller/recipe_processor.py,sha256=sXyHnvZJEABG5enAHGm-2VYq6lfQ2lsYLE5_jKUnsng,19575
 laboneq/controller/results.py,sha256=b9Oy_F0GqSzHulNSWqt6ltUzXpYZ4JmC0BVIE176Qzc,1917
 laboneq/controller/toolkit_adapter.py,sha256=moZzwjnRUUbyT-7JL31EBtBh39VD3USx1SRolFS8v-g,1594
 laboneq/controller/util.py,sha256=UuAnPes0F2VXm_3nw0NCAVRNRhsOSUorkTN0gjHMcsw,624
 laboneq/controller/versioning.py,sha256=IcmXytxA6OtbudyM2aK8gCgWLcuLbweru5wIafolpnU,281
 laboneq/controller/devices/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/controller/devices/device_collection.py,sha256=ocTpC6pIvf2wDcPKz_xumoqgt7X5P2PLKGJeqGWcpms,12627
+laboneq/controller/devices/device_collection.py,sha256=BJ4SEWVi2DYZD2XcUzmVK6NofRZqwh7dxWwBAORxzcU,15231
 laboneq/controller/devices/device_factory.py,sha256=10RUKOTxniQDFM9NOjgLkLk33b7hdsNiOZhXyfXTxoQ,1173
-laboneq/controller/devices/device_hdawg.py,sha256=-DsPo-4U93hrzJvcwJ2y2WIhZQ9X2NM4mAg5JMAcL0Y,22931
+laboneq/controller/devices/device_hdawg.py,sha256=eWePSboxqiHm71uuE9FS55_CuWbEKlxcrnAJI8SYbvM,23560
 laboneq/controller/devices/device_nonqc.py,sha256=N2EHsj1Gsf6n1nBZVBdAKU1k-bltgfMb1kqcmtTAVf0,1234
 laboneq/controller/devices/device_pqsc.py,sha256=_Al4lmalT89zbcbevTIaKHOP_I2WWN95SnxkfEcrPOg,8260
-laboneq/controller/devices/device_setup_dao.py,sha256=Q0qQg7rxkSoHKy1CYuOicPKNNZujN2juBE4-_Tu106E,1179
-laboneq/controller/devices/device_shfqa.py,sha256=jpfr8grCmcHJJSyWvEgbz_il8BOVHAfu28f8yI4sOog,39516
-laboneq/controller/devices/device_shfsg.py,sha256=xS_ncxsQOcz0yqf2gHg6yYInx2WXtnRtIfkbYLVAMp4,19911
-laboneq/controller/devices/device_uhfqa.py,sha256=Uujazg7Bz2Jb0VfcCcYDyXNWD_4b7-EKo6NktT-5t9w,28085
-laboneq/controller/devices/device_zi.py,sha256=k6nxKh4vFchmH0qnzF4GWMwyji3RzEc5RHjAa2xAI5U,41842
-laboneq/controller/devices/zi_emulator.py,sha256=GXwl8V8A8ULbeHGN5OBf0l3VchhKco5tQyLAvXgqY3M,29827
+laboneq/controller/devices/device_setup_dao.py,sha256=oP7CPZdylqRRfJEGonw8J0DTLO1Dpjz0zBt2GMRaSLo,2830
+laboneq/controller/devices/device_shfqa.py,sha256=DgT_kcG-EVHu0B5XSYWY_FwcqSZKDfQwxAHwKq6ftL8,40121
+laboneq/controller/devices/device_shfsg.py,sha256=bHqk2Z7yQhLorhjWbxVDu5i-6fNlJgYl5o5mPIM_cQc,20516
+laboneq/controller/devices/device_uhfqa.py,sha256=8L64mqOBZQm8O3cG9PEoDRuDoNrNiRWqE97zOYYvw2U,28707
+laboneq/controller/devices/device_zi.py,sha256=gmyR5LlYSRBQjWg3bxhWauH1_skwZ_0z-CBt7NzHwOQ,42463
+laboneq/controller/devices/zi_emulator.py,sha256=Uqs0jrOfGPuZ6vEZhZvaUM7Dqr8ThND9kqz15XtadGU,30874
 laboneq/controller/devices/zi_node_monitor.py,sha256=1b2fraKJar4w6rp3LeRohgWXayLY0lj35rPFQJO795Q,9837
 laboneq/core/__init__.py,sha256=nx0-aqsC4hdoO7jIj0Ut7yNTQbe5dme7jodU9wkd4N4,97
 laboneq/core/path.py,sha256=QEND23yk_IXftMdZaDszUVCdezZACDYwyxPOD9AoVVo,1998
 laboneq/core/validators.py,sha256=pmtl8RdlBr-49CkxJseW1VrDtJU2gqLVBWSZdLrRpWc,1338
 laboneq/core/exceptions/__init__.py,sha256=8ZaME3lWkRJ7BZw1qVWGbt91jaklPd67iyIZ-zXoBpE,126
 laboneq/core/exceptions/laboneq_exception.py,sha256=bWRVbnLJiBszdNeEglRFp-z1Q3bb-irTIzf2vgTaBK0,123
 laboneq/core/serialization/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
@@ -156,17 +156,17 @@
 laboneq/core/types/enums/reference_clock_source.py,sha256=hN1gZKxh_ElHZOq3zl0nHyJaaKoCgixTc0fKcCKUy7E,188
 laboneq/core/types/enums/repetition_mode.py,sha256=hRnj_stjpVRDGTCHoN7q5kPffAm6OoTX9BWcoerl3A8,198
 laboneq/core/types/enums/section_alignment.py,sha256=nYuTh1r0PL35aQoLUgeOGTnZoAb6XhGPgVY4a70UMgc,170
 laboneq/core/utilities/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/core/utilities/pulse_sampler.py,sha256=eKdg1IcTwjoVmp7mKSSAu6eV80mYPgHaMUUr9AIWkZ4,8039
 laboneq/core/utilities/replace_pulse.py,sha256=LEWhHoF3s8klVXSaVO26gkthLuyJE_A5NRcZW8WGTx4,9808
 laboneq/dsl/__init__.py,sha256=gsR9dv88edpbJLrwc_X2jj147IfVWpnTT10td01fPkY,178
-laboneq/dsl/laboneq_facade.py,sha256=HyhhUFRexTeBK36jZEQthyHjX2nHPkGIRslXIql0ZNU,2963
+laboneq/dsl/laboneq_facade.py,sha256=xfeHLO9ywCpClZ1Jl_I_Z_IC5wDpr2tckFsJhPuy8PY,2929
 laboneq/dsl/parameter.py,sha256=AbR78048B3-jyYvq_A5rmBqaeg4v0C601f9EGFJzRN0,2552
-laboneq/dsl/session.py,sha256=-FvTLSMAdw4KjeMOYbq850tGfNCRcseN5M9CD1cHJQI,23470
+laboneq/dsl/session.py,sha256=P-mOhpv3-u5stl3oeRSjTn97b4Nm4M42gxw24HYzsT4,25670
 laboneq/dsl/utils.py,sha256=v0qlt2XA2CXiGK3Rpi_PC45YZGeQriRz-ShovaTXMBE,2296
 laboneq/dsl/calibration/__init__.py,sha256=LX2pS3IGkA0uTtVK-3SncxddLT4hLHssivSlAPFqz7M,487
 laboneq/dsl/calibration/calibratable.py,sha256=DEx55rhplLTxoaf8-bGnmZqyO4eZdIyMptiLAGKEp7M,545
 laboneq/dsl/calibration/calibration.py,sha256=2js2bMMwX6pYrRFlWv3NRyeJOE5pwxDRqg3qVff6X5c,1886
 laboneq/dsl/calibration/calibration_item.py,sha256=JlPu54zS2NfivokgD4ICOhrw5e3Rhs5DO7pB0iDazpY,111
 laboneq/dsl/calibration/mixer_calibration.py,sha256=_ivXcsDgELxaC8zZ7E5caMhE-HZYSuuDyR5odaVImKw,992
 laboneq/dsl/calibration/observable.py,sha256=5zf7HE7e4MnrnHcgwAWMKkejOiVTZs4UCtlRiVn8OVw,3403
@@ -190,25 +190,25 @@
 laboneq/dsl/device/instruments/nonqc.py,sha256=j6jLNrFifaKe1QDcQJcTVWMdQR7eBI345V7S-iWqhts,466
 laboneq/dsl/device/instruments/pqsc.py,sha256=JQrg31Gj6HRjUOYjDyG5m2A9ngrQOFcX0mHw_2BwsGk,948
 laboneq/dsl/device/instruments/shfqa.py,sha256=C6yaZvxr1xZwUegOILTNC8_B7a28O_GqsIYag-dCvYo,2248
 laboneq/dsl/device/instruments/shfsg.py,sha256=MCJkySVlx7ls33IPHrf2ZmKBRuBXQDPGwVw7o_JXfmk,1659
 laboneq/dsl/device/instruments/uhfqa.py,sha256=sHidPdFcZHTOXXSFJFcCD__K90IkEogpZPiai5dt8Us,2312
 laboneq/dsl/device/instruments/zi_standard_instrument.py,sha256=IcDKOIMU_Yi9niyZlq9aw1xKXVLGd2VO0mO9qRW8lDI,888
 laboneq/dsl/device/io_units/__init__.py,sha256=UOI3L_V5_3lji95HUdB3KvWoAQkja0pR8bGBshRnRr4,187
-laboneq/dsl/device/io_units/logical_signal.py,sha256=HQGnFDMpGt0i-m9SVKHFh8rnQPviFKHr91Y6ukt4xPI,11590
+laboneq/dsl/device/io_units/logical_signal.py,sha256=Pju-ynSMfqI-HuOvOvZFT1TrFZD8v-thiJVDD2ZS5vQ,12288
 laboneq/dsl/device/io_units/physical_channel.py,sha256=1C7QrHbUBIUXD0gzR6Z5RpazDAA_WJJb6qSqY44_xeY,3608
 laboneq/dsl/device/servers/__init__.py,sha256=ZeYikalTjZXb_HDjfdGe6YHUuZAlDv0qqHZ0d1JLOE8,114
 laboneq/dsl/device/servers/data_server.py,sha256=URgMXwwmzNAPF3PrQBTE11dU7QLxGaJa0tIdi8F2BiQ,704
 laboneq/dsl/enums/__init__.py,sha256=GeDXWBzskaPr4MxVoeJp6kj-X5kVZA1yrbUw7wcV2F0,718
 laboneq/dsl/experiment/__init__.py,sha256=N159QRiB6rNL_RH6vzZwYqi4B91GTlX-JmmysAoQgMM,508
 laboneq/dsl/experiment/acquire.py,sha256=g4Pvm6T0qu8tH8LRTHhCZ1wb2K4Drc1rawNeNTRkS_E,972
 laboneq/dsl/experiment/call.py,sha256=eATarAz81C0QC5Ih-Uuh9PrS0g4rEF_vbQsrav_-I6Q,814
 laboneq/dsl/experiment/delay.py,sha256=98P3AePai3fqH1csDnWSxUN3EGJchuysX_2qnkCF2-Y,780
-laboneq/dsl/experiment/experiment.py,sha256=3yjsIrfy1fUqNgTPDdEPp9rS6LgBy7BhUrOX5jAiLHk,41480
-laboneq/dsl/experiment/experiment_signal.py,sha256=h7jt59QU50KabKDqmyXY2bFGcc_jMGcsB9hGvPVwj5U,8058
+laboneq/dsl/experiment/experiment.py,sha256=-UF5dmsIlhhGmA98LXQB7CR1qUCaf_RKh5ixHUyeK8g,41433
+laboneq/dsl/experiment/experiment_signal.py,sha256=YUofWe1v4XUuwzaKU9RyLDLbV0tKqmS3PD5gM2P_-OA,7754
 laboneq/dsl/experiment/operation.py,sha256=kJPLIjNTFf_lJkVsOmASPi7GZVJ9CCZySdA2YDCmswU,401
 laboneq/dsl/experiment/play_pulse.py,sha256=yGd_-jzkuOK_i4A65mfoPfeG1IRKK8ZaDQE-E627Idw,1647
 laboneq/dsl/experiment/pulse.py,sha256=WH8cUpm40dv-xUTi-B4s542QU3c3BF4Dpwm-QtYTwOw,3568
 laboneq/dsl/experiment/pulse_library.py,sha256=cvLbQXr4lUPeXDY-09iNuWyqhdAvtTAROTcJbiPZD8I,7932
 laboneq/dsl/experiment/reserve.py,sha256=tn1YEkW6E7BbBuG4SKveCmiAXrsYm2IeMUI2iDnwazs,890
 laboneq/dsl/experiment/section.py,sha256=zC0Dgxsr3wbrnyfpDsRmYTNuE5AXogvZAkZrayK7KMI,11366
 laboneq/dsl/experiment/set.py,sha256=4hEgxT9iYWNgDEEAFDS4D1GlgTsInRK3regArR4cnaU,640
@@ -225,15 +225,15 @@
 laboneq/pulse_sheet_viewer/__init__.py,sha256=F_gdqvR3iTbFH2-iGtGWPp2v2XpMu0c4SXEPEIJyQb0,127
 laboneq/pulse_sheet_viewer/event_graph_viewer.py,sha256=hKBUzFzimfz9YAFUYNYwrhwMscXHa-4M3BNa6id6SHE,2059
 laboneq/pulse_sheet_viewer/interactive_psv.py,sha256=D7pEX9C8mP9EZofE5L3aAAkX3lNFaEoHwBc_l2AHyec,2692
 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py,sha256=_O53T2cm8KWDhbUKoONuRb_9JOKyKvOqEMtQgrwlQPI,3288
 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html,sha256=TsX3r0W8qf_PKAw1pYreXQEcexRfzgL_FmbvOAFh06s,1443040
 laboneq/simulator/__init__.py,sha256=BuPOsR4Dwi6tSLAsG0lBeHzpOZFnCsNn93ohr-v9mZ8,152
 laboneq/simulator/output_simulator.py,sha256=OjbHVNNkrYITwZaJ58HaqAeM-ETeLP4y_ifA0aQXrGE,5904
-laboneq/simulator/seqc_parser.py,sha256=k0wq30NDSpiIVYNLZQDfke5XdHjB8ExdZjMWSdWLgGM,37399
+laboneq/simulator/seqc_parser.py,sha256=Ru8TnmLX49vX9jhY_o8hbZ6iy3FgL5EuB1XHgmAjFgg,39230
 laboneq/simulator/wave_scroller.py,sha256=j3lQLcCuqv8b2UTbViAtXIDvEa2mXADApPmhj570fdU,12081
-laboneq-2.3.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
-laboneq-2.3.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
-laboneq-2.3.0.dist-info/METADATA,sha256=q5COgeapip1ypsiJlFY8dp-bY_H04k4U5nMdtm3rczc,3188
-laboneq-2.3.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-laboneq-2.3.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
-laboneq-2.3.0.dist-info/RECORD,,
+laboneq-2.4.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
+laboneq-2.4.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
+laboneq-2.4.0.dist-info/METADATA,sha256=izEbJfyerp_UbO7Uwbddccf_pILC4K2v3RnR8X3l0KY,3188
+laboneq-2.4.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+laboneq-2.4.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
+laboneq-2.4.0.dist-info/RECORD,,
```

